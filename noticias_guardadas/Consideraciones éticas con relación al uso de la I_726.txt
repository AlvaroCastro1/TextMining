Título: Consideraciones éticas con relación al uso de la IA generativa - Silicon
URL: https://www.silicon.es/brandvoice/consideraciones-eticas-uso-ia-generativa
Número de palabras: 2618

Actualidad TI > Brandvoice Posts La inteligencia artificial generativa se ha convertido en una tecnología transformadora con un rango aparentemente ilimitado de aplicaciones y la promesa de beneficios generalizados para la sociedad. Sin embargo, detrás de esta promesa se esconden numerosos desafíos éticos y empresariales que requieren una consideración cuidadosa. A medida que el uso de la IA generativa crece y más empresas incorporan esta tecnología en sus productos y servicios su impacto en la sociedad se vuelve cada vez más evidente. Por esta razón existe una necesidad urgente de abordar las dimensiones éticas del uso generalizado de estas herramientas para tener la seguridad de que su desarrollo y despliegue se alineen con los valores fundamentales de la sociedad. La IA generativa se refiere a una familia de modelos de aprendizaje profundo dotados de una capacidad extraordinaria para crear contenido, ya sea texto, imágenes u otros tipos de datos, que se asemeje estrechamente a la información en la que fueron entrenados. Al escrutar los patrones dentro de los datos de entrenamiento, estos algoritmos adquieren la capacidad de generar resultados nuevos e innovadores, produciendo esencialmente nuevas muestras dentro del mismo formato de datos. Los modelos de IA generativa presentan una amplia versatilidad y variedad, desde aquellos diseñados para generar texto o audio hasta los que analizan conjuntos de datos (historial clínico, sentencias judiciales, series estadísticas…) a partir de los cuales elaboran informes. Cada uno de estos enfoques ha llevado al desarrollo de diferentes productos y servicios que no solo están avanzando en la comprensión de la IA, sino que también ofrecen ventajas significativas en comparación con los productos y servicios que no incorporan IA generativa. Los modelos de difusión destacan cuando se trata de crear contenido visual y multimedia o de realizar tareas como el relleno y la expansión de imágenes, especialmente cuando se les proporciona una indicación textual que detalla el resultado deseado. Los modelos de difusión prominentes para la generación de imágenes incluyen DALL·E 2, Image GPT, Midjourney y Stable Diffusion.  Las aplicaciones potenciales de IA generativa abarcan multiples sectores, incluyendo servicios financieros, educación y salud. En la banca, la IA generativa puede ayudar a la detección de transacciones fraudulentas, la generación de datos sintéticos para entrenar modelos de aprendizaje automático, la protección de datos del cliente utilizando GANs para estimar el valor en riesgo y la predicción de posibles pérdidas en escenarios específicos, entre otros. En educación tiene la capacidad de revolucionar el diseño personalizado de cursos, mejorar el aprendizaje de los estudiantes a través de simulaciones virtuales y restaurar materiales de aprendizaje históricos. Además, en atención médica las aplicaciones incluyen el descubrimiento y desarrollo de medicamentos, tratamientos personalizados, imágenes médicas y gestión de la salud poblacional, entre otras aplicaciones transformadoras. A pesar de su potencial aparentemente ilimitado, la IA generativa no está exenta de inconvenientes. La utilización de esta tecnología introduce una serie de dilemas éticos, incluyendo la perpetuación de sesgos preexistentes, preocupaciones sobre la propiedad intelectual y los derechos de autor, así como la responsabilidad derivada de la capacidad potencial para generar noticias falsas o la capacidad de suplantar a individuos, como sucedió recientemente en Colombia con abogados que presentaron en Colombia una demanda ante los tribunales en la que se citaban casos falsos “inventados” por ChatGPT. Estos problemas críticos requieren un examen cuidadoso y soluciones reflexivas. A medida que el uso de la IA generativa crece, también lo hacen las preocupaciones sobre su posible uso indebido, lo que ha llevado a la creación de iniciativas como marcos regulatorios y legislativos específicos para fomentar el desarrollo responsable y sostenible de la IA generativa. La Comisión Europea ha sido uno de los primeros organismos en actuar, publicando en 2019 sus “Directrices éticas para la IA confiable”. Estas directrices destacan la importancia de que los sistemas de IA cumplan con las leyes, adhieran a principios éticos y sean técnica y socialmente robustos. En este sentido se identifican siete requisitos fundamentales Estos serían los requisitos fundamentales: Existe un acuerdo general en que cualquier sistema de IA debe empoderar a los seres humanos, proteger sus derechos y permitir la supervisión humana. Sin embargo, la IA generativa plantea desafíos únicos en este sentido com jefe ser la creación de burbujas de contenido que limiten los distintos puntos de vista sobre la información que le llagan al usuario. Por otra parte la aplicación de sesgos a la IA generativa podría facilitar la manipulación maliciosa de la información buscando influir en la opinión pública. Cuando se aplica en las redes sociales, las capacidades de la IA generativa pueden utilizarse para engañar a los usuarios, lo que lleva a percepciones distorsionadas de la realidad y presiones sociales aumentadas. Encontrar el equilibrio adecuado entre el inmenso potencial de la IA generativa y la necesidad de agencia humana y supervisión requiere de una monitorización continua, investigación y desarrollo de herramientas y políticas que promuevan la autonomía del usuario y mitiguen los posibles impactos negativos. La creciente sofisticación de la IA generativa plantea preguntas sobre su seguridad y confiabilidad. Una de las preocupaciones más extendidas es que la IA generativa contribuya a la propagación de información errónea y noticias falsas, influyendo en la opinión pública. En ese sentido la creación de imágenes falsas muy convincentes de figuras de alto perfil, conocidas como deepfakes, es una de las mayores preocupaciones en torno a la IA generativa, ya que pueden utilizarse para propaganda política o para desacreditar a individuos u organizaciones. La investigación continua sobre las vulnerabilidades de los sistemas de IA y el desarrollo de contramedidas sólidas ayudarán a reducir el daño potencial debido a las noticias falsas (fake news) y deepfakes, y aquí la estrecha colaboración entre gobiernos, empresas tecnológicas y expertos en ciberseguridad será crucial para abordar adecuadamente los problemas de seguridad y robustez técnica de IA generativa. La IA generativa se basa en grandes conjuntos de datos, que incluyen información personal y con derechos de autor, generalmente recopilada a través de Internet. Entrenar la IA con datos con derechos de autor sin permiso puede llevar a infracciones e incluso violaciones de los derechos de autor y la posibilidad de que el contenido generado por la IA carezca de originalidad y se asemeje estrechamente a obras existentes. El desarrollo ético de la IA generativa debe involucrar prácticas claras de gobernanza de datos, incluyendo políticas estrictas para la recopilación, almacenamiento y uso de datos. Además, abordar las ambigüedades sobre los derechos de autor del contenido generado por IA será esencial para fomentar un entorno justo y legalmente conforme. A veces se puede generar incertidumbre sobre el procedimiento del funcionamiento interno de la IA en relación con la toma de decisiones de los algoritmos aplicados, siendo necesario un ejercicio de transparencia al respecto que permita interpretar y explicar los resultados de los modelos de IA generativa. Estos métodos pueden incluir la visualización de los procesos internos del modelo, el análisis de sus representaciones aprendidas o la prueba de sus resultados con datos del mundo real. Un tema particularmente controvertido que ha surgido con el crecimiento del uso de IA generativa se centra en la calidad y diversidad de los datos de entrenamiento. Ha habido casos de modelos de IA generativa que trabajan con datos personales o imágenes que refuerzan estereotipos sexuales o raciales o que subrepresentan ciertos grupos. Abordar estos sesgos requiere un diseño cuidadoso, una evaluación continua y la selección responsable de datos de entrenamiento. Inevitablemente, la IA generativa también puede ser utilizado por actores maliciosos para generar contenido ofensivo, incluyendo imágenes y textos discriminatorios o violentos, propaganda o incluso pornografía falsa. Asegurar la diversidad, la no discriminación y la equidad en las aplicaciones de IA generativa es no solo un imperativo ético, sino también crucial para construir sistemas de IA inclusivos y equitativos. Dado el entusiasmo y, a menudo, asombro generado por la IA generativa, es fácil pasar por alto algunas de las consecuencias menos deseables de la rápida adopción de esta tecnología en el medio ambiente y en la sociedad en su conjunto. Estos sistemas de IA generativa requieren recursos computacionales significativos y se estima que una consulta de ChatGPT utiliza de 3 a 30 veces más electricidad que una búsqueda tradicional de Google. Por lo tanto, el crecimiento esperado de IA generativa deberá estar acompañado de un cambio de paradigma hacia el uso de fuentes de energía más sostenibles para alimentar los centros de datos que albergan este tipo de aplicaciones, si no queremos agravar la crisis climática. Otro desafío que potencialmente afecta a todos los trabajadores humanos es cómo la IA generativa cambiará la naturaleza del trabajo. Durante varios años, los economistas han debatido sobre el impacto que tendrán los robots y la IA en los empleos, particularmente aquellos que involucran tareas repetitivas de baja cualificación que son más fáciles de automatizar. Ahora, con el crecimiento de esta tecnología un rango mucho más amplio de empleos está potencialmente en riesgo, incluyendo trabajadores administrativos, creadores de contenido, programadores, servicio al cliente y representantes de ventas, entre otros. Abordar estas implicaciones éticas requiere un enfoque de múltiples facetas, que involucre esfuerzos para reducir la huella energética de los sistemas de IA e iniciativas para volver a capacitar y reciclar a la fuerza laboral para el panorama laboral en evolución. A medida que la adopción de la IA generativa crece, existe una clara y urgente necesidad de una regulación mejor y más precisa para abordar el problema de la responsabilidad. Los algoritmos estocásticos que impulsan estos sistemas de IA generativa a veces crean “alucinaciones”, que no tienen sentido o se pueden demostrar que son falsas. Un caso reciente involucró a un equipo de abogados en los EE. UU. que no se dio cuenta de que ChatGPT había inventado las citas y referencias que usaron en una presentación ante el tribunal. Integrar la supervisión humana en los sistemas de IA generativa será esencial no solo para detectar alucinaciones, sino también para garantizar una toma de decisiones ética, reducir posibles sesgos y desafiar acciones que parezcan sin sentido. En el campo emergente de la gobernanza de la inteligencia artificial, la Unión Europea ha dado un paso significativo al proponer en 2021 la Ley de IA (también conocida como AI Act), un marco legislativo integral diseñado para regular los sistemas de IA. La ley clasifica los sistemas de IA en cuatro categorías según sus riesgos: Este marco tiene como objetivo encontrar un equilibrio entre fomentar la innovación y salvaguardar los derechos fundamentales, la salud, la seguridad, el medio ambiente, la democracia y el Estado de derecho. La Ley de IA plantea preguntas importantes sobre cómo debemos regular la inteligencia artificial generativa, un campo en rápido desarrollo que abarca sistemas como ChatGPT y grandes modelos de lenguaje (LLM en sus siglas en inglés). La legislación propuesta se basa en gran medida en las leyes existentes de la Unión Europea (UE), como el Reglamento General de Protección de Datos (RGPD) y la Ley de Servicios Digitales, y requiere que los LLM detrás de la IA generativa tengan suficientes salvaguardias contra la generación de contenido que viole estas leyes. Reconoce que estos llamados modelos fundamentales, como GPT-4 de OpenAI, que impulsa ChatGPT, requieren una atención especial porque son capaces de una amplia gama de tareas generales, por lo que cualquier error o sesgo en el modelo subyacente puede potencialmente afectar a un gran número de aplicaciones construidas sobre estos modelos. En consecuencia, los proveedores de sistemas de IA generativa estarán sujetos a requisitos adicionales de transparencia, que incluyen: Los proveedores deben informar a los usuarios que el contenido que encuentran está generado por IA. La comunicación clara es crucial, especialmente cuando la IA interactúa con personas naturales. Los proveedores tienen la responsabilidad de diseñar y entrenar sus modelos con salvaguardias para evitar la generación de contenido ilegal o perjudicial. Esto se extiende al respeto de los derechos fundamentales, incluida la libertad de expresión. Los proveedores deben publicar resúmenes de su uso de datos de entrenamiento que puedan estar protegidos por derechos de autor. Es importante aclarar que estos requisitos no clasifican a los modelos fundamentales como sistemas de IA de alto riesgo. En cambio, buscan alinear la IA generativa con los objetivos generales de la Ley de IA: la protección de los derechos fundamentales, la salud, la seguridad, el medio ambiente, la democracia y el Estado de derecho. También es importante destacar que esta propuesta de ley está aún en proceso de evaluación y se espera su aprobación a principios de 2024. La regulación de la IA generativa a través de la futura Ley de IA marca un momento crucial en el camino hacia la implementación responsable de la IA. Aunque establece un precedente prometedor, aún queda mucho trabajo por hacer. La creación de un marco claro y adaptable que acomode la naturaleza versátil de la IA generativa es crucial. Además, esta conversación se extiende más allá de las fronteras de Europa, ya que el mundo se enfrenta al complejo desafío de regular la IA generativa mientras fomenta la innovación y protege los intereses de la sociedad. Fuera de la UE otras regiones y países están desarrollando legislación para regular el uso de la IA. Sin embargo, crear nuevas leyes suele ser un proceso lento y los legisladores pueden tener dificultades para comprender completamente el potencial de esta tecnología y mantenerse al día con sus avances. Por esta razón, se han propuesto muchas otras estrategias y propuestas para abordar los desafíos éticos, legales y sociales planteados por IA generativa. Aquí hay algunas de las estrategias y propuestas clave: Las empresas tecnológicas y desarrolladores de IA trabajan en el desarrollo de directrices y mejores prácticas voluntarias para gobernar el desarrollo y despliegue de GenAI. Si bien la autorregulación de la industria puede ser rápida y flexible, existen preocupaciones sobre su efectividad y potencial para el sesgo. Algunas organizaciones e instituciones promueven marcos éticos de IA. Por ejemplo, el IEEE (Instituto de Ingenieros Eléctricos y Electrónicos) ha desarrollado una Iniciativa Global sobre Ética de Sistemas Autónomos e Inteligentes, que incluye directrices para la IA ética. Las evaluaciones de impacto de IA buscan evaluar las posibles consecuencias sociales, económicas y éticas de desplegar sistemas de la IA generativa, ayudando a los responsables de la formulación de políticas a tomar decisiones informadas. Algunas regulaciones se centran en la gobernanza sólida de los datos, asegurando que los datos utilizados en el entrenamiento de IA sean representativos, diversos y éticamente obtenidos. Leyes de privacidad de datos más estrictas, como el RGPD en Europa, ya desempeñan un papel aquí. Algunas iniciativas abogan por la participación pública en el proceso de toma de decisiones sobre la regulación de la IA generativa. Consultas públicas y aportaciones pueden ayudar a garantizar que los sistemas de IA se alineen con los valores y necesidades de la sociedad. Establecer comités de ética de IA independientes o cuerpos de supervisión podría ayudar a garantizar un control más objetivo y experto sobre la regulación de la IA generativa.   Estas estrategias y propuestas pueden actuar como complemento de la legislación formal y pueden ayudar a moldear un entorno ético y legal para los desarrollos de la IA generativa más allá de las fronteras de la UE. Para descubir más sobre las consideraciones éticas relativas al uso de la IA, te invitamos a leer el white paper de NTT DATA, aquí.    NEWSLETTER   Suscríbete para recibir nuestros mejores artículos  
						Brand Discovery ofrece a los anunciantes la oportunidad de dirigirse directamente a nuestras comunidades profesionales. Consiste en un formato publicitario que se integra en el contenido editorial y en el diseño general de la página dando lugar a una publicidad mucho más fluida y poco intrusiva. Los lectores pueden identificar fácilmente su procedencia con la expresión “Brand Discovery”. Para más información, contáctenos en la siguiente dirección:						 publicidad@netmediaeurope.com    Síguenos: 