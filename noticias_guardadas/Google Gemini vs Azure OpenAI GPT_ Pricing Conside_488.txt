Título: Google Gemini vs Azure OpenAI GPT: Pricing Considerations
URL: https://www.vantage.sh/blog/gcp-google-gemini-vs-azure-openai-gpt-ai-cost
Número de palabras: 983

Easily build complex reports Monitoring and efficiency metrics Custom cost allocation tags Network cost visibility Organizational cost hierarchies Budgeting and budget alerts Discover active resources Consumption-based insights Alerts for unexpected charges Automated AWS cost savings Discover cost savings Unified view of AWS discounts COGS and business metrics Model savings plans Collaborate on cost initiatives Create and manage your teams Automate cloud infrastructure Easily build complex reports Monitoring and efficiency metrics Custom cost allocation tags Network cost visibility Organizational cost hierarchies Budgeting and budget alerts Discover active resources Consumption-based insights Detect cost spikes Automated AWS cost savings Discover cost savings Unified view of AWS discounts COGS and business metrics Model savings plans Collaborate on cost initiatives Create and manage your teams Automate cloud infrastructure by Emily Dunenfeld Contents Updated June 26, 2024 to reflect recent updates. For most of the early 21st century, Google was just about unanimously considered the king of AI. However, with OpenAI’s release of ChatGPT to the public at the end of 2022 and the whirlwind of AI innovation that followed, Google has taken the backseat. Due to the impressive 1M context window and competitive pricing, Gemini could be their chance to take the lead. Google’s generative AI offerings have been hard to follow. In December 2023, not even one year after Bard (Google’s former and short-lived flagship LLM) was announced, Gemini was announced as its “largest and most capable model” and since then, there have been rapid and significant developments. February 2024, in particular, was a busy month for updates and rebranding efforts. The biggest of which was the rebranding of Bard to Gemini. Gemini builds upon and surpasses Bard in terms of functionalities and scalability. February also saw the consolidation of Duet AI for Workspace, the AI tools used to integrate with Google productivity tools (i.e. Gmail, Docs, and Sheets), and Duet AI for Developers into the Gemini framework. Gemini is accessible via Google AI Studio or Google Cloud Vertex AI. Table of supported Google Gemini models (as of 6/26/2024). Note-Gemini 1.0 Ultra and Gemini 1.0 Ultra Vision are GA with allow list. OpenAI almost needs no introduction. Since the release of ChatGPT to the public in November 2022, OpenAI GPT models have seen widespread adoption across various sectors. Its impact on the AI landscape has been substantial, catalyzing advances in research and development and fostering increased awareness, with many people referring to AI chatbots and ChatGPT synonymously. Azure OpenAI is a partnership between Azure and OpenAI that enables Azure users to use OpenAI (including OpenAI GPT models) via an API, Python SDK, or their web-based interface, while authenticated with their Azure cloud credentials. Azure OpenAI distinguishes itself from OpenAI by offering co-developed APIs, enhanced security, and private networking. Throughout this article, “GPT models” refers exclusively to Azure OpenAI GPT models for the sake of brevity. Table of supported Azure OpenAI GPT models (as of 6/26/2024). Gemini has been met with skepticism from users, due in part to Bard falling short of expectations. Gemini 1.0 has received mixed reviews from users, with some saying it falls short of GPT-4 and some saying they prefer it over GPT-4. However, the highly anticipated Gemini 1.5 and its massive context window are receiving glowing accolades from early adopters, with predictions that it is poised to surpass GPT-4. Aside from comparing benchmarks of the two, we can compare them at a service and model level. As far as service offerings, Google and Azure provide varying levels of support. 
Vertex AI Studio
 
Azure AI Studio
 Fine-Tuning Models: Supervised fine-tuning for Gemini 1.0 Pro is in preview. With Azure, you can fine-tune GPT-3.5 Turbo. Context Caching: Certain Gemini models support context caching for a separate charge, enabling you to cache repetitive input/output results easily and possibly save money. Data Use: Neither Google nor Azure uses customer data to train their AI models. As far as the actual models go, there are several quantitative factors to consider. Charges vary for different model types and input types. Google Gemini model pricing table (as of 6/26/2024). Charges for GPT models are fairly simple. It is a pay-as-you-go, with no commitment. There are additional customization charges. Price varies per region and is shown for the US East region. Charges vary for different model types and context. OpenAI GPT model pricing table (as of 6/26/2024). Fine-tuning charges are based on training tokens and hosting time. OpenAI GPT fine-tuning pricing table (as of 6/26/2024). Based on benchmarks, user feedback, and use cases the most comparable models are: Gemini 1.5 Pro is the cost-effective choice compared to GPT-4o. Both the input and output tokens are priced 30% lower than GPT-4o’s. Gemini 1.0 Pro is significantly less expensive than GPT-4. Its input tokens are priced 99.17% lower than GPT-4’s and its output tokens are 98.75% lower. This dramatic price difference makes Gemini 1.0 Pro a good option for users looking to optimize costs. The GPT models are still widely considered to be the most powerful AI models available on the market. However, based on the extraordinarily competitive pricing of Gemini, as well as the 1M context window with Gemini 1.5, Google has positioned itself as a serious competitor in the realm of AI. Monitor your Google & Azure costs. Track and monitor your AI spend with Vantage. Interested in this type of content? Join our growing Slack community of over 1,000 cloud professionals  Infinite recursion in Lambda can cause costs to spiral out of control. Following best practices can help you avoid getting caught up in your own Lambda horror story.   For frequently accessed data, R2 is always less expensive than GCS, while GCS is much more cost-effective for archival use cases.   While Graviton processors are gaining significant adoption, some companies are still hesitant to make the switch. Switching to Graviton is a significant way to lower compute costs.  
            Tools for developers to analyze,report on and reduce cloud
            costs.
           
            ©
            
            VNTG Inc.
          