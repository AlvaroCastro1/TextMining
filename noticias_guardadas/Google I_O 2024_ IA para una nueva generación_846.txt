Título: Google I/O 2024: IA para una nueva generación
URL: https://blog.google/intl/es-es/productos/tecnologia/google-io-2024-ia-para-una-nueva-generacion/
Número de palabras: 3300

15, May, 2024 [[read-time]] mins de lectura 
          Sundar Pichai comparte noticias de Google I/O, incluidas actualizaciones en Gemini, Android, Búsqueda y Fotos.
         Nota del redactor: El siguiente texto es una transcripción modificada de los comentarios de Sundar Pichai en I/O 2024, y se ha adaptado para incluir más información de la anunciada sobre el escenario. Consulta todas las notas informativas. Google ha entrado de lleno en la era Gemini. Antes de entrar en materia, quiero reflexionar sobre el momento en el que nos encontramos. Llevamos invirtiendo en IA más de una década e innovando en todas y cada una de sus facetas: investigación, productos e infraestructura. De todo esto hablaremos hoy. Aun así, seguimos en el inicio del camino del nuevo rumbo que está tomando la IA. Vemos muchas oportunidades en el futuro: para creadores, desarrolladores, nuevas empresas… En definitiva, para todos. Y aprovechar esas oportunidades es el objetivo de esta era Gemini. Empecemos. La era Gemini Hace un año, sobre el escenario de I/O, os contamos por primera vez nuestros planes para Gemini: un modelo vanguardista creado para ser multimodal de forma nativa y desde el principio, y que pudiera razonar a través de textos, imágenes, video, código y más superficies. Sin duda, un gran paso para llegar a convertir cualquier entrada en cualquier salida. Por eso hablamos de una IA para una nueva generación. Desde entonces, hemos presentado los primeros modelos de Gemini, los más capaces hasta el momento. Demostraron un rendimiento excepcional en todas las pruebas comparativas multimodales. Dos meses después, presentamos Gemini 1.5 Pro, lo que supuso un gran avance en el contexto extenso. Este modelo puede ejecutar 1 millón de tókenes en producción y de manera constante, más que cualquier otro modelo básico de gran escala. Queremos que todo el mundo se beneficie de lo que Gemini es capaz. Por eso, hemos querido contaros pronto estos avances. En estos momentos, más de 1500 millones de desarrolladores utilizan los modelos de Gemini en nuestras herramientas para depurar código, adquirir nuevos conocimientos y crear la nueva generación de aplicaciones de IA. También hemos integrado las innovadoras funciones de Gemini a todos nuestros productos de una manera muy satisfactoria. Hoy os enseñaremos ejemplos en la Búsqueda, Fotos, Workspace, Android y otros productos. Avances en el producto Actualmente, todos nuestros productos (con 2000 millones de usuarios) emplean Gemini. También hemos creado nuevas experiencias (por ejemplo, en los dispositivos móviles) que permiten a los usuarios interactuar con Gemini directamente a través de la aplicación propia, que está disponible tanto en Android como en iOS. Y en cuanto a Gemini Advanced, que utiliza los modelos más capaces, podemos contaros que más de un millón de personas ya se han registrado para probarlo en cuestión de tres meses, y sigue registrando una muy buena acogida. “Resúmenes creados con IA” llega a la Búsqueda Una de las transformaciones más interesantes que ha vivido Gemini se ha producido en la Búsqueda de Google. El año pasado, respondimos miles de millones de consultas gracias a nuestra Experiencia Generativa en la Búsqueda. Los usuarios la utilizan para buscar de formas totalmente nuevas, plantear nuevos tipos de preguntas, y hacer consultas más largas y complejas (incluso buscando con fotos). Así sacan provecho de lo mejor que la Web puede ofrecer. Hemos estado probando esta experiencia fuera de Labs. Y nos motiva ver no solo que se está usando más la Búsqueda, sino también que la satisfacción de los usuarios ha aumentado. Por fin puedo anunciar que comenzaremos a lanzar esta experiencia completamente renovada, Resúmenes creados con IA, a todos los usuarios de EE. UU. esta misma semana. Y pronto llegará a más países. Estamos trabajando en muchas innovaciones en la Búsqueda. Gracias a Gemini, podemos crear experiencias de búsqueda mucho más ricas, incluso en nuestros productos. Presentamos “Pregunta a Fotos” Un ejemplo de toda esta innovación es Google Fotos, un producto que lanzamos hace casi 9 años. Desde aquel entonces, los usuarios lo utilizan para organizar sus recuerdos más importantes. Esto se traduce en que todos los días se suben más de 6000 millones de fotos y vídeos. Supongamos que estáis pagando en el aparcamiento, pero no recordáis vuestra matrícula. Antes, podíais buscar fotos por palabras clave y luego desplazaros por años de fotos en busca de matrículas. Ahora, simplemente podéis preguntarle a Fotos, ya que conoce los coches que aparecen frecuentemente, triangula cuál es el vuestro y os dice la matrícula. Además, Pregunta a Fotos puede ayudaros a buscar en tus recuerdos de una manera más avanzada. Por ejemplo, tenéis una hija llamada Lucía y estáis rememorando sus primeros años de vida. Ahora, puedes preguntarle a Fotos: “¿Cuándo aprendió Lucía a nadar?” Y podéis seguir con solicitudes más complejas: “Muéstrame cómo ha progresado en natación Lucía”. En este sentido, Gemini va un paso más allá de lo que supone una simple búsqueda, ya que reconoce diferentes contextos, desde nadar en la piscina hasta practicar esnórquel, pasando por identificar el texto y las fechas de los certificados de natación, por ejemplo. Y Fotos responde a las solicitudes mostrando un resumen, para que sea posible volver a revivir recuerdos increíbles y disfrutarlos. Lanzaremos Pregunta a Fotos este verano y presentaremos más funciones en el futuro. Más conocimientos con multimodalidad y contexto extenso Aprovechar al máximo los conocimientos en todos los formatos es la razón por la que desarrollamos Gemini para que fuese multimodal desde el principio. Se trata de un modelo con todas las modalidades integradas. Por lo tanto, no solo comprende todos los tipos de entrada, sino que también encuentra conexiones entre ellas. La multimodalidad multiplica radicalmente las preguntas que podemos hacer y las respuestas que obtendremos. El contexto extenso lleva todo esto un paso más allá, ya que nos permite aportar aún más información: cientos de páginas de texto, horas de audio o una hora de vídeo, un repositorio entero de código, o incluso, aproximadamente 96 menús de vuestro local favorito de tartas de queso. Para tantos menús, necesitaríais una ventana de contexto de un millón de tókenes, pero ahora esto es posible con Gemini 1.5 Pro. Los desarrolladores han estado utilizando este modelo de unas formas muy interesantes. Durante los últimos meses, hemos estado implementando Gemini 1.5 Pro con un contexto extenso en versión preliminar. Hemos hecho una serie de mejoras de calidad en la traducción, la codificación y el razonamiento. Estas mejoras se verán reflejadas en el modelo a partir de hoy mismo. Por fin puedo anunciar que todos los desarrolladores, sean de donde sean, podrán utilizar esta versión mejorada de Gemini 1.5 Pro. Además, Gemini 1.5 Pro, con un contexto de 1 millón de tókenes, ya está a disposición de los usuarios de Gemini Advanced, en 35 idiomas. 2 millones de tókenes en la versión preliminar privada Con 1 millón de tókenes se abren posibilidades completamente nuevas. Aunque es increíble, creo que podemos conseguir aún más. Por eso, hoy extendemos la ventana de contexto a 2 millones de tókenes y la ponemos a disposición de los desarrolladores a través de una versión preliminar privada. Es increíble echar la vista atrás y ver lo mucho que hemos avanzado en pocos meses. Y esto marca el siguiente paso en nuestro camino hacia el objetivo final de lograr un contexto infinito. Gemini 1.5 Pro en Workspace Hasta ahora hemos hablado de dos avances técnicos: la multimodalidad y el contexto extenso. Cada uno de ellos es potente por sí solo. Pero juntos, ofrecen capacidades más profundas y más inteligencia. Y todo esto se hace realidad en Google Workspace. Los usuarios siempre están buscando cosas en sus correos en Gmail, así que estamos trabajando duro para que, gracias a Gemini, los resultados sean más eficaces. Por ejemplo, si sois padres, querréis estar informados de todo lo que pasa en el colegio. Gemini también puede ayudaros con esta tarea. Ahora podemos pedir a Gemini que resuma todos los correos recientes del colegio. En segundo plano, identifica los correos relevantes e incluso analiza los adjuntos, inclusive los PDFs. Como resultado, veréis un resumen con los puntos clave y lo que tenéis que hacer. Puede que esta semana estuvierais de viaje y no pudierais asistir a la reunión de la Asociación de Padres y Madres, y la grabación de la reunión dura una hora. Si se hizo con Google Meet, podéis pedirle a Gemini que resuma lo más destacado. O si hay un grupo de padres que busca voluntarios y estáis libre, por supuesto, Gemini puede redactar por vosotros una respuesta. Hay muchísimos más ejemplos más de cómo se pueden hacer las cosas más fáciles en el día a día. Gemini 1.5 Pro está disponible desde hoy mismo en Workspace Labs. Más información de la mano de Aparna Salidas de audio en NotebookLM Acabamos de ver un ejemplo con salidas de texto. Pero con un modelo multimodal podemos hacer mucho más. Estamos consiguiendo avances en este sentido, y aún queda más por hacer. Los resúmenes de audio en NotebookLM son una muestra de esos avances, ya que emplea Gemini para tomar vuestros materiales de origen y generar una conversación de audio personalizada e interactiva. Esta es la gran ventaja de la multimodalidad. Pronto podréis mezclar y combinar entradas y salidas. Esto es lo que queremos decir cuando hablamos de IA para una nueva generación. Pero ¿y si pudiéramos ir aún más lejos? Más avances gracias a los agentes de IA Llevar todo esto aún más lejos es una de las oportunidades que vemos con los agentes de IA. Yo los considero sistemas inteligentes que demuestran razonamiento, planificación y memoria, y que son capaces de "pensar" varios pasos por delante y de trabajar con distintos programas y sistemas, todo ello para hacer tareas por vosotros y, lo que es más importante, bajo tu supervisión. Todavía estamos en los albores, pero os voy a enseñar los tipos de casos prácticos con los que estamos trabajando arduamente. Empecemos por las compras. Es muy entretenido comprar zapatos, pero mucho menos devolverlos cuando no nos quedan bien. Imaginaos que Gemini pudiera hacer por nosotros todos estos pasos: Buscar en la bandeja de entrada el recibo Localizar el número de pedido en el correo Rellenar un formulario de devolución Incluso programar una recogida en UPS Así es mucho más fácil, ¿verdad? Veamos otro ejemplo un poco más complejo. Pongamos que os acabáis de mudar a Chicago. Pues Gemini y Chrome trabajarían juntos para ayudaros con todos los preparativos gracias a que pueden organizar, razonar y sintetizar por vosotros. Por ejemplo, querréis explorar la ciudad y encontrar servicios cercanos, desde tintorerías hasta paseadores de perros. Y tendréis que actualizar vuestra nueva dirección en decenas de sitios web. Gemini puede ayudaros con todas esas tareas, y os pedirá más información cuando sea necesario, para que vosotros siempre tengáis el control. Esa parte es muy pero que muy importante: a medida que creamos prototipos de estas experiencias, nos planteamos cómo hacerlo de forma privada, segura y útil para todo el mundo. Os hemos mostrado unos casos prácticos sencillos, pero dan una idea del tipo de problemas que queremos resolver creando sistemas inteligentes que piensen, razonen y planifiquen por vosotros. Lo que significa para nuestra misión El poder de Gemini (con multimodalidad, contexto extenso y agentes) nos acerca a nuestro objetivo final: conseguir que la IA sea útil para todos. Creemos que así es como avanzaremos más en nuestra misión: organizar la información del mundo a través de cualquier entrada, hacerla accesible a través de cualquier salida, y combinar la información del mundo con la información de VUESTRO mundo de una manera que os sea verdaderamente útil. Abriendo nuevos horizontes Para aprovechar todo el potencial de la IA, necesitaremos abrir nuevos caminos. El equipo de Google DeepMind ha estado trabajando arduamente en esta labor. Hemos visto mucho entusiasmo en torno a 1.5 Pro y su extensa ventana de contexto. Pero los desarrolladores también nos contaron que querían algo más rápido y rentable. Así que mañana mismo presentaremos Gemini 1.5 Flash, un modelo más ligero diseñado a escala que se ha optimizado para tareas en las que la baja latencia y el coste sean la prioridad. 1.5 Flash estará disponible en AI Studio y Vertex AI desde el martes. De cara al futuro, siempre hemos querido crear un agente universal que fuese útil en el día a día. Project Astra integra comprensión multimodal y capacidades de conversación en tiempo real. También hemos dado grandes pasos en la generación de videos e imágenes con Veo e Imagen 3, y presentamos Gemma 2.0, nuestra última generación de modelos abiertos para la innovación responsable en IA. Más información de la mano de Demis Hassabis Infraestructura para la era de la IA: Presentamos Trillium Para entrenar modelos de última generación, se necesita una gran capacidad de computación. La demanda de la industria de computación de tipo ML se ha multiplicado por 1 millón en los últimos 6 años. Y cada año se multiplica por 10. Google se creó para esto. Durante 25 años, hemos invertido en infraestructura técnica de primera clase: desde el hardware puntero que está detrás de la Búsqueda hasta nuestras unidades de procesamiento de tensores (TPU, por sus siglas en inglés) personalizadas, que son el motor de nuestros avances en IA. Gemini se entrenó y ejecutó íntegramente en nuestras TPUs de cuarta y quinta generación. Otras empresas líderes en IA, como Anthropic, también han entrenado sus modelos en TPUs. Por fin hoy podemos anunciar nuestra sexta generación de TPUs: Trillium. Trillium es nuestra TPU con mejor rendimiento y eficiencia hasta el momento, ya que multiplica por 4,7 el rendimiento computacional por chip de la generación anterior, la TPU v5e. A finales del 2024, pondremos Trillium a disposición de nuestros clientes. Además de nuestras TPUs, es todo un orgullo poder ofrecer CPUs y GPUs que admiten cualquier carga de trabajo. Por ejemplo, los nuevos procesadores Axion que anunciamos el mes pasado, nuestra primera CPU personalizada basada en Arm, con un rendimiento y una eficiencia energética líderes en el sector. Para nosotros, también es un orgullo ser uno de los primeros proveedores de nube en ofrecer las vanguardistas GPUs Blackwell de NVIDIA, que estarán disponibles a principios del 2025. Tenemos la suerte de colaborar con NVIDIA desde hace muchos años, así que es increíble poder ofrecer a nuestros clientes las revolucionarias prestaciones de Blackwell. Los chips son una parte fundamental de nuestro sistema integrado de extremo a extremo: desde hardware de rendimiento optimizado y software abierto hasta modelos de consumo flexibles. Todo esto se reúne en nuestra hipercomputadora de IA, una arquitectura de supercomputadora revolucionaria. Las empresas y los desarrolladores la están utilizando para abordar desafíos más complejos, con más del doble de eficiencia en comparación con la simple compra de hardware y chips en bruto. Los avances en nuestra hipercomputadora de IA son posibles, en parte, gracias al enfoque de refrigeración líquida que adoptamos en nuestros centros de datos. Llevamos haciendo esto casi una década, mucho antes de que se convirtiera en una tecnología puntera en el sector. En la actualidad, la capacidad total de nuestra flota de sistemas de refrigeración líquida es de casi 1 gigavatio, y sigue en aumento; es decir, casi 70 veces la capacidad de cualquier otra flota. La clave de todo está en la magnitud de nuestra red, que conecta nuestra infraestructura a escala mundial. Nuestra red abarca más de 3 millones de kilómetros de fibra terrestre y submarina: más de 10 veces (increíble, ¿eh?) el tamaño de la red del siguiente proveedor de nube más importante. Seguiremos realizando las inversiones necesarias para continuar innovando en IA y ofrecer prestaciones de última generación. El capítulo más emocionante de la Búsqueda hasta el momento Una de nuestras mayores áreas de inversión e innovación es nuestro producto fundador, la Búsqueda. Hace 25 años creamos la Búsqueda para ayudar a los usuarios a entender las olas de información que circulan en Internet. Con cada salto a una nueva plataforma, hemos logrado avances que han conseguido ayudar a responder mejor a vuestras preguntas. En el móvil, hemos descifrado nuevos tipos de preguntas y respuestas, utilizando un mejor contexto, conocimiento de la ubicación e información en tiempo real. Gracias a los avances en comprensión del lenguaje natural y visión por ordenador, hemos hecho posibles nuevas formas de buscar: con la voz o tarareando para dar con vuestra nueva canción favorita, o con una foto de esa flor que visteis paseando. Y ahora incluso podéis usar Rodea para Buscar para identificar esos zapatos nuevos tan chulos que quizá queráis comprar. Adelante, ¡siempre podéis devolverlos! Por supuesto, la Búsqueda en la era Gemini llevará esto a un nivel completamente nuevo, combinando nuestros puntos fuertes de infraestructura, las últimas capacidades de la IA, nuestro elevado listón en calidad de la información y nuestras décadas de experiencia conectando a los usuarios con la riqueza de la Web. El resultado es un producto que hace el trabajo por vosotros. La Búsqueda de Google es IA generativa a la escala de la curiosidad humana. Y es nuestro capítulo más emocionante de la Búsqueda hasta el momento. Más información sobre la era Gemini de la Búsqueda de la mano de Liz Reid Experiencias de Gemini más inteligentes Gemini es más que un chatbot; lo hemos diseñado para que sea vuestro asistente personal para el día a día y que pueda ayudaros a realizar tareas complejas y ejecutar acciones por vosotros mismos. Interactuar con Gemini debería ser algo intuitivo y natural desde el punto de vista conversacional. Por eso anunciamos una nueva experiencia de Gemini que nos acerca a esa idea llamada “Live” que permite tener una conversación profunda con Gemini usando solamente la voz. También extenderemos la ventana de contexto a 2 millones de tókenes en Gemini Advanced a finales de este año, lo que permitirá cargar y analizar archivos superdensos, como vídeos y códigos de gran tamaño. Más información de la mano de Sissie Hsiao Gemini en Android Android tiene miles de millones de usuarios en todo el mundo, así que es increíble poder anunciar que vamos a introducir una experiencia de Gemini aún más integrada en el sistema operativo. Gemini, como vuestro nuevo asistente de IA, tiene como objetivo ayudaros en cualquier momento y lugar. También hemos incorporado los modelos de Gemini a Android, incluido nuestro último modelo en el dispositivo: Gemini Nano, con multimodalidad, que procesa texto, imágenes, audio y voz para poder disfrutar de nuevas experiencias y al mismo tiempo que la información se mantenga privada en el dispositivo. Consulta todas las novedades de Android Nuestro enfoque responsable de uso de la IA Seguimos abordando la oportunidad de la IA con valentía y entusiasmo. Pero también nos aseguramos de hacerlo de manera responsable. Estamos desarrollando una revolucionaria técnica a la que llamamos “red teaming asistido por IA”, que se inspira en los avances de Google DeepMind en juegos como AlphaGo. Además, hemos introducido nuestras innovadoras técnicas de marca de agua, como SynthID, en dos nuevas modalidades, texto y vídeo, para que el contenido generado por IA sea más fácil de identificar. Más información de la mano de James Manyika Creando el futuro juntos Todo esto demuestra el importante avance que supone adoptar un enfoque audaz y responsable para conseguir que la IA sea útil para todo el mundo. Llevamos mucho tiempo dando prioridad a la IA. Nuestras décadas de liderazgo en investigación han sido precursoras de muchos de los avances modernos que impulsan el progreso de la IA, para nosotros y para el sector. Además, contamos con: Este progreso solo es posible gracias a nuestra increíble comunidad de desarrolladores. Vosotros lo hacéis realidad a través de las experiencias y aplicaciones que creáis cada día. Así que, todos los que estamos aquí en Shoreline y los millones de personas que nos estáis viendo desde todo el mundo, brindemos por las oportunidades venideras y por poder crearlas juntos. 
              Síguenos
            