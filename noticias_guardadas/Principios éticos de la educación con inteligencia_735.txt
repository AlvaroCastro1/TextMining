Título: Principios éticos de la educación con inteligencia artificial
URL: https://observatorio.tec.mx/edu-news/principios-eticos-de-la-educacion-con-inteligencia-artificial-ia/
Número de palabras: 1189

¿Existe realmente una diferencia entre hacer cosas éticas y hacer las cosas éticamente? Aunque la ética aplicada a la educación con inteligencia artificial es un campo inexplorado por muchos, comprenderla es de suma relevancia en tiempos actuales. 
 
 ¿Existe realmente una diferencia entre hacer cosas éticas y hacer las cosas éticamente? Aunque la ética aplicada a la educación con inteligencia artificial es un campo inexplorado por muchos, comprenderla es de suma relevancia en tiempos actuales.  Al pensar en inteligencia artificial (IA) es normal imaginar el futuro de los coches que se conducen solos, los visores de realidad virtual o los avances en medicina, pero ¿qué tanto se ha pensado sobre el impacto social y ético de la IA? Aunque parezca que la ética y la inteligencia artificial son dos términos lejanos, la ética es importante para el buen desarrollo e implementación de la IA para el bien común, puesto que las implicaciones éticas asociadas principalmente con los datos (sobre el uso, consentimiento, privacidad, sesgos y transparencia de estos), así como otros aspectos que se discutirán más tarde, han sido tema de debate para muchas instancias internacionales. Aunque la era de la inteligencia artificial es ubicua, se debe desarrollar de manera responsable y con transparencia. Por ende, no solo es prioridad tomar en cuenta los aspectos técnicos de la IA, sino de las implicaciones éticas de su uso. Además, los gobiernos deben crear políticas y lineamientos para asegurar la práctica responsable de la IA, facilitando a su vez la innovación y el progreso. Las Naciones Unidas en su reporte “A Framework for Ethical AI at the United Nations”, menciona que gobiernos, organizaciones y empresas han empezado a considerar cómo se utiliza la IA. A saber, algunos han emitido políticas o principios, siendo la Comisión Europea uno de los actores más importantes en el área de responsabilidad política en este sentido. Por su parte, la Comisión Europea emitió la AI act, la cual es una propuesta de regulación para que desarrolladores, desplegadores y usuarios tengan los requisitos y obligaciones claras con respecto a los usos específicos de la IA. Busca reducir las cargas administrativas y financieras de las pequeñas y medianas empresas (Pymes). Dicha propuesta se fundamenta en un enfoque basado en el riesgo, integrado por cuatro niveles de riesgo. Catalogando a la educación en el nivel de high risk (alto riesgo). Existen muchas organizaciones a nivel internacional que han acuñado diversos términos para describir su marco ético sobre IA. Aunque algunos de estos son confusos, lo más importante son los principios contenidos en estos. Cada organización define su brand name según el enfoque de su marco ético, por lo que estos pueden variar: Ethical AI, Trustworthy AI, Explainable AI, Intepretable AI, Meaningful AI, Transparent AI, Responsible AI, Human-centered AI y Beneficial AI. Por ejemplo, la Comisión Europea, en su división de IA llamada High Level Expert Group on Artificial Intelligence (AI HLEG) utiliza el término de Trustworthy AI en su reporte “Guideliness for Trustworthy AI”, el cual transmite un sentido de confianza del ser humano a la IA, ya que esta tiene las cualidades de ser legal, ética y robusta. A saber, existen organizaciones que han estado trabajando en iniciativas sobre la ética en la inteligencia artificial. Por ejemplo, AI Ethics Iniciative, AI Now Institute, Deep Mind Ethics and Society, Future of Life Institute, The Institute for Ethical & AI Machine Learning, por mencionar algunas. Aunque su enfoque ha estado principalmente en los datos y cómo se analizan, existen organizaciones como The Montréal Declaration for Responsible Development of Artificial Intelligence, la cual ha desarrollado una serie de principios con carácter humanista que prometen mejorar el desarrollo, uso e implementación de la IA. Estos son algunos de los principios éticos generales insignia de la inteligencia artificial:  El uso de la inteligencia artificial en la educación (AIDE, por sus siglas en inglés) ha revolucionado no solo los procesos de enseñanza-aprendizaje, sino también la experiencia del aprendizaje en general.  Se ha identificado que el uso de la IA en educación ha tomado cuatro roles principales: tutor inteligente, tutelado, herramienta de aprendizaje/compañero y asesor en la formulación de políticas. No obstante, existen dilemas éticos sobre la IA en educación. La UNESCO señala que existen seis retos para lograr el desarrollo sustentable de la AIDE. Otros riesgos legales, éticos, de seguridad, etc., que se plantean son los siguientes: sesgo sistemático, discriminación, desigualdad, xenofobia (a nivel individual), brechas de desigualdad entre estudiantes, riesgos de privacidad asociados con la responsabilidad de los datos (consentimiento informado, violación de la privacidad, equidad, apofenia estadística), vigilancia y consentimiento, configuración de la identidad, confidencialidad del usuario, integridad e inclusividad, recolección de datos, disponibilidad restringida de datos, sesgo y representación, propiedad, control y autonomía de los datos. Aunque los riesgos éticos que implica el uso e implementación de la IA en la educación son variados, y muchos de ellos apenas están siendo considerados, se han creado reportes y políticas para asegurar el buen uso de la IA en educación. Algunas organizaciones se han preocupado por emitir lineamientos sobre la ética y la IA en la educación, de las cuales se puede mencionar las siguientes: UNESCO Ethics AI (2020), UNESCO Education & AI (2021), Beijin Consensus, OCDE (2021), Comisión Europea(2019), European Parliament Report AI Education (2021), UNICEF (2021) y Foro Económico Mundial (2019). Cabe señalar que los reportes en materia de ética en IA abarcan principios, dentro de los cuales se encuentran códigos más específicos para estos fundamentos, por lo que llegan a ser muy extensos. A continuación, se enlistan los siete principios éticos fundamentales de la inteligencia artificial para la educación: Es importante mencionar que muchos de los reportes no se enfocan en los derechos de los niños y las niñas a la privacidad. No obstante, organizaciones como la UNICEF, el Foro Económico Mundial, UNESCO Education & AI y el European Parliament Report AI Education y el Institute for Ethical AI in Education (IEAIE)han salido en defensa de la inclusión de los derechos de los niños en las políticas éticas sobre IA. Su objetivo es aminorar el riesgo de los y las niñas a la exposición de la IA, pero no solo para proteger sus datos y privacidad, sino también exponer los problemas relacionados con la maleabilidad de los infantes con respecto a valores, ideas y actitudes, y con lo que es apropiado para su edad. Ahora que ya sabes un poco más sobre la ética de la IA en la educación, ¿habías escuchado de los principios éticos de la IA en educación?, ¿qué tan importante es la ética en el desarrollo responsable de la IA?, ¿cuál principio crees que tenga más áreas de oportunidad?, ¿crees que el derecho a la privacidad de las y los niños sea respetado en los ambientes educativos?  Este artículo del Observatorio del Instituto para el Futuro de la Educación puede ser compartido bajo los términos de la licencia CC BY-NC-SA 4.0  Recibe en tu bandeja de entrada una dosis semanal de la actualidad educativa. 
						Observatorio | Instituto para el Futuro de la Educación | Tecnológico de Monterrey | Av. Eugenio Garza Sada 2501 Sur Col. Tecnológico C.P. 
						64849 | Monterrey, Nuevo León, México. 2022 | Contáctanos: observatorio@itesm.mx
						