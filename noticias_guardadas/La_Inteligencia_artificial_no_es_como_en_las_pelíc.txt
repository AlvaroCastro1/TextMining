Título: La Inteligencia artificial no es como en las películas. ¿Qué es? | EL MUNDO
URL: https://lab.elmundo.es/inteligencia-artificial/que-es.html

Como si el "volveré" de Arnold Schwarzenegger retumbara aún en nuestras cabezas, la mención del término inteligencia artificial (IA) provoca todavía escalofríos. Nuestra visión está contaminada por Terminator, por los replicantes de Blade Runner y, cómo no, por ese HAL 9000 de voz desesperada que tenía "miedo" y que pedía al astronauta Dave Bowman que se detuviera y no lo desconectara. La ciencia ficción "expande nuestros límites", como describe la escritora de este género Laura Fernández, "nos permite vivir otras vidas en nuestra imaginación" y facilita que "estemos en varios sitios a la vez". También lo hace la inteligencia artificial, pero nos cuesta detectarlo y las mezclas, como todo el mundo sabe, confunden. "Creo que ese miedo al progreso es un miedo a nosotros mismos, es algo atávico que no va a desaparecer nunca. Pensar que ese ser que creas te va a superar", aduce esta escritora, que ve en las redes sociales (sí, ahí hay IA) esa posibilidad de enterarte de todo que en el pasado se hubiese percibido "como magia negra". "La inteligencia artificial se ve como algo misterioso, escapado de una película, que de repente se ha metido en nuestras vidas. Pero la realidad es que está facilitando muchos servicios que sin ella sería imposible prestar a escala global", aclara Pilar Manchón, directora de interfaces cognitivos de la multinacional Amazon y experta en procesamiento de lenguaje natural. "El objetivo es mejorar la calidad de esos servicios, lo cual, dependiendo del dominio de aplicación, puede implicar una mejora en nuestra calidad de vida, en la experiencia de usuario, en el coste del servicio o en su accesibilidad, además de muchos otros beneficios. Pero las personas solemos tener un cierto resquemor cuando se nos presenta algo que no terminamos de entender", añade Manchón. "La IA está cuando sacamos el móvil para hacer una foto y el recuadro amarillo reconoce los rostros, cuando buscamos en internet, cuando Netflix nos recomienda una película según nuestros gustos, cuando usamos Google Maps para elegir el mejor trayecto o cuando Facebook te muestra determinadas actualizaciones de tus amigos", explica Nuria Oliver, doctora por el Media Lab del Instituto Tecnológico de Massachusetts (MIT) y directora de investigación de ciencias de datos en Vodafone. "Es esa inteligencia artificial invisible la que realmente tiene impacto en nuestras vidas, no esos robots apocalípticos del cine que se proponen dominar el mundo y que la gente se imagina". ¿Suerte o magia? No, es IA, aseguran desde BigML, una compañía que ofrece machine learning como servicio y que entrenó a su sistema para predecir quién se haría con los premios de la Academia. Seis de seis. Unos días antes de los Oscar, una máquina predijo con éxito los ganadores en las seis categorías principales: película, director, actriz principal, actor principal, actriz secundaria y actor secundario. "Somos una plataforma que contiene algoritmos, no hace falta ser programador para usarlos porque nuestra misión es hacerlos accesibles a todo el mundo. Introduces tus datos y puedes sacar predicciones. Yo misma soy economista, no data scientist", asegura Teresa Álvarez, jefa de producto de esta empresa y responsable del exitoso pronóstico de los Oscar, uno de los ejemplos de lo que se puede hacer ya gracias a la IA. ¿Cómo se hacen esas predicciones? El primer paso es entrenar a la máquina para que considere todas las variables que pueden influir en los miembros de la Academia a la hora de elegir los ganadores. Para ello, introdujeron en el sistema datos históricos desde el año 2000 (de 1.183 películas), las características de cada filme (como su presupuesto, el género o la duración), los actores del reparto, nominaciones en otros premios (Globos de Oro, BAFTA, Screen Actors Guild y Critics Choice) y su evaluación en la base de datos de cine IMDB. En total, el sistema cuenta con aproximadamente un centenar de datos por película. Con 13 nominaciones, La forma del agua partía como clara favorita, también para este sistema de IA, que le dio una puntuación de 91, mientras que Tres anuncios en las afueras obtuvo un 68. Guillermo del Toro, al que el algoritmo daba como vencedor con una puntuación de 75, se hizo con el Oscar al mejor director. Pocas dudas tenía la máquina de que Frances McDormand (99) ganaría la estatuilla a la mejor actriz y de que Gary Oldman (88) obtendría la de mejor actor. Por lo que respecta a los intérpretes secundarios, Allison Janney tuvo una puntuación de 64 y Sam Rockwell, de 95. Es el segundo año que BigML vaticina los resultados de estos premios de cine, aunque el año pasado, su sistema de IA sólo acertó la mitad de las categorías. ¿Qué han corregido? Mientras en 2017 usaron ensembles (un tipo de algoritmo), este año Teresa Álvarez optó por las redes neuronales profundas o deepnets. Lo más costoso, señala, es la preparación de los datos, por lo que en esta edición sólo han tenido que añadir los del último año. También se optó por prescindir de las críticas de los usuarios de IMDB que sí se incluyeron en 2017, al considerar que no fueron importantes el año pasado y es complicado obtenerlas. Una vez se completó la introducción de datos hasta 2012, evaluaron la fiabilidad del sistema retándolo a adivinar los ganadores de los Oscar entre 2013 y 2016. Si la IA es capaz de acertar los ganadores de los Oscar o el equipo que ganará una liga deportiva, quizás se esté preguntando si una máquina le puede decir qué número o combinación saldrá premiada en los juegos de azar. La decepcionante respuesta es que no: "Para la lotería no es eficaz porque lo que necesitas para poder hacer predicciones son variables del pasado para buscar patrones, y en estos sorteos todos los números tienen la misma probabilidad de salir", aclara Álvarez. "En la Liga sí se podría porque depende de los equipos, el entrenador, etc". Según señala, los clientes de esta compañía internacional que nació en Oregón (EEUU) y que cuenta con una sede en Valencia, son muy variados y pertenecen a campos tan diversos como el farmacéutico, el automovilístico, la banca o las telecomunicaciones. Utilizan la IA para la predicción de cancelación de cuentas bancarias e intentar no perder clientes, acelerar los procesos de selección de personal, hacer un marketing más personalizado o desarrollar coches inteligentes que, sin que el conductor se lo indique, sepan el destino que tienen que seguir o regulen la temperatura según las preferencias del usuario para que no se distraiga. Aunque Álvarez considera que "el avance en esta área desde 2011 ha sido bestial y el interés de las empresas por la IA ha ido en aumento, aún sigue habiendo desconocimiento y falta entender todo el potencial que tiene". Lo más difícil de entender para el ciudadano medio, que se levanta con el móvil entre las manos y pone el despertador en el mismo aparato cuando se acuesta, es ver cómo "los datos se conectan entre sí y proporcionan más información de lo que uno infiere de cada operación por separado. La IA busca patrones y a veces dichos patrones no son obvios a simple vista, que es lo que genera sorpresa", aclara Pilar Manchón. Los 20 años en el sector de esta sevillana -creó la startup de desarrollo de asistentes virtuales Indisys, que compró Intel en 2012- y su formación como lingüista le dan una perspectiva privilegiada sobre los avances de esta tecnología: "Para mí lo más emocionante son las mejoras en los sistemas de reconocimiento y síntesis de voz, el reconocimiento de imágenes y el entendimiento del lenguaje natural. Lo interesante de la democratización de la IA es que pone a disposición de cualquier usuario tecnologías muy avanzadas. Es el mecanismo ideal para incentivar la innovación, la creatividad y la diversidad".
 Una película que se convirtió en un filme de culto a pesar del fracaso que supuso para Disney en taquilla. Jeff Bridges interpreta a Kevin Flynn, un programador de videojuegos engañado por el gran ejecutivo de su antigua empresa, Ed Dillinger (David Warner), que se queda con la autoría de sus creaciones. Otros empleados de Encom, que así se llama la compañía, contactan con él para sacar a la luz las malas prácticas de Dillinger. Kevin Flynn se desmaterializa para poder entrar en el sistema y acceder a los datos, pero éste le captura. Seres humanos microscópicos en un mundo completamente virtual (no pudo aspirar al Oscar a los efectos especiales por utilizar gráficos animados por ordenador) y una carrera de motos que se quedó en la memoria de muchos cuarentones. "Estoy vivo". El encantador Número 5, el lector más rápido del mundo, devoraba datos y, a pesar de sus formas, el espectador acaba viéndolo como un igual. Tan inteligente como cualquiera, aprendía como un niño y no necesitaba que nadie le programase para adaptarse a un mundo para él sorprendente. Un rayo provoca el famoso cortocircuito de estra creación militar, cuyo artífice pensó en fines pacíficos no muy acordes con los planes del Ejército. Es uno de los clásicos cómicos de los años 80. El diseñador del robot había trabajado en la producción de Tron y de Blade Runner (1982). Los culpables de que los fondos de pantalla de los ordenadores a finales de los 90 se llenaran con barras verdes en movimiento fueron los hermanos Wachowski, actualmente hermanas porque ambas se cambiaron de sexo. Neo (Keanu Reeves), una especie de Mesías, fue el protagonista de una trilogía ciberpunk que puso de moda también las gabardinas de cuero negro y las gafas de sol macarras. En el arranque del filme, el bueno de Reeves es un tranquilo programador aficionado a los pirateos que cambiará su vida (o sus vidas) por un mensaje extraño que aparece en su computadora: "Matrix te posee". Unos agentes le persiguen y otro personaje extraño, Morfeo, le relata que lo que vive es un largo sueño fruto del desarrollo de una inteligencia artificial... La acción nos sitúa, acompañados de Will Smith, en el año 2035, cuando los robots ya realizan actividades humanas con las mismas habilidades que nosotros. El personaje de Smith, el detective Del Spooner, no es muy amigo del progreso y utiliza reliquias del pasado como su aparato de música o sus zapatillas made in siglo XX. La muerte de un científico lleva a investigar las vulnerabilidades de los androides aparentemente perfectos. La paradoja es que el duro de Spooner va a tener que contar con la ayuda de una inteligencia artificial. La película utiliza el título de unas historias cortas de Isaac Asimov, aunque la inspiración es más bien leve. La voz de Scarlett Johansson enamora a Joaquin Phoenix y le saca de su monótona y solitaria vida. Lo curioso es que Scarlett es Samantha, una asistente de voz, algo que no parece importar mucho al protagonista de esta película, un escritor llamado Theodore Twombly que se acaba de divorciar. La cinta de Spike Jonze lanza la pregunta de si alguna vez nos enamoraremos de las máquinas en un ambiente que recuerda más los colores y los diseños de los años 70 (o a los hipsters del barrio madrileño de Malasaña) que a un momento indeterminado del futuro. La relación también tiene sus altibajos... ¿Pero no iba a ser todo perfecto? Aunque los expertos del mundo real en inteligencia artificial se quedan afónicos señalando las diferencias con la robótica, nuestras cabezas no llegan a aceptar que una mente privilegiada no tenga forma humanoide. A Alicia Vikander le colocan algo raro en la cabeza para despistar, pero se demuestra más humana que cualquiera. Un programador (son los reyes de este tipo de películas) gana un sorteo en su empresa para pasar una semana en el refugio secreto del presidente de su compañía, Nathan (Oscar Isaac). Él no lo sabe, pero ha sido seleccionado para interactuar con Ava, una inteligencia artificial superior. Una edad de oro que a veces lleva a que extrapolemos lo que hace el cerebro con lo que pueden llegar a hacer los sistemas, y magnifica la confianza en que la evolución de las máquinas vaya a ir pareja con el comportamiento humano. Nuria Oliver reconoce las "expectativas sobreexageradas" que olvidan las acentuadas limitaciones de los sistemas existentes: "Los humanos aprendemos de manera continuada y no tan supervisada. Los sistemas necesitan ver millones de gatos para reconocerlos, mientras que un niño sólo precisa ver un par de ejemplos". "Los algoritmos son mucho mejores que nosotros en procesar grandes cantidades de información, detectar patrones e identificar anomalías dentro de esos patrones", prosigue Oliver, pero "los humanos tenemos mejores cualidades al interpretar, porque nuestra capacidad de enmarcar esos resultados específicos en un conjunto más amplio es superior. Conocemos otros factores que nos dan la panorámica y no necesitamos desaprender. Los sistemas de hoy en dia son buenos en sólo una cosa y hay que volver a entrenarlos para dominar otra. Es lo que se conoce como inteligencia artificial específica". "Si se mira la propia historia de la IA siempre ha tenido valles y picos de popularidad, porque la idea de crear máquinas inteligentes siempre ha cautivado nuestra imaginación", detalla Nuria Oliver. "Dependiendo de la época y de las capacidades de computación, ha habido momentos de gran expectativa y de pensar que ya estábamos al borde de inteligencia artificial general (la que supera las tareas limitadas y se asemeja al ser humano), que es el Santo Grial, y esas épocas han venido seguidas de otras de decepción, porque esas perspectivas no se han cumplido".  "Hoy estamos en una era de grandes promesas y de gran auge, porque es verdad que la IA está teniendo mucho impacto y económicamente estamos hablando de billones de dólares. Pero es peligroso que, como sociedad, vayamos a tomar decisiones sobre tecnologías que no entendemos y que tienen mucho impacto en nuestras vidas", subraya esta experta. "Además, los equipos deben ser multidisciplinares, porque la IA es transversal y de ahí viene su capacidad de transformación en la sociedad. Puedes aplicarla en medicina, en transporte, en educación, en legislación... Es necesario que trabajen expertos de todas las áreas". También que haya diversidad de toda índole y, sobre todo, de género: "Hay una gran falta de mujeres en investigación tecnológica", destaca. Oliver insiste en que la pluralidad es clave para generar avances más significativos y soluciones más innovadoras, pero también tiene otra dimensión de la que todavía se desconocen sus consecuencias: "Estos algoritmos que usan millones de personas de todas las geografías del mundo y de todos los grupos demográficos han sido diseñados por grupos bastante homogéneos. ¿Qué nos estamos perdiendo por este hecho?". Kike Maíllo, que ganó en 2012 el Goya a mejor director novel por su película Eva, donde abordaba el hito de la máquina que empieza a tener carácter y se aminora su deber de obediencia al humano marcado por las tres reglas de Isaac Asimov, tuvo la oportunidad de entrevistar a Marvin Minsky, uno de los padres de la IA, poco antes de su fallecimiento. Fue en una visita del científico a Madrid para recibir el premio Fronteras del Conocimiento de la Fundación BBVA. "Recuerdo que había cierta frustración en él", cuenta el cineasta, "él vivió un momento muy utópico en el que parecía que iba a ser la gran revolución, que evidentemente lo ha sido, pero él y sus compañeros esperaban que hubiera ido mucho más lejos y comentaba que nada de lo que había pasado en los últimos años le había sorprendido", rememora. "En las décadas del arranque de la IA, la Guerra Fría estaba en plena ebullición, y el dinero del Ejército acababa en los equipos de investigación de las universidades, pero de repente dejó de llegar ese dinero. Al final un investigador piensa en lo suyo y él lamentaba que no hubiera seguido ese mismo ritmo. Decía que debía haber muchos equipos haciendo cosas porque sólo unos pocos lograrán hacer algo importante. Minsky me dijo que él deseaba el gran desarrollo de la IA para poder entender mejor cómo funciona el cerebro humano. Para él había que crear máquinas que emulen nuestra capacidad de pensamiento y, sobre todo, nuestra capacidad de toma de decisiones", recuerda. El más importante de los padres de la inteligencia artificial acabó con su vida comiendo una manzana empapada en cianuro. Y probablemente lo hizo empujado por la espeluznante castración química a la que un juez le obligó a someterse dos años antes para evitar la cárcel por el solo hecho de ser homosexual. La aterradora historia de Turing ha tenido durante años un cierto paralelismo con el propio campo científico que él ayudó a crear, para el que algunos pioneros vaticinaban la madurez plena a la que nos tiene mal acostumbrados la ciencia ficción para los últimos años del siglo pasado, pero que parece que nunca termina de llegar. Sin embargo, décadas después, en 2013, llegó para Turing el indulto real. El propio ministro de Justicia británico, Chris Grayling, afirmó entonces que el perdón póstumo de la reina Isabel entraba en vigor inmediatamente, como merecido homenaje a "un hombre excepcional, con una mente brillante". La derogación de la discriminatoria sentencia coincide con un resurgir de la inteligencia artificial empujada por la era de los teléfonos móviles y con un discreto robot inteligente viajando en la órbita terrestre a bordo de la Estación Espacial Internacional, como si de HAL 9000 se tratase. Para llegar hasta ahí, el castillo de la IA se ha tenido que construir sobre los ingeniosos pilares que Turing ayudó a cimentar. Poco después de diseñar la máquina que descifró el inquebrantable sistema de codificación de mensajes de la Alemania nazi y de ser pieza clave en el final de la Segunda Guerra Mundial, en 1950, el pionero británico publicó un trabajo científico llamado Computing Machinery and Intelligence (Maquinaria Computacional e Inteligencia) en el que ya planteaba un test para evaluar si una máquina puede participar en una conversación con un humano de forma que un juez no pueda distinguir quién es el ser humano y quién la máquina. La conversación comenzaba con la pregunta: "¿Las máquinas pueden pensar?"; y con ella arrancaba la era de la inteligencia artificial. Había comenzado ya una nueva era, pero aún no tenía nombre. Habría que esperar algunos años más, hasta 1956, para eso, cuando tres jóvenes investigadores financiados por una corporación llamada RAND, algo así como un think tank de las Fuerzas Armadas de EEUU, idearon el primer programa de inteligencia artificial conocido como Logic Theorist. Algunos años antes, los investigadores del Carnegie Mellon Allen Newell y Herbert Simon que más de 25 años después ganaría el premio Nobel... ¡en Economía!- comenzaron a plantearse la posibilidad de enseñar a las máquinas a pensar. Su primer proyecto para lograrlo consistía en idear un programa capaz de imitar la capacidad de solucionar problemas que tiene el ser humano.  ¿Y qué tarea le pondrían? No una sencilla precisamente. Eligieron los teoremas planteados en la obra Principia Mathematica, de Bertrand Russell años después premio Nobel de Literatura- y Alfred Whitehead. Para ello reclutaron a un programador de RAND para desarrollar el programa. Así se unió al equipo John Clifford -Cliff- Shaw. En poco tiempo su programa había demostrado 38 de los 52 primeros teoremas del capítulo 2 del Principia Mathematica. De hecho, uno de ellos fue capaz de resolverlo de una forma mucho más elegante que la utilizada por Russell y Whitehead. El propio Simon se ocupó de anunciárselo mediante una misiva a Bertrand Russell: "Estoy encantado de saber que Principia Mathematica puede ser resuelto por una máquina. A Whitehead y a mí nos hubiera encantado saber que existía esta posibilidad antes de perder 10 años de nuestras vidas haciéndolo a mano", le respondió. Simon, Newell y Shaw tenían que mostrar sus resultados al mundo en algún lugar. Pero en aquel momento ni siquiera existía la disciplina en la que estaban trabajando, con lo que no había congreso, simposio o reunión anual de nada donde pudieran reunirse aquel grupo de jóvenes investigadores cuyo objetivo último era desplazar a los viejos investigadores que apenas entendían lo que estaban haciendo. La inteligencia artificial nació oficialmente como disciplina en una conferencia de ciencias de la computación creada para la ocasión en el Dartmouth College (New Hampshire, EEUU), en 1956. Los padres de este nuevo campo fueron John McCarthy, de la Universidad de Stanford; los propios Allen Newell y Herbert Simon, y Marvin Minsky. McCarthy no sólo es el responsable del nombre de la disciplina, de que una pléyade de entonces jóvenes investigadores se volcaran con ella o de la creación del primer laboratorio dedicado exclusivamente a ella en el MIT de Boston; él creo también el lenguaje de programación Lisp que se convirtió en el más usado en la época y que se continua utilizando en la detección del fraude bancario en internet o en la reserva de vuelos online, por ejemplo. Dio pie a tecnologías de reconocimiento de voz como Siri, el robot al que resuelve todo tipo de dudas a los usuarios del iPhone. Ya desde el inicio de la disciplina, McCarthy veía cercano el momento en el que la IA compartiese con el ser humano la capacidad del pensamiento: "Es un avance que llegará dentro de cinco a 500 años", repetía con humor.  Marvin Minsky, cofundador del Laboratorio de Inteligencia Artificial del MIT y uno de los principales teóricos de este campo de investigación, sin embargo llegó a afirmar que "en una generación, el problema de crear inteligencia artificial estaría básicamente resuelto". Esto lo decía, naturalmente, antes de vivir el largo invierno en el que se sumió esta disciplina científica en los años 70 y 80. Minsky trabajó buena parte de su carrera con fondos del ejército estadounidense. "Yo sólo me preocupaba de investigar, jamás supe lo que costaba lo que hacía ni tuve que rendir cuentas a nadie", comentaba a EL MUNDO pocos años antes de morir en el año 2016. De ahí su optimismo inicial. Minsky fue amigo íntimo y vecino, puerta con puerta, de Isaac Asimov, el conocido escritor de ciencia ficción: "Mi ciencia sigue a su ciencia ficción y no al revés", contaba Minsky, de quien el propio Asimov decía que era, junto con el astrofísico Carl Sagan, una de las dos únicas personas más inteligentes que él que había conocido en toda su vida. Pero su relación con la ciencia ficción fue más allá. Suyas son algunas de las ideas que hay detrás de las más conocidas referencias cinematográficas de la inteligencia artificial. Fue asesor de Stanley Kubrick para la creación del personaje robótico HAL 9000 en la realización de la película 2001: Una odisea del espacio (1968). Durante el rodaje estuvo a punto de ser aplastado por una pieza del decorado. Había pasado ya el largo invierno de la IA. Era el año 1997. Gary Kasparov jugaba con negras. Sólo habían pasado 62 minutos desde el comienzo de la partida y el campeón del mundo ya tenía suficiente. Era el movimiento 19, pero pensó que la máquina no haría el necesario sacrificio de un caballo. Se equivocaba y lo pagó. No lo podía creer, agitó su cabeza, se levantó y se rindió. Era la sexta partida del segundo enfrentamiento entre el mejor jugador de ajedrez del mundo y el superordenador Deep Blue. El primero de los enfrentamientos, jugado un año antes, se resolvió con la victoria de Kasparov. Pero las mejoras realizadas sobre la supercomputadora decantaron la partida de ajedrez más publicitada y más seguida de la historia del lado del superordenador diseñado por IBM. Era el 11 de mayo de 1997. Gary Kasparov nunca había perdido un enfrentamiento jugado a seis partidas y jamás había abandonado el tablero tan rápido. La relación entre seres humanos y máquinas no volvió a ser como antes. La considerada como la más espectacular partida de ajedrez de todos los tiempos no fue un gran hito en la historia de la inteligencia artificial, pero rescató todos los fantasmas que la ciencia ficción ha lanzado sobre la humanidad desde los años 50. La posibilidad de crear máquinas capaces de pensar por sí mismas y, por tanto, de rebelarse contra los seres humanos -personalizada en HAL 9000 desde 1968-, estaba cada vez más cerca. Deep Blue no tenía inteligencia artificial en sentido estricto. Se trataba de un sistema basado en el conocimiento humano y programado a mano para tomar decisiones que su programador sabía de antemano que tomaría. Pero eso ha cambiado recientemente con otro gran maestro del ajedrez: el AlphaZero, un sistema creado por Deep Mind, de Google. AlphaZero ha aprendido por sí mismo a jugar al ajedrez a alto nivel. La única información de origen humano con la que cuenta son las reglas básicas del ajedrez: que cada jugador juega con un color, los movimientos de las piezas y que cuando cae el rey acaba la partida, poco más. En apenas cuatro horas, jugando contra sí mismo y partiendo del mismo conocimiento que un niño que empieza a jugar al ajedrez, este sistema fue capaz de entrenar a la red neuronal artificial en la que se basa y de humillar al programa más sofisticado del mundo, el Stockfish 8 (diseñado durante 10 años por los algunos de los mejores ingenieros del mundo para jugar un ajedrez perfecto), en un duelo a 100 partidas. El sistema basado en la inteligencia humana no ganó ni una sola partida: 28 victorias de AlphaZero y 72 tablas. Sin embargo, los expertos creen que aún cabe esperar mucho más de la inteligencia artificial, esto es sólo el principio: "Es sin duda una contribución muy buena a la IA, pero no creo que nos acerque más hacia la consecución de inteligencia artificial de tipo general similar a la humana", opinaba Ramón López de Mántaras, director del Instituto de Investigación en Inteligencia Artificial del CSIC. "Si bien es cierto que sin modificar nada el sistema (estructura de la red, parámetros, etc.) aprendió a jugar a shogi después de haber aprendido a jugar al ajedrez, eso no es suficiente como para afirmar que sea una IA de tipo general, ya que de hecho ambos juegos tienen suficientes elementos comunes como para que el mismo algoritmo sirva para ambos", sentencia el experto.  Lo que seguro que no podían imaginar estos pioneros hace 60 años era que cualquiera podría tener en el bolsillo un aparato con bastante más capacidad que las superherramientas de sus laboratorios. Aquel dato tan repetido de que la capacidad de cualquiera de nuestros teléfonos móviles es superlativa si se compara al ordenador que llevó a los astronautas del Apolo 11 a pisar el suelo lunar. El salto de la IA en los últimos años se está dando gracias al usuario y a las empresas tecnológicas que gobiernan el gran negocio. Álvaro Gonzalo y Álvaro Mata, ambos de la empresa española Commons, uno físico y otro economista, aseguran que es el mercado el que ha ayudado en la evolución de estos sistemas. "Ahora las líneas son mucho más prácticas que en los orígenes y los objetivos más cortoplacistas, por lo que el impacto en la calle es mucho mayor y las tecnología más accesibles. Hoy es asequible que cualquier persona coja una parte específica de la IA y la aplique a un negocio concreto". Ellos se han especializado en bots (programas informáticos que permiten interactuar de una manera similar a la humana), lo que les ha servido para probar y valorar proyectos más ambiciosos que incluyan la voz. La superpotencia mundial de la IA sigue siendo EEUU, por el gran empuje de las grandes tecnológicas, aunque China se ha propuesto convertirse en la competencia. Pekín apuesta con importantes inversiones por el desarrollo de la IA y está fichando a muchos expertos que desarrollaban su trabajo en tierras americanas. En Europa destaca Reino Unido, aunque sus empresas las están comprando las grandes corporaciones de EEUU. Francia ha anunciado recientemente una inversión pública de 1.500 millones de euros en los próximos años en un plan que ha llamado IA para la Humanidad. El presidente francés, Emmanuel Macron, presentó la idea asegurando que este área supone una revolución económica, social, ética y política que "no se producirá en 30 años", sino que "se está produciendo ya". Nuria Oliver, que trabaja para una tecnológica, Vodafone, explica que las grandes empresas están contratando a los mejores expertos, muchos de los cuales abandonan sus clases y sus equipos de investigación de las universidades. "Hay un gran éxodo, no sólo por los atractivos salarios, sino también por la posibilidad de acceder a cantidades ingentes de datos, que son escasos en el contexto académico. Una de las preocupaciones es quién va a formar a las siguientes generaciones de expertos y expertas en este campo. Además, no es bueno para ningún campo de conocimiento que su progreso esté siendo desarrollado exclusivamente en un contexto industrial de empresas privadas, porque obviamente no son ONG".  Una realidad a la que José Luis Pons, responsable del grupo de neuro-rehabilitación del Instituto Cajal, dependiente del CSIC, y por tanto investigador público, ve aspectos positivos: "Uno de los motivos del boom actual de la IA y la robótica es que hayan entrado empresas muy potentes, como Amazon, Google o Microsoft; al final lo que estamos viendo es una colaboración público-privada". "Está claro que estas empresas invierten para generar negocio, pero si no hubieran dado ese paso, el desarrollo hubiese sido mucho más lento. Esto ha sido un revulsivo que ha hecho que más grupos se metan a trabajar en estos temas y que se apueste por nuevas aplicaciones". Pons recuerda que cuando hace más de 15 años en su grupo tuvieron que decidirse por una especialización, no dudaron ni un segundo en dedicarse a la salud y a la rehabilitación. Su objetivo es llegar a tener dispositivos que ayuden a las personas con daños neurológicos, como lesiones medulares, tetraplejias o Parkinson, de la misma forma que los marcapasos controlan el corazón de los enfermos coronarios. "El problema es mucho más complejo, porque el dispositivo tiene que entender qué es lo que quiere hacer la persona, si quiere rascarse o agarrar una botella. Sería un implante que podrá percibir qué está pasando con el paciente, lo interprete y reaccione para asistirle. Es muy complejo y creo que me jubilaré antes de conseguirlo", reconoce. "Hay tecnologías sorprendentes desde el punto de vista de clasificación de patrones, de solución de textos, de identificación de habla", continúa este físico, "pero todavía no me sorprende ningún comportamiento que sea fruto de la IA por especialmente inteligente. No, no creo que vayamos a ver ni replicantes al estilo Blade Runner ni a Terminator". Geoffrey Hinton no es un programador, un experto en construir complejos algoritmos de los que dirigen nuestra vida sin que apenas lo notemos desde Facebook o Google. Él es un entrenador. Claro que, para proponer los ejercicios a su pupilo, antes tiene que construirlo. El trabajo de este catedrático emérito en Ciencias de la Computación de la Universidad de Toronto e investigador en Ingeniería de Google se ha centrado desde hace décadas en construir máquinas que funcionen como el cerebro humano, conocido como deep learning. "Ya no se trata de programar a mano absolutamente todo lo que quieres que haga un ordenador. Es mejor que aprenda por sí mismo a partir de ejemplos", asegura. Y en esas está. De él han partido herramientas que ya forman parte de nuestro día a día como el reconocimiento de voz de nuestro teléfono móvil o los traductores online, y por ello fue merecedor del Premio Fundación BBVA Fronteras del Conocimiento en 2017. Desde su posición privilegiada de protagonista del avance de la inteligencia artificial vislumbra un futuro en el que la verdadera inteligencia vendrá de la unión del ser humano y las máquinas inteligentes.   No es difícil engañar al cerebro humano. Mediante ilusiones ópticas, la vista puede hacer que el cerebro interprete las cosas erróneamente. De la misma forma, modificaciones muy leves de una imagen original, de unos pocos píxeles, pueden engañar a una máquina y hacerle creer que un objeto representado es completamente distinto a la realidad. Y resulta mucho más fácil engañar a una máquina que a un humano. Así lo asegura el ingeniero Luis Muñoz González, cuyo trabajo en el Imperial College de Londres consiste precisamente en descubrir los puntos débiles de los sistemas de Inteligencia Artificial (IA) para hacerlos más seguros y prevenir ataques. Su campo se llama Adversarial machine learning y, según explica, "es una intersección del machine learning (aprendizaje de máquinas) y la seguridad". Nació hace una década con el auge de la IA, que se ha convertido en el componente clave de muchos sistemas: "Por un lado, tratamos de diseñar ataques sofisticados que sean capaces de comprometer estos sistemas de IA, no sólo para mostrar su vulnerabilidad sino para tratar de proponer mejores sistemas de defensa", relata Muñoz, investigador del grupo Resilient Information Systems Security ( RISS ) del Departamento de Computación del Imperial College. "Es necesario que nos adelantemos y que seamos capaces de comprender las vulnerabilidades de estos sistemas y las peores situaciones que se pueden dar. Por otro lado, está la investigación sobre los mecanismos de defensa para mitigar esos ataques", dice este ingeniero salmantino afincado en Reino Unido desde hace tres años y medio. Un ejemplo de que el aprendizaje de máquinas es un proceso vulnerable que hace que los sistemas se comporten a veces de forma imprevista es el chatbot  Tay , diseñado por Microsoft para interactuar con jóvenes en Twitter imitando su lenguaje y aprendiendo de sus intercambios con ellos. Aunque al inicio reproducía la jerga y las expresiones utilizadas por ellos, apenas 16 horas después de su debut la compañía interrumpió su servicio: Tay estaba escribiendo tuits racistas y sexistas porque algunos usuarios habían colgado mensajes ofensivos, que habían envenenado los datos usados por este sistema de IA para actualizar el entrenamiento previo. Pero la vulnerabilidad de los algoritmos, de los que dependen ya numerosos componentes y servicios, es una oportunidad para que los cibercriminales lleven a cabo actividades ilícitas y lucrativas. Así, durante el último año se han producido varios ataques de malware, un programa o software malicioso que intenta infiltrarse o dañar un ordenador o un sistema: "Encripta los ficheros y te pide una recompensa. Se está empezando a usar la IA como un arma para desarrollar malware que sea indetectable, ataques más sofisticados. Básicamente, lo que se hace es buscar los puntos ciegos o débiles del sistema para tratar que cometa un error, que no te detecte como malware, sino que piense que eres una herramienta normal, software no malicioso, explica. Existen varios tipos de ataques. Los denominados de caja blanca son ejecutados por personas que conocen el algoritmo. En los de caja negra, el atacante no sabe nada del sistema: "En la práctica tenemos una situación intermedia, en la que el atacante puede conocer partes del sistema o de la información. En cualquier caso la posibilidad del ataque está ahí. Y en ciertos casos es relativamente sencillo atacar o producir errores en un sistema de IA", asegura. Y es que, "no hay sistemas blindados. Los ataques están a la orden del día pese al dinero que se invierte y defenderse de ellos sigue siendo un tema de investigación abierto. Es una lucha constante". En los últimos dos o tres años, el interés y la preocupación por este problema está creciendo enormemente, especialmente en EEUU. "En Europa empezamos a tener también grupos interesados porque realmente es un aspecto que puede limitar el desarrollo y la penetración de estas tecnologías en todos los ámbitos de aplicación", señala. El ingeniero considera que "ha habido una explosión de este tipo de sistemas, sobre todo desde el desarrollo de ciertos algoritmos de Deep learning o aprendizaje profundo que han mostrado unas prestaciones muy buenas para resolver determinados tipos de tareas". Si lo juntamos con el desarrollo de las tecnologías de big data y la gran cantidad de datos recogidos por sensores, dispositivos y personas, tenemos la explicación para la expansión de la IA. Muñoz admite que "hay una cierta burbuja, pero son innegables las capacidades y las ventajas que están ofreciendo este tipo de sistemas, aunque a su vez plantean nuevos retos que requieren su análisis e investigación. Uno de ellos es la seguridad, pero hay otros que resultan bastante llamativos como el de la justicia". En efecto, los algoritmos de IA aprenden a partir de los datos que nosotros les proporcionamos. Pero esos datos están tan sesgados como los humanos: "Tenemos prejuicios y los algoritmos de IA los reflejan. Por ejemplo, pueden reflejar discriminación por sexo o por raza. Uno de los retos es cómo eliminar esos sesgos y lograr algoritmos más justos". En EEUU el sistema judicial de varios estados está empezando a emplear sistemas automáticos, como el algoritmo Compas, para evaluar el riesgo de reincidencia de la población reclusa de cara a dar permisos penitenciarios o decretar la libertad condicional. El objetivo es agilizar el proceso y ayudar a los jueces a tomar la decisión basándose en datos más objetivos pero como señala Muñoz, "se está viendo que esos sistemas discriminan por la raza, y eso es algo indeseable. Aprenden a partir de los ejemplos que le das, como un niño". Varios estudios e informes han puesto en entredicho la capacidad de Compas para prever el comportamiento de un recluso. Por ejemplo, un estudio publicado en la revista Science Advances concluyó que no había diferencias significativas entre las predicciones del algoritmos y las de los participantes en una encuesta online sin ninguna preparación o entrenamiento previo- sobre la probabilidad de que los presos pudieran reincidir. Los algoritmos de búsqueda de imágenes de Google, recuerda el ingeniero, también presentan ciertas limitaciones (con connotaciones raciales) como reflejan algunos errores cometidos por ellos. Un desarrollador de software negro sacó los colores a Google en 2015 al revelar a través de Twitter que el servicio de fotos de la compañía había etiquetado fotos de él con un amigo como gorilas, un error por el que la empresa se disculpó. El otro gran desafío, según Muñoz, es el de la responsabilidad porque, "al igual que las personas, los sistemas de IA cometen errores, no son perfectos. Y cuando se comete un error hay que encontrar la fuente para intentar subsanarlo". Los algoritmos, añade, deben proporcionar explicaciones sobre las decisiones que tomen. "Por ejemplo, si pides una hipoteca y el banco no te la da basándose en su sistema de IA, necesitarás saber por qué. Es otro de los campos que está en desarrollo. Son aspectos que realmente se necesitan para que la IA funcione y pueda aplicarse en muchos ámbitos de la sociedad".  Pasa más tiempo de lo que cree con Greg Corrado y sus compañeros. No en sentido literal, evidentemente, pero ellos están detrás de muchas de las herramientas de Google que cualquiera utiliza a diario. Corrado, neurocientífico computacional, nos habla de la deseable relación natural que debe buscarse entre hombres y máquinas desde el cuartel general de la compañía en Mountain View, en California. Corrado es uno de los fundadores de Google Brain, el proyecto de investigación sobre inteligencia artificial de esta empresa tecnológica centrado en el deep learning o aprendizaje profundo. Cuando crearon este departamento en 2011, no sabían si llegaría a tener una aplicación práctica. Pero hoy se puede ver el fruto de su trabajo en herramientas como su popular buscador, el traductor o las respuestas automáticas que ofrece el servicio de correo Gmail que se asemejan a las que daría una persona. Pesa cinco kilos, tiene el tamaño de una pelota grande, vuela de forma autónoma y este verano comenzará a hacer prácticas como astronauta. Hablamos de CIMON, el primer robot con inteligencia artificial que viajará al espacio. El próximo junio será enviado a la Estación Espacial Internacional (ISS), donde se estrenará como ayudante del alemán Alexander Gerst, astronauta de la Agencia Espacial Europea (ESA). Desarrollado por el Centro Aeroespacial de Alemania (DLR, por sus siglas en alemán) en estrecha colaboración con varias empresas. CIMON (de Crew Interactive Mobile Companion) puede ver, oír, hablar y entender. También es capaz de aprender, pero no de forma autónoma. Un humano tiene que enseñarle. Según explica Till Eisenberg, jefe del proyecto CIMON en Airbus, la compañía que lo ha diseñado y construido, este ingenio robótico de forma casi esférica ha sido concebido para ayudar a la tripulación a realizar sus tareas y reducir sus niveles de estrés. "Se mueve a una velocidad de un metro por segundo, que es bastante lento pero comparable a la del movimiento normal de un miembro de la tripulación", añade el ingeniero. El objetivo de este experimento será testar por primera vez cómo cooperan los humanos con máquinas inteligentes. Por ejemplo, CIMON permitirá que los astronautas tengan las manos libres mientras realizan sus procedimientos o llevan a cabo reparaciones de componentes. En lugar de consultar un ordenador, podrán pedirle que les muestre o lea los documentos o instrucciones que necesiten. Según explica en un comunicado Christian Karrasch, jefe del projecto CIMON en el Centro Aeroespacial Alemán, usaron la tecnología de impresión 3D durante todo el proceso de fabricación de la estructura, compuesta de metal y plástico. Los trabajos comenzaron en 2016. "Hemos implementado este experimento en muy poco tiempo. Pretendemos que muestre hasta qué punto se puede ayudar a los astronautas en los trabajos que realizan en el módulo Columbus de la ISS y liberarles, sobre todo, de las tareas rutinarias. Idealmente, los astronautas podrán usar su tiempo mejor y de una forma más eficaz", asegura. En 2011, Robonauta (R2) se convirtió en el primer robot humanoide en viajar al espacio. La cabeza y el torso de este androide de la NASA estaban llenos de sensores, procesadores y potentes cámaras, pero no estaba dotado de inteligencia artificial. El aspecto de CIMON es bastante diferente. No es un robot humanoide, pero sí tiene una cara humana. Sus 32 centímetros de diámetro le permiten llevar incorporada una pantalla de ocho pulgadas, lo suficientemente grande como para mostrar un rostro completo, un elemento importante desde el punto de vista psicológico, ya que una de sus funciones será hacer compañía a los astronautas. Su boca es un altavoz que puede usar para hablar o poner música y cuenta con siete micrófonos que le permiten oír y detectar de dónde vienen los sonidos. Sus ojos son dos cámaras y lleva varias más que le permiten, entre otras funciones, reconocer las caras de los tripulantes y grabar para documentar lo que allí ocurre. Asimismo, CIMON cuenta con sensores para medir las distancias y evitar chocar con objetos, paredes o personas. El robot lleva incorporado el sistema de IA Watson, desarrollado por la compañía IBM, que le permite hablar y aprender, mientras que investigadores del Hospital Universitario Ludwig-Maximilian de Múnich supervisan los aspectos relacionados con el sistema de asistencia. "Nuestros estudios muestran que estar expuesto a la microgravedad durante un tiempo puede afectar significativamente al sistema inmune de un astronauta. El estrés es uno de los principales factores. Como compañero y ayudante, CIMON podría ayudar a los tripulantes con sus experimentos y tareas de mantenimiento, reduciendo su exposición al estrés", asegura Judith-Irina Buchheim, del Hospital Ludwig-Maximilian. Y es que las tareas extenuantes suelen ser menos difíciles si se hacen en compañía. Por otro lado, sistemas como CIMON tienen un gran potencial de aplicaciones en la Tierra. Además de ayudar a ingenieros, médicos o investigadores a realizar su trabajo, pueden trabajar como asistentes de personas ancianas o enfermas. Volviendo al espacio, los sistemas de IA podrían resultar especialmente útiles en futuras misiones de larga duración. Por ejemplo, contribuirían a solucionar los problemas técnicos que aparecieran en un viaje tan largo y complejo como será una expedición a Marte, o mediar en los conflictos que surgiesen entre los tripulantes, recluidos en una nave espacial durante muchos meses. Pero algunos científicos, como el astrofísico británico Martin Rees, de la Universidad de Cambridge, van más allá y consideran que la única forma de explorar planetas fuera del Sistema Solar (exoplanetas) será enviando sistemas de IA capaces de superar los límites físicos de los humanos. Ninguna persona viviría lo suficiente como para viajar durante siglos o milenios para comprobar si alguno de los exoplanetas que reúnen las condiciones para tener vida albergan algún organismo. Álvaro Giménez Cañete, profesor de investigación del CSIC y ex director de Ciencia y Robótica de la Agencia Espacial Europea (ESA), cree que "la exploración del Sistema Solar, tanto de planetas como de lunas alrededor de ellos", se hará fundamentalmente con misiones robóticas. "La llegada a Marte requiere solventar problemas serios como el efecto de la radiación en la salud, y no creo que sea posible antes de unos 20 años. Las misiones robóticas, sin embargo, pueden llegar sin problemas y preparar el acceso humano". "La eficacia de estas misiones se verá muy beneficiada por robots que incorporen IA para desarrollar sus actividades, tanto durante el viaje como en la superficie del planeta. Lo mismo será válido para mundos más alejados, especialmente las apasionantes lunas de los planetas gigantes. Así será posible la toma de decisiones de forma autónoma, sin el problema del retraso en la comunicación con la Tierra. Posteriormente, cuando sean posibles las misiones de exploración humana, los equipos dotados de inteligencia artificial serán imprescindibles como acompañantes, permitiendo la optimización de las tareas a desarrollar por los astronautas", describe el astrofísico. Según detalla, "la ESA no desarrolla directamente proyectos de inteligencia artificial, pero los promociona haciendo estudios preparatorios, llamadas de interés a grupos de investigación en los países miembros y haciéndose eco o probando desarrollos realizados por las agencias nacionales". El astronauta Pedro Duque, por su parte, se muestra cauto a la hora de valorar el potencial de estos sistemas en la exploración espacial pues, "de momento, los sistemas de IA se dedican a determinadas tareas" y "no se vislumbra la aparición aún de sistemas en los que podamos confiar como lo hacemos con los humanos. Antes de usar sistemas que tengan implicaciones en seguridad tenemos que hacer múltiples ensayos en condiciones reales". Como ejemplo, pone los ensayos que desde hace muchos años se están realizando con los sistemas de conducción automática de coches: "Cuanto más complejas son las condiciones, hacen falta más ensayos en los que el sistema funcione bajo supervisión de alguna persona especialista", señala. Del mismo modo, Duque, que ha viajado dos veces al espacio, cree que "la exploración de cuerpos celestes seguramente se iniciará con astronautas que llevarán algún sistema de IA en pruebas y, al cabo de muchos viajes, quizá estemos en condiciones de dejarlos solos, ¿por qué no?", reflexiona. Como astronauta, ¿qué le parecería tener un compañero como CIMON? "Es un primer paso en el que la IA se utiliza únicamente para descifrar comandos en lenguaje natural. Seguramente conseguiremos en el futuro muchísima mayor capacidad de proceso local, y podremos añadir interacción real y más conversación, como tenía HAL 9000", señala en referencia a la supercomputadora de 2001: Una odisea del espacio.  "En este sentido, lo que realmente ayudaría sería tener sistemas inteligentes con acceso a los comandos y sensores de la nave, como en las películas. Por ejemplo, decir: 'HAL, cierra la escotilla', y que HAL la cierre, compruebe la estanqueidad, reporte en caso de fallo y, de paso, sea capaz de avisarte si no conviene cerrarla", dice Duque, que asegura que, por ahora, prefiere seguir teniendo colegas de carne y hueso haciendo las tareas más importantes. "De momento, prefiero cerrarme la escotilla yo o que lo haga un compañero profesional, si la vida me va a ir en ello. Ya vimos cómo acabó lo de HAL". Coordinación: Virginia Hernández. Responsable EL MUNDO Lab: Sergio Rodríguez. Redacción: Teresa Guerrero, Virginia Hernández, Miguel G. Corral, Carlos Fresneda, Rebeca Yanke, Laura Tardón, Cristina G. Lucio, Mar de Miguel, Carmen Valero e Isabel Munera. Vídeos: Nacho Moreno. Locuciones: Maite Vaquero Podcast: Virginia Hernández, Nacho Moreno, Maite Vaquero y Adrián Portellano. Infografías: Isabel González. Ilustración: Akirant | Ulises Diseño y maquetación: Antonio Pedro Germán