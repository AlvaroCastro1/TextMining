Título: El derecho de protecciÃ³n de datos personales en los sistemas de inteligencia artificial
URL: http://www.scielo.org.mx/scielo.php?script=sci_arttext&pid=S1870-21472021000200179
Número de palabras: 11949



 ArtÃ­culos de InvestigaciÃ³n El derecho de protecciÃ³n de datos personales en los sistemas de inteligencia artificial The personal data protection right in artificial intelligence systems Olivia AndreaÂ Mendoza EnrÃ­quez*Â 
			http://orcid.org/0000-0002-4704-740X *Profesora investigadora en la DivisiÃ³n de Estudios JurÃ­dicos del Centro de InvestigaciÃ³n y Docencia EconÃ³micas, MÃ©xico. (andrea.mendoza@cide.edu)    Resumen: El objetivo del documento es analizar la inteligencia artificial (IA) desde la visiÃ³n del derecho de protecciÃ³n de datos personales con el fin de identificar los desafÃ­os que existen para la salvaguarda de este derecho humano. La aportaciÃ³n se desarrolla a partir de una revisiÃ³n documental que establece el estado de la cuestiÃ³n, describe la forma en la que incide la IA en el derecho a la privacidad especialmente en el de protecciÃ³n de datos personales, identifica los desafÃ­os normativos en esta materia y posibles soluciones que involucran a los actores que intervienen en los sistemas de inteligencia artificial, particularmente los Estados. Palabras clave:Â Inteligencia artificial; regulaciÃ³n; derechos humanos; derecho a la privacidad; derecho de protecciÃ³n de datos personales Abstract:  The objective of the document is the analysis of artificial intelligence from data protection right perspective to identify the challenges for the safeguarding of this human right. The contribution is developed from a documentary review that establishes the actual context, describes how artificial intelligence could affect the right to privacy, especially data protection right and identifies the regulatory challenges in this matter and possible solutions that involve artificial intelligence actors, particularly States. Keywords:Â Artificial intelligence; regulation; human rights; right to privacy; data protection right Sumario: 


IntroducciÃ³n.
Concepto de inteligencia artificial y usos en la economÃ­a digital.
ConfiguraciÃ³n del derecho de protecciÃ³n de datos personales como derecho humano y sus implicaciones en la inteligencia artificial.
Inteligencia artificial y derecho a la privacidad.
Inteligencia artificial y protecciÃ³n de datos personales en MÃ©xico.
Conclusiones.


 IntroducciÃ³n. Concepto de inteligencia artificial y usos en la economÃ­a digital. ConfiguraciÃ³n del derecho de protecciÃ³n de datos personales como derecho humano y sus implicaciones en la inteligencia artificial. Inteligencia artificial y derecho a la privacidad. Inteligencia artificial y protecciÃ³n de datos personales en MÃ©xico. Conclusiones. 1. IntroducciÃ³n El vertiginoso desarrollo tecnolÃ³gico ha permitido que las organizaciones utilicen cada vez mÃ¡s tÃ©cnicas como la inteligencia artificial, a fin de hacer mÃ¡s eficientes los procesos y la toma de decisiones. Los usos de la IA son tan variados que pueden ser incorporados en sectores desde la agricultura hasta medios de transporte, por lo que tienen una incidencia en todos los espacios de la sociedad. Los usuarios digitales tambiÃ©n encuentran en la IA una oportunidad para el procesamiento de informaciÃ³n, por ejemplo, relativa a su estado de salud, preferencias comerciales, o simplemente para buscar informaciÃ³n en el ciberespacio. Estos beneficios son posibles a partir del anÃ¡lisis masivo y sistemÃ¡tico de la informaciÃ³n, que incluye casi siempre, datos personales que identifican o hacen identificables a los humanos.1
 Derivado de lo anterior, existe una constante preocupaciÃ³n respecto del uso masivo de sistemas de IA que para su funcionamiento requieran de informaciÃ³n que identifique o haga identificable a la persona detrÃ¡s del dato. Esto frente a prÃ¡cticas como los tratamientos indebidos de datos (falta de cumplimiento normativo o de incorporaciÃ³n de lÃ­mites Ã©ticos), la falta de medidas de seguridad o errores en el diseÃ±o de la tÃ©cnica, que podrÃ­an traer consigo la violaciÃ³n de derechos humanos: desde el derecho a la vida, el derecho a la no discriminaciÃ³n, el derecho a la salud, hasta el derecho a la privacidad y a la protecciÃ³n de datos personales, por enunciar algunos. Por otro lado, cuando estamos ante tratamientos de informaciÃ³n que contienen datos personales a travÃ©s de sistemas de inteligencia artificial, ya existe un marco normativo transversal de Ã­ndole local y en algunos casos regional o internacional, sobre todo en materia de protecciÃ³n de datos personales, por lo que la hipÃ³tesis central de este documento es que el desafÃ­o del derecho de protecciÃ³n de los datos personales en la IA no es del todo normativo (como podrÃ­a pensarse), sino de mecanismos que permitan el efectivo ejercicio y garantÃ­a de los derechos humanos por parte de los actores involucrados en la IA (desarrolladores, corporaciones y usuarios). TambiÃ©n resulta pertinente analizar si el marco legal de los derechos humanos, en especÃ­fico el de protecciÃ³n de datos personales permite proteger a la persona frente a tÃ©cnicas como la inteligencia artificial, a fin de lograr un correcto balance entre innovaciÃ³n y dignidad de la persona. El lector encontrarÃ¡ en las siguientes lÃ­neas una aproximaciÃ³n conceptual de la IA y algunos de sus usos en la economÃ­a digital, la forma en la que el derecho de protecciÃ³n de datos personales se ha configurado como un derecho humano, un estudio sobre el derecho a la privacidad y el de protecciÃ³n de datos personales en la IA y un apartado de conclusiones. 2. Concepto de inteligencia artificial y usos en la economÃ­a digital Como ha quedado establecido, el tÃ©rmino âinteligencia artificialâ aparece desde los aÃ±os 50 en algunas investigaciones de ciencias de la computaciÃ³n. El concepto fue utilizado por primera vez en 1955 en el proyecto de investigaciÃ³n de John McCarthy, Marvin L. Minsky, Nathaniel Rochester, y Claude Shannon.2
 TambiÃ©n el tÃ©rmino de IA en la dimensiÃ³n atribuida por la informÃ¡tica ha sido explorado por la ciencia jurÃ­dica desde 1960. Los primeros documentos jurÃ­dicos que hablan de inteligencia artificial lo hacen para referirse a la transcripciÃ³n de medios de prueba en una forma legible por computadoras para 181 obtener un procesamiento eficiente de la informaciÃ³n,3 asÃ­ como para procesar la informaciÃ³n proporcionada por un cliente a un abogado y determinar la probabilidad de ganar un caso, la cantidad estimada de daÃ±os si los hubiere, el anÃ¡lisis de la legislaciÃ³n legal, asÃ­ como la jurisprudencia.4
 En recientes fechas, el Grupo de Alto Nivel en IA creado por la ComisiÃ³n Europea para desarrollar la Estrategia Europea en Inteligencia Artificial, ha aplicado el concepto de IA a âsistemas que manifiestan un comportamiento inteligente, al ser capaces de analizar el entorno y realizar acciones, con cierto grado de autonomÃ­a, con el fin de alcanzar objetivos especÃ­ficosâ.5
 Desde una perspectiva tÃ©cnica, entonces podemos afirmar que el tÃ©rmino IA se usa en general para referir la capacidad de una mÃ¡quina para imitar las funciones cognitivas de los humanos; sin embargo, nos encontramos tambiÃ©n frente nuevas ramas que derivan del concepto de inteligencia artificial, tales como el aprendizaje de las mÃ¡quinas (machine learning), en el cual, los sistemas aprenden a partir de ejemplos, pruebas o de la informaciÃ³n y comportamiento de usuarios de dicho sistema, y los modelos de redes neuronales,6 por lo que el alcance del concepto de IA irÃ¡ evolucionado a la par de los avances tecnolÃ³gicos en la materia. Una vez que hemos dado una aproximaciÃ³n conceptual a la inteligencia artificial, resulta necesario hablar de algunos de sus usos en la economÃ­a digital para identificar las intersecciones especÃ­ficas con el derecho de protecciÃ³n de datos personales. De acuerdo al Libro Blanco sobre la IA-un enfoque europeo orientado a la excelencia y la confianza-, el impacto derivado de los usos de los sistemas de IA debe considerarse no solo desde una perspectiva individual, sino tambiÃ©n desde la perspectiva de la sociedad en su conjunto y que el uso de sistemas de IA puede tener un papel importante en la consecuciÃ³n de los Objetivos de Desarrollo Sostenible y en el respaldo de los procesos democrÃ¡ticos y los derechos sociales.7
 Esto resulta importante porque el uso de sistemas de IA no solo beneficia a la persona en lo individual, sino que tiene un impacto social, en los derechos humanos e incluso en las democracias. Es por esta razÃ³n que algunos paÃ­ses desarrollados ya han advertido el impacto favorable que tendrÃ­a la incorporaciÃ³n de sistemas de inteligencia artificial, por lo que han dedicado planes y polÃ­tica pÃºblica para el desarrollo de dicha innovaciÃ³n. Para tener una idea del alcance que se tiene proyectado para la inteligencia artificial, globalmente, Europa se sitÃºa a la zaga en inversiones privadas en IA, las cuales oscilaron entre 2 400 y 3 200 millones EUR en 2016, frente a 6 500-9 700 millones EUR en Asia y 12 100-18 600 millones EUR en AmÃ©rica del Norte.8
 En el mismo sentido, resulta necesario analizar que el trÃ¡fico mundial a travÃ©s del Protocolo de Internet (IP) pasÃ³ de unos 100 gigabytes (GB) al dÃ­a en 1992, a mÃ¡s de 45.000 GB por segundo en 2017, debiendo considerarse que el mundo solo se encuentra en los principios de la economÃ­a basada en datos y que las predicciones son que para 2022 el trÃ¡fico IP mundial alcance los 150.700 GB por segundo, alimentado por un nÃºmero cada vez mayor de personas que se conectan por primera vez y por la expansiÃ³n de Internet de las Cosas (que funciona con sistemas de inteligencia artificial).9
 El tipo de IA que ha disparado la aplicaciÃ³n prÃ¡ctica de esta disciplina es la que se conoce como IA-dÃ©bil10 que se caracteriza por desarrollar soluciones capaces de resolver un problema concreto y acotado. La aplicaciÃ³n de este tipo de sistemas es extensa: desde los videojuegos a sistemas de defensa, pasando por entorno sanitario, control industrial, robÃ³tica, buscadores de Internet, tratamiento de lenguaje natural, marketing, asistentes personales, recursos humanos, optimizaciÃ³n de servicios pÃºblicos, gestiÃ³n energÃ©tica, medioambiente y cualquier otra actividad que nos podamos imaginar.11
 Por citar algunos ejemplos, en Dinamarca, la IA ayuda a salvar vidas al permitir a los servicios de emergencias diagnosticar paradas cardÃ­acas u otras dolencias analizando la voz de la persona que llama. En Austria, ayuda a los radiÃ³logos a detectar tumores con mayor precisiÃ³n, al facilitarles la comparaciÃ³n instantÃ¡nea de las radiografÃ­as con una gran cantidad de otros datos mÃ©dicos. Muchas explotaciones agrarias de toda Europa ya estÃ¡n utilizando la IA para controlar los desplazamientos, la temperatura y el consumo de los animales. La IA tambiÃ©n estÃ¡ contribuyendo a que el sector industrial europeo resulte mÃ¡s eficiente y a que la fabricaciÃ³n vuelva a Europa.12
 Es fÃ¡cil entonces, identificar los enormes beneficios que traen consigo los sistemas de inteligencia artificial, pero no se puede obviar una constante preocupaciÃ³n especÃ­ficamente cuando el insumo de la IA que es la informaciÃ³n, contiene datos personales, ya que al ser sistemas que se incorporan en la vida diaria y que recopilan todo tipo de informaciÃ³n, pueden tener un impacto considerable a Ã¡mbitos privados de las personas, por lo que resulta necesario establecer los lÃ­mites para el tratamiento de la informaciÃ³n y en general, salvaguardar la vida privada de las personas, aÃºn con la utilizaciÃ³n de sistemas de inteligencia artificial, por lo que en el apartado cinco, analizaremos algunas de las disposiciones normativas que establecen reglas para el tratamiento de datos en sistemas de inteligencia artificial. 3. ConfiguraciÃ³n del derecho de protecciÃ³n de datos personales como un derecho humano y sus implicaciones en la inteligencia artificial Cuando se habla del derecho de protecciÃ³n de datos personales es usual pensar que es un derecho nuevo que nace a partir de la economÃ­a digital, del uso de Internet y del vertiginoso desarrollo de las TecnologÃ­as de la InformaciÃ³n y ComunicaciÃ³n. No obstante, si bien es un derecho de reciente reconocimiento en la ConstituciÃ³n PolÃ­tica de los Estados Unidos Mexicanos (2009), tiene antecedentes importantes en la Ã©poca de posguerra en Europa. Pensemos asÃ­ en una Alemania nazi que tratÃ³ los datos de miles de judÃ­os a travÃ©s de un censo realizado por el Estado, con la ayuda de las tarjetas perforadas de la empresa IMB, con el objetivo de identificar a esta poblaciÃ³n y planear su exterminio de forma mÃ¡s efectiva.13
 A partir de atrocidades como Ã©stas, se volviÃ³ evidente la necesidad de establecer lÃ­mites del Estado frente a la vida privada de las personas y ejemplo de ello estÃ¡ manifestado en el artÃ­culo 12 de la DeclaraciÃ³n Universal de Derechos Humanos, -en adelante DUDH-. Antes de analizar este artÃ­culo, es pertinente dar un contexto sobre la necesidad histÃ³rica de reconocer en instrumentos internacionales un concepto tan importante como la dignidad humana, que hasta el dÃ­a de hoy, es sustento de los instrumentos jurÃ­dicos en materia de derechos humanos. Es decir, a partir de las atrocidades cometidas durante la Segunda Guerra Mundial, paÃ­ses ganadores y vencidos encontraron esencial reconocer derechos mÃ­nimos a las personas, en una invocaciÃ³n inÃ©dita a la dignidad humana. Es asÃ­, que la manifestaciÃ³n del lÃ­mite del Estado respecto de la vida privada de las personas estÃ¡ plasmado en el citado artÃ­culo 12 de la DUDH, el cual seÃ±ala: Nadie serÃ¡ objeto de injerencias arbitrarias en su vida privada, su familia, su domicilio o su correspondencia, ni de ataques a su honra o a su reputaciÃ³n. Toda persona tiene derecho a la protecciÃ³n de la ley contra tales injerencias o ataques. Como se puede advertir, este artÃ­culo no reconoce de forma expresa el derecho de protecciÃ³n de datos personales, pero sÃ­ es un antecedente importante para la evoluciÃ³n normativa manifestada a travÃ©s de nuevos derechos como el de protecciÃ³n de datos personales. Aunado a la DUDH, existen otros instrumentos internacionales en materia de derechos humanos que reconocen lÃ­mites del Estado frente a la vida privada de las personas, como el artÃ­culo 11 de la ConvenciÃ³n Americana de Derechos Humanos14 (Pacto de San JosÃ© de Costa Rica), de 1966, el artÃ­culo 17 del Pacto Internacional de Derechos Civiles y PolÃ­ticos15 de 19 de diciembre del mismo aÃ±o 1966, el artÃ­culo 8 del Convenio Europeo de Derechos Humanos16 de 4 de noviembre de 1950 son ejemplo de ello; asimismo, la Carta de los Derechos Fundamentales de la UniÃ³n Europea suscrita en Niza el 7 de diciembre de 2000. Desde el derecho continental, un paso importante para el derecho de protecciÃ³n de datos personales se reconoce cuando el Tribunal Constitucional Federal AlemÃ¡n, en la sentencia de 15 de diciembre de 1983 sobre el Censo, completÃ³ los derechos constitucionales de la personalidad, sobre la base del derecho a la dignidad humana y al libre desarrollo de la personalidad, lo cual garantizÃ³ la continuidad de las libertades bÃ¡sicas reconocidas anteriormente, a travÃ©s de la formulaciÃ³n de un nuevo derecho denominado autodeterminaciÃ³n informativa. Este derecho reconoce la facultad de las personas para decidir sobre el tratamiento de sus datos personales y asÃ­ garantizar derechos conexos como el derecho a la no discriminaciÃ³n y al libre desarrollo de la personalidad.17
 En este sentido, el reconocimiento de la dignidad humana resulta el sustento del derecho al libre desarrollo de la persona que es la esencia y fundamento del derecho a la identidad, el de imagen y el de datos personales, a fin de no instrumentalizar a la persona humana. Esto en concordancia con la fÃ³rmula del objeto de Kant (objekt formel)18 y su aplicaciÃ³n a este caso: la persona es el fin mÃ¡s no el instrumento (la persona no puede ser tratada como el medio porque no es un objeto en el mercado con un valor determinado). En otras palabras, la IA tendrÃ­a que ser desarrollada para mejor la vida de los humanos y no para utilizarlos, por ejemplo, a travÃ©s de tratamientos de datos personales que vulneren derechos como la no discriminaciÃ³n, la privacidad, la protecciÃ³n de datos personales o incluso el derecho a la vida. Determinar el alcance del derecho humano a la protecciÃ³n de datos personales no es tarea sencilla ya que, al tratarse de un derecho humano, es susceptible de colisionar con otros derechos, por ejemplo, el de la libertad de expresiÃ³n, por lo que la ponderaciÃ³n de derechos de forma casuÃ­stica permite a los tribunales establecer los parÃ¡metros del derecho de protecciÃ³n de datos personales en el marco de una sociedad democrÃ¡tica. El reconocimiento que ha hecho MÃ©xico del derecho de protecciÃ³n de datos personales como un derecho humano tiene interesantes consecuencias ya que derivado de la reforma constitucional en materia de derechos humanos de 2011, el estado mexicano se ve comprometido a salvaguardar y promover este derecho e incluso, la aplicaciÃ³n de principios como el de progresividad de los derechos humanos, compromete a MÃ©xico a evolucionar normativamente en favor de este derecho. No obstante lo anterior, para el estado mexicano la salvaguarda del derecho de protecciÃ³n de datos personales en el Ã¡mbito tecnolÃ³gico resulta bastante compleja. Esto atendiendo a que se ha depositado una enorme responsabilidad en las corporaciones para que sean Ã©stas las que decidan los tÃ©rminos y condiciones en los que garantizarÃ¡n los derechos humanos. Es decir, espacios ubicuos como Internet o un sistema de inteligencia artificial, hacen inminente la reducciÃ³n de la figura tradicional de Estado-NaciÃ³n, cuando se trata de garantizar y promover los derechos humanos, ya que estas acciones quedan mayormente en manos de las corporaciones. Pensemos, por ejemplo, si las polÃ­ticas de privacidad de una cuenta o perfil en una red social estÃ¡n redactadas en tÃ©rminos de la mÃ¡xima protecciÃ³n que reconoce la norma mexicana para el tratamiento de datos personales, particularmente en tÃ©rminos del ejercicio del derecho de cancelaciÃ³n u oposiciÃ³n para el tratamiento de datos personales, o de la jurisdicciÃ³n que reconoce la red social para resolver posibles disputas. Ante este panorama, cada vez se vuelve mÃ¡s necesario incorporar el principio de escrutinio de los derechos humanos como habilitador para el Estado de un mecanismo efectivo para la supervisiÃ³n, garantÃ­a y ejercicio de los derechos humanos a la luz del desarrollo tecnolÃ³gico. En este sentido, un caso interesante sobre desarrollo de instrumentos de control estatal que permite la salvaguarda de los derechos humanos en la inteligencia artificial, es el Consejo de la UniÃ³n Europea que presentÃ³ en febrero de 2019 unas conclusiones relativas al Plan Coordinado sobre la IA âMade in Europeâ, entre las que destaca la importancia de garantizar el pleno respeto de los derechos de los ciudadanos mediante la aplicaciÃ³n de directrices Ã©ticas para el desarrollo y uso de la inteligencia artificial.19
 Dicho esto, podemos afirmar que, en la mayorÃ­a de las legislaciones, se reconoce un catÃ¡logo de derechos humanos que pueden verse afectados con la instrumentaciÃ³n de la IA sin lÃ­mites Ã©ticos, jurÃ­dicos y sociales Desde del derecho pÃºblico, particularmente para el caso de MÃ©xico, tambiÃ©n podemos plantear la siguiente interrogante: Â¿los Estados deben impulsar e incidir en la transparencia en el desarrollo de algoritmos y sistemas de funcionamiento general de la inteligencia artificial? El planteamiento con miras a hacer posible que la autoridad tenga claros los temas de vigilancia y cumplimiento que deben seguir las corporaciones, respecto de la explotaciÃ³n de la informaciÃ³n. Ante tal panorama, el derecho humano de protecciÃ³n de datos personales tiene retos complejos que superar frente la inteligencia artificial, los cuales radican primordialmente en recuperar la parte humanÃ­stica relacionada al mismo, para asÃ­ otorgar certidumbre, generar confianza y ofrecer un entorno digital Ã©tico a los usuarios. Reforzando esta idea, es necesario invocar la DeclaraciÃ³n de Principios de la Cumbre Mundial sobre la Sociedad de la InformaciÃ³n, en la que se estableciÃ³ el compromiso de construir una sociedad basada en la persona, en la que todos pudiÃ©ramos crear, consultar, utilizar y compartir la informaciÃ³n y el conocimiento, para impulsar el desarrollo sostenible y mejorar la calidad de vida, sobre la base de los propÃ³sitos y principios de la Carta de las Naciones Unidas y respetando plenamente y defendiendo la DeclaraciÃ³n Universal de Derechos Humanos.20
 Derivado de lo anterior, podemos afirmar que la idea de dignidad humana debe estar mÃ¡s presente que nunca en el desarrollo tecnolÃ³gico y en la forma en la que se configura la regulaciÃ³n en torno a dicho rubro, y uno de los grandes desafÃ­os de no hacerlo, es la paradoja de la coordinaciÃ³n y fragmentaciÃ³n de procesos desiguales de desarrollo.21 Es decir, el desarrollo tecnolÃ³gico debe preservar un equilibrio entre la libertad y la dignidad humana, el cual podrÃ­a lograrse a travÃ©s de un humanismo sÃ³lido y del respeto de dicha dignidad como eje de cualquier avance cientÃ­fico: la tecnologÃ­a como herramienta para empoderar a las personas, pero no como el Ãºnico fin. Apuntalando lo anterior, el derecho en nuestro siglo tiene el reto de recuperar el carÃ¡cter humanÃ­stico frente al desarrollo tecnolÃ³gico.22
 4. Inteligencia artificial y derecho a la privacidad En este apartado, primero es necesario dar una aproximaciÃ³n a lo que referimos cuando decimos palabras aparentemente iguales, pero que tienen pequeÃ±as variaciones en su significado, necesarias de distinguir cuando queremos preservar la privacidad en tiempos de inteligencia artificial. Es asÃ­ que el significado de tÃ©rminos como privacidad, vida privada, y protecciÃ³n de datos personales, tiene alcances distintos. Iniciando desde la conceptualizaciÃ³n del derecho a la privacidad, Ã©ste tiene su origen en la doctrina estadounidense de finales del siglo XIX,23 cuando Warren y Brandeis publicaron su ensayo The Right to Privacy, el cual manifestaba el necesario reconocimiento del derecho a no ser molestados (right to be alone), y posteriormente Westin ampliÃ³ este concepto e incluyÃ³ dentro del derecho a la privacidad, el derecho de todo individuo para determinar cÃ³mo, cuÃ¡ndo y hasta quÃ© punto su informaciÃ³n personal es comunicada a los demÃ¡s.24
 El fin Ãºltimo que se busca preservar frente a posibles injerencias arbitrarias en la vida privada de las personas, es contar con mecanismos legales que en su conjunto salvaguarden la vida privada. Uno de estos mecanismos, es el derecho de protecciÃ³n de datos personales (que Ãºnicamente protege el poder del titular de un dato personal para decidir sobre su tratamiento, salvo excepciones), pero al menos para el caso de MÃ©xico, hay otros instrumentos como el reconocimiento constitucional del secreto de las comunicaciones, la incorporaciÃ³n de figuras del derecho civil que protegen el derecho al honor, a la propia imagen y disposiciones de Ã­ndole penal que establecen las reglas de geolocalizaciÃ³n en tiempo real. Es decir, todas estas disposiciones en su conjunto permiten (en el deber ser), al Estado garantizar la vida privada de las personas. El concepto âprivacidadâ no es un concepto terminado y depende del contexto y circunstancias de los casos particulares, poder acotarlo. Es decir, lo que en un paÃ­s puede considerarse como una situaciÃ³n del Ã¡mbito privado, en otro no.25
 En virtud de lo anterior, el tÃ©rmino âprivacidadâ no es fÃ¡cil de definir, ya que hasta el momento no se tiene una idea clara de sus alcances. Esto se confirma con lo dicho por el Tribunal Europeo de Derechos Humanos, que considera la privacidad como un concepto amplio, no susceptible de una definiciÃ³n exhaustiva.26
 Para el caso de MÃ©xico, la Suprema Corte de Justicia de la NaciÃ³n (SCJN) estableciÃ³ que las afirmaciones contenidas en las resoluciones nacionales e internacionales relacionadas a la privacidad o vida privada son Ãºtiles en la medida en que no se tomen de manera descontextualizada, emerjan de un anÃ¡lisis cuidadoso de los diferentes escenarios jurÃ­dicos en los que la idea de privacidad entra en juego y no se pretenda derivar de ellas un concepto mecÃ¡nico de vida privada, de referentes fijos e inmutables. Lo Ãºnico que estas resoluciones permiten reconstruir, en tÃ©rminos abstractos, es la imagen general que evoca la idea de privacidad en nuestro contexto cultural.27
 Es asÃ­ que en tÃ©rminos generales podemos decir que la privacidad es el Ã¡mbito mÃ¡s Ã­ntimo o profundo de la vida de una persona, que puede comprender sus sentimientos, pensamientos, emociones, vida familiar o relaciones personales y el derecho a la privacidad, el poder que tiene la persona frente a cualquier intromisiÃ³n de un tercero que pudiera manifestarse (incluido el propio Estado). El derecho a la privacidad es el poder de decisiÃ³n de una persona sobre su espacio privado, con quiÃ©n lo comparte, quÃ© debe formar parte de lo pÃºblico y quÃ© de lo privado.28
 La privacidad y derecho a la privacidad no necesariamente refieren a lo mismo: la privacidad es un elemento consustancial a la dignidad humana y por ende debe ser protegido por el derecho y el derecho a la privacidad es aquÃ©l que todo individuo tiene a separar aspectos de su vida privada del escrutinio pÃºblico.29
 Por otro lado, los conceptos de privacidad y vida privada se han redefinido a partir del vertiginoso desarrollo tecnolÃ³gico, el cual hace posible la sobreexposiciÃ³n de Ã¡mbitos que hasta hace unas dÃ©cadas eran meramente del Ã¡mbito privado. Una vez que hemos tratado de definir o al menos dar una aproximaciÃ³n conceptual de la privacidad, vida privada y derecho de privacidad, podrÃ­amos estar preguntÃ¡ndonos entonces, Â¿por quÃ© es tan importante preservar la privacidad en tiempos de inteligencia artificial?: Una primera respuesta es que el valor de la privacidad tiene un componente privado, pero tambiÃ©n es un social good, en la medida en la que es necesaria para la pervivencia de la democracia y la libertad.30 Por ejemplo, no podrÃ­amos imaginar un estado constitucional y democrÃ¡tico de derecho, frente a censos que utilicen la IA para procesar informaciÃ³n de la poblaciÃ³n, que deriven en un exterminio masivo de personas, como sucediÃ³ en la Alemania nazi durante el Holocausto. Una segunda respuesta sobre la importancia de preservar la privacidad en tiempos de IA tiene que ver con la enorme capacidad tÃ©cnica de las organizaciones para recabar grandes cÃºmulos de informaciÃ³n en tiempo real, procesarla y tomar decisiones, lo cual expone aspectos privados de la vida de las personas, como los hÃ¡bitos de consumo de un hogar, los ingresos econÃ³micos de una persona o su ideologÃ­a polÃ­tica o religiosa, por mencionar algunos. Esta sobreexposiciÃ³n y concentraciÃ³n de informaciÃ³n por parte de unos cuantos, deja a los usuarios de sistemas de inteligencia artificial, particularmente desprotegidos frente al poder acumulado por las corporaciones y ejemplos como el de Cambridge Analytical,31 hacen evidente la necesidad de vigilar el comportamiento de tecnologÃ­as como la inteligencia artificial. La tercera respuesta estÃ¡ relacionada con el pÃ¡rrafo anterior, ya que el rol de las corporaciones como actores que ostentan el poder en la economÃ­a digital propicia la eventual disminuciÃ³n del Estado NaciÃ³n y la no intervenciÃ³n a travÃ©s de su rectorÃ­a, para la salvaguarda de derechos humanos como el derecho a la privacidad. Como podemos advertir de las lÃ­neas anteriores, el rÃ¡pido desarrollo tecnolÃ³gico hace que cada vez sea mÃ¡s complejo garantizar el derecho a la privacidad, ya que la informaciÃ³n que se genera a partir del uso de Internet y de sistemas de inteligencia artificial, se encuentra susceptible a ser sometida a tratamientos masivos, y muchas veces sin contar con el conocimiento y consentimiento informado del titular del dato. En este punto, es conveniente resaltar que hoy dÃ­a, la IA permite en algunos casos hacer tratamiento de datos legales pero poco Ã©ticos, ya que si bien los sistemas son programados para cumplir en el mejor de los casos, con los requisitos mÃ­nimos de las normas, (en materia de protecciÃ³n de datos personales serÃ­a el consentimiento de los titulares de la informaciÃ³n), este consentimiento no es verdaderamente informado, o no se propician los mecanismos necesarios para que los titulares de datos alcancen a entender la dimensiÃ³n de la autorizaciÃ³n.32
 5. El derecho de protecciÃ³n de datos personales en los sistemas de inteligencia artificial Como hemos visto en apartados previos, el artÃ­culo 12 de la DeclaraciÃ³n Universal de Derechos Humanos, reconoce el derecho a la no injerencia en la vida privada de las personas, el cual puede considerarse el antecedente mÃ¡s importante, que estableciÃ³ las bases para una evoluciÃ³n normativa e incorporaciÃ³n a los marcos legales domÃ©sticos de distintas figuras jurÃ­dicas, que en su conjunto protegen la vida privada de las personas. Una de estas figuras, es el derecho de protecciÃ³n de datos personales, el cual fue reconocido en 2009, en la ConstituciÃ³n PolÃ­tica de los Estados Unidos Mexicanos, mediante adhesiÃ³n de un pÃ¡rrafo al artÃ­culo 16, el cual, seÃ±ala:  âArtÃ­culo 16. â¦ Toda persona tiene derecho a la protecciÃ³n de sus datos personales, al acceso, rectificaciÃ³n y cancelaciÃ³n de los mismos, asÃ­ como a manifestar su oposiciÃ³n, en los tÃ©rminos que fije la ley, la cual establecerÃ¡ los supuestos de excepciÃ³n a los principios que rijan el tratamiento de datos, por razones de seguridad nacional, disposiciones de orden pÃºblico, seguridad y salud pÃºblicas o para proteger los derechos de terceros. â¦â.33
 El derecho de protecciÃ³n de datos personales le confiere al titular del dato, el poder de decisiÃ³n sobre el tratamiento de su informaciÃ³n, desde que se recaba hasta que se destruye. Este derecho cobra vida a travÃ©s de los denominados derechos ARCO, tambiÃ©n reconocidos en el referido artÃ­culo 16 de la carta magna, y consistentes en los derechos de: acceso, rectificaciÃ³n, cancelaciÃ³n y oposiciÃ³n frente al tratamiento de datos personales.34
 No obstante, como pasa con otros derechos humanos, el de protecciÃ³n de datos personales no es un derecho absoluto y encuentra sus restricciones en el multicitado artÃ­culo 16 constitucional, al referir que todas las personas gozarÃ¡n del derecho de protecciÃ³n de datos personales, salvo que exista un impedimento o restricciÃ³n por razones de seguridad nacional, disposiciones de orden pÃºblico, seguridad y salud pÃºblicas o para proteger derechos de terceros. En otras palabras, el derecho de protecciÃ³n de datos personales encuentra sus lÃ­mites en aquellas excepciones reconocidas expresamente en el 16 constitucional y que resultan necesarias en sociedad democrÃ¡tica. El derecho de protecciÃ³n de datos personales en MÃ©xico ha sido regulado en dos normas: La Ley Federal de ProtecciÃ³n de Datos Personales en PosesiÃ³n de los Particulares (2010) y la Ley General de ProtecciÃ³n de Datos Personales en PosesiÃ³n de los Sujetos Obligados (2017). En general, estas normas, la primera de Ã­ndole federal y la segunda de aplicaciÃ³n nacional, reconocen los principios que deben regir el tratamiento de datos personales, las obligaciones de los Responsables y Encargados del tratamiento, las medidas de seguridad que deben considerarse, los procedimientos de denuncia que tiene la persona frente a la vulneraciÃ³n de este derecho y los mecanismos de sanciÃ³n que tiene el Instituto Nacional de Transparencia, Acceso a la InformaciÃ³n y ProtecciÃ³n de Datos Personales (INAI) frente al incumplimiento de las disposiciones legales en la materia. El camino del derecho de protecciÃ³n de datos personales en MÃ©xico desde la perspectiva normativa, parece ser un camino largo y sÃ³lido que brinda dos leyes que regulan el tratamiento de datos personales tanto en empresas como en el sector pÃºblico, e incluso reconoce la coexistencia de algunas normas sectoriales con disposiciones en la materia, que tambiÃ©n constituyen excepciones dentro del rÃ©gimen general de este derecho, como la Ley de Instituciones de CrÃ©dito. No obstante, cuando hablamos del derecho de protecciÃ³n de datos personales en Ã¡mbitos digitales o tecnolÃ³gicos, como lo es el de la inteligencia artificial, -por las caracterÃ­sticas propias de las innovaciones-, parece que el alcance de este derecho se diluye respecto de los alcances efectivos que sÃ­ tiene en el mundo fÃ­sico. El efectivo ejercicio de derechos ARCO en sistemas de IA a veces resulta casi imposible, por ejemplo, la dificultad de ejercer los derechos de acceso y/o rectificaciÃ³n previa a una posible vulneraciÃ³n de derechos humanos frente al tratamiento de datos personales que haga un sistema de identificaciÃ³n facial utilizado por el Estado. Es decir, el sistema de IA funcionarÃ¡ con la informaciÃ³n que haya suministrado alguna entidad estatal, haciendo casi imposible el acceso, la rectificaciÃ³n o cancelaciÃ³n del dato, antes o despuÃ©s de una vulneraciÃ³n a un derecho humano como podrÃ­a ser el de libertad de expresiÃ³n. Aunado a esto, pensemos en la falta de transparencia en el funcionamiento de estos sistemas de identificaciÃ³n facial, ya que muchos de ellos trabajan con informaciÃ³n de la poblaciÃ³n en general y no solo de aquellos individuos que representan por cualquier motivo vÃ¡lido en una sociedad democrÃ¡tica, un riesgo para la seguridad pÃºblica o la seguridad nacional y en la medida desproporcionada en la que los sistemas de identificaciÃ³n son utilizados por parte de los Estados. Tal vez en este ejemplo, el sistema de IA de identificaciÃ³n facial constituya por sÃ­ mismo una vulneraciÃ³n a la libertad de expresiÃ³n en una sociedad democrÃ¡tica, que establece una medida sistemÃ¡tica y previa de censura y desproporcionada por parte del Estado. Esta conclusiÃ³n que nada aparentemente tiene que ver con el derecho de protecciÃ³n de datos personales, se pude elaborar a partir del anÃ¡lisis del tipo de datos que trata un sistema, los fines para llevar a cabo dicho tratamiento y una evaluaciÃ³n a la luz del principio de proporcionalidad en materia de datos personales. Lo anterior, sin tomar en consideraciÃ³n que la IA permite incorporar nuevas posibilidades que representan desafÃ­os para los derechos humanos, por ejemplo, el anÃ¡lisis de emociones a travÃ©s de lo que una persona publica en una red social y un algoritmo que calcule el riesgo que su estado anÃ­mico, pensamientos, ideologÃ­a, representa para la seguridad de un Estado. En este ejemplo, las polÃ­ticas de privacidad de las redes sociales desempeÃ±an un papel importante, por ejemplo, los usuarios que fueron analizados para crear perfiles psicolÃ³gicos por la empresa Cambridge Analytical, lo hicieron proporcionando su consentimiento para el tratamiento de datos en general, y dicha autorizaciÃ³n la hicieron cuando fueron condicionados a otorgarla para usar una aplicaciÃ³n de proyecciÃ³n del futuro. Este Ãºltimo punto permite la reflexiÃ³n sobre el enorme peso que desde el modelo mexicano de regulaciÃ³n en materia de datos personales se ha depositado sobre el principio de informaciÃ³n y su manifestaciÃ³n travÃ©s del aviso de privacidad, ya que el cumplimiento tanto del principio de informaciÃ³n como el de consentimiento a travÃ©s de dicho aviso, no asegura un tratamiento Ã©tico de la informaciÃ³n. Es decir, estamos frente a tratamientos lÃ­citos de datos personales, pero no Ã©ticos. Es pertinente matizar el ejemplo diciendo que el enorme desafÃ­o que se advierte respecto del derecho de protecciÃ³n de datos personales en la IA es el de lograr un balance que permita aprovechar los beneficios de esta tecnologÃ­a, sin poner en peligro la dignidad de las personas y sus derechos fundamentales. Esto no parece sencillo, por lo que elementos como la transparencia, el escrutinio de la proporcionalidad en el uso de sistemas de inteligencia artificial, la incorporaciÃ³n de esquemas de cumplimiento normativo y Ã©tico, los mecanismos de supervisiÃ³n estatal y de defensa frente a afectaciones derivadas de decisiones automatizadas, permitirÃ­an hacer frente a los peligros que hoy dÃ­a preocupan a expertos en la materia. Es decir, en palabras de Federico Lefranc, no hay que equivocarse, la crÃ­tica no es a la evoluciÃ³n de la tecnologÃ­a, ni tampoco frente a sus posibilidades ni frente a sus usos. La crÃ­tica se dirige a la concepciÃ³n epistemolÃ³gica del discurso, en el entendido de que esta concepciÃ³n se puede articular entendiendo al sujeto como receptor de dicho discurso.35
 TambiÃ©n el derecho de protecciÃ³n de datos personales en la IA se debe estudiar bajo la Ã³ptica del fenÃ³meno de los paÃ­ses perifÃ©ricos (consumidores de tecnologÃ­a que no generan o desarrollan sus propias capacidades de ciencia, tecnologÃ­a e innovaciÃ³n), los cuales casi siempre ven reducido su marco normativo, frente las polÃ­ticas de privacidad de las corporaciones trasnacionales, que no son compatibles necesariamente, con la dimensiÃ³n, que por ejemplo MÃ©xico, le ha dado al derecho humano de protecciÃ³n de datos personales. Es decir, cuando hablamos de tecnologÃ­a, a pesar de que MÃ©xico cuenta con un marco legal en materia de protecciÃ³n de datos personales robusto, que retoma los mÃ¡s altos estÃ¡ndares de protecciÃ³n de la persona, en la lÃ³gica del modelo de regulaciÃ³n europeo y de la familia romano germÃ¡nica, todos estos esfuerzos se ven reducidos frente a sistemas de IA que han sido diseÃ±ados principalmente en paÃ­ses desarrollados cuya familia jurÃ­dica pertenece al derecho anglosajÃ³n. A nivel global existen desarrollos de IA que han despertado el interÃ©s y preocupaciÃ³n de muchos Estados, pensando por ejemplo en los sistemas de defensa y en los robots autÃ³nomos cuya tendencia en su desarrollo es que puedan tratar datos personales en tiempo real (imÃ¡genes) y tomar decisiones sobre los blancos de ataque. Esto considerando si el derecho internacional humanitario alcanza o no para regular los lÃ­mites que deben tener en cuenta los desarrolladores al momento de programar el software. Por ejemplo, la viabilidad de preguntarse si es lÃ­cito o no programar un robot para comparar con una base de datos, imÃ¡genes de niÃ±os y civiles para descartarlos como blanco de ataque y la autonomÃ­a de decisiÃ³n del robot. Como respuesta a algunas de las preocupaciones generadas a partir de los ejemplos citados, se han creado instancias que trabajan sobre las directrices que debe seguir el desarrollo de IA y cuyo eje transversal sin duda alguna, serÃ¡n las reglas y lÃ­mites para el tratamiento de informaciÃ³n personal. Un ejemplo interesante de los esfuerzos que supone el uso de la IA protegiendo a la persona frente a tratamientos de sus datos, lo encontramos en el documento de la Agencia EspaÃ±ola de ProtecciÃ³n de Datos Personales, denominado âAdecuaciÃ³n al RGPD de tratamientos que incorporan Inteligencia Artificial. Una introducciÃ³nâ36, en el que se puede encontrar un modelo de incorporaciÃ³n de disposiciones normativas en materia de datos a sistemas de inteligencia artificial.  Retomando el caso de MÃ©xico en los ejemplos mencionados, se puede advertir que si bien el paÃ­s ha reconocido a nivel constitucional el derecho de protecciÃ³n de datos personales cuenta con normas secundarias que dan vida a este derecho (Ley Federal de ProtecciÃ³n de Datos Personales en PosesiÃ³n de los Particulares de 2010 y Ley General de ProtecciÃ³n de Datos Personales en PosesiÃ³n de Sujetos Obligados de 2017), el nivel de protecciÃ³n de la persona frente a la tecnologÃ­a no puede garantizarse cuando hablamos de inteligencia artificial, debido a fenÃ³menos como la ubicuidad, la no existencia de fronteras fÃ­sicas, la extraterritorialidad de la normas, la reducciÃ³n del Estado NaciÃ³n (al depositarse principalmente la garantÃ­a de derechos humanos en manos de las corporaciones), la falta de mecanismos estatales de supervisiÃ³n y garantÃ­a de los derechos humanos en la inteligencia artificial. Es decir, los esfuerzos de los Estados para la salvaguarda de los derechos humanos en Ã¡mbitos tecnolÃ³gicos, especialmente Internet e inteligencia artificial, muchas veces se ven diluidos en la globalizaciÃ³n de la era digital. A pesar de que la falta de mecanismos efectivos para el ejercicio del derecho de protecciÃ³n de datos personales en la IA podrÃ­a ser el principal problema al que se enfrenta este derecho, no debemos dejar de advertir dos cosas. Las leyes nacionales en materia de datos personales no contienen disposiciones especÃ­ficas para el tratamiento de datos personales en sistemas de inteligencia artificial, lo cual no serÃ­a un problema determinante, salvo que por las caracterÃ­sticas de dicho tratamiento y la forma en la que funciona la tÃ©cnica, es necesario cuestionarse sobre la necesidad de configurar nuevos derechos que permitirÃ­an la efectiva garantÃ­a de la dignidad humana frente a sistemas de inteligencia artificial. Estos derechos son: el âderecho a la no identificaciÃ³nâ de las personas en la utilizaciÃ³n de inteligencia artificial, el âderecho a que la informaciÃ³n personal no sea tratada mediante tÃ©cnicas de inteligencia artificialâ o incluso un âderecho de reclamaciÃ³nâ frente a afectaciones a los derechos de las personas, derivadas de las decisiones tomadas mediante sistemas de inteligencia artificial. Es decir, el marco jurÃ­dico de los derechos humanos, en especÃ­fico el del derecho de protecciÃ³n de datos personales, sirve para establecer las reglas para el tratamiento de datos a travÃ©s de sistemas de inteligencia artificial, por ejemplo, los principios, deberes, obligaciones y mecanismos para el ejercicio de los derechos ARCO. No obstante, como consecuencia de los tratamientos automatizados de datos personales a travÃ©s de inteligencia artificial, empieza a hacerse necesario el reconocimiento de nuevas modalidades de ejercicio del derecho de protecciÃ³n de datos personales que incluso servirÃ­an para garantizar otros derechos humanos, como el de no discriminaciÃ³n (que no es objeto de este trabajo). Ahora bien, no se puede hablar del derecho de protecciÃ³n de datos personales en sistemas de IA sin mencionar que al ser la informaciÃ³n un valor muy preciado en la economÃ­a digital, este derecho tiene tambiÃ©n lugar en las negociaciones de tratados internacionales, no sÃ³lo de derechos humanos, sino comerciales tambiÃ©n. Es asÃ­ que cuando hablamos de protecciÃ³n de datos personales e inteligencia artificial, resulta necesario situarnos en la influencia que han tenido instrumentos jurÃ­dicos internacionales en la construcciÃ³n y forma de interpretaciÃ³n de este derecho en MÃ©xico. En este sentido, en 2018 MÃ©xico fue aceptado al Convenio 108 del Consejo de Europa para la protecciÃ³n de las personas con respecto al tratamiento automatizado de datos de carÃ¡cter personal, -un instrumento paradigmÃ¡tico en materia de protecciÃ³n de datos personales en el Ã¡mbito europeo y de paÃ­ses terceros que sean aceptados a formar parte de Ã©ste)-, lo cual establece las bases para una mÃ¡xima protecciÃ³n de la informaciÃ³n de las personas, en un reconocimiento jurÃ­dico, histÃ³rico y polÃ­tico de la dignidad humana frente al desarrollo tecnolÃ³gico. Este paso tan significativo para MÃ©xico ha tenido una etapa de estancamiento, en donde hoy dÃ­a, existen amenazas directas al reconocimiento que ha hecho el paÃ­s sobre el derecho de protecciÃ³n de datos personales. Esta afirmaciÃ³n tiene sustento en la aceptaciÃ³n por parte de MÃ©xico de clÃ¡usulas contenidas en un instrumento primordialmente econÃ³mico como el Tratado comercial entre MÃ©xico, Estados Unidos de NorteamÃ©rica y CanadÃ¡ (TMEC), que estÃ¡n por debajo del nivel de protecciÃ³n que el paÃ­s se comprometiÃ³ a otorgar en 2018, a travÃ©s del citado Convenio 108.37 Otro elemento que apuntala la afirmaciÃ³n de que el derecho de protecciÃ³n de datos personales se ha visto estancado en MÃ©xico, es la falta de voluntad polÃ­tica y legislativa para solicitar la adhesiÃ³n al Convenio 108 Plus del Consejo de Europa, que permitirÃ­a a MÃ©xico terminar la armonizaciÃ³n del marco legal domÃ©stico con las normas en el Ã¡mbito europeo en materia de protecciÃ³n de datos personales, paso necesario para la consolidaciÃ³n de modelos de comercio digital, cooperaciÃ³n internacional entre autoridades y en general, para la transferencia internacional de datos personales. Sobre el capÃ­tulo 19 de comercio digital del TMEC, el artÃ­culo 19.8 habla sobre la protecciÃ³n de la informaciÃ³n personal, e inicia haciendo un reconocimiento de los beneficios econÃ³micos y sociales de la protecciÃ³n de la informaciÃ³n personal de los usuarios del comercio digital y la contribuciÃ³n que dicha protecciÃ³n aporta para generar confianza en el consumidor. En principio, este artÃ­culo otorga un margen de apreciaciÃ³n para que cada Estado, adopte o mantenga un marco legal que disponga la protecciÃ³n de la informaciÃ³n personal de los usuarios de comercio digital, e incluso seÃ±ala que cada Estado, podrÃ¡ tomar en consideraciÃ³n los principios y directrices de los organismos internacionales pertinentes, tales como el Marco de Privacidad de APEC y la RecomendaciÃ³n del Consejo de la OCDE relativa a las Directrices de la OCDE sobre protecciÃ³n de la privacidad y flujos transfronterizos de datos personales (2013). Los Estados tambiÃ©n reconocen la importancia de asegurar el cumplimiento de las medidas para proteger la informaciÃ³n personal y asegurar que las restricciones a los flujos transfronterizos de informaciÃ³n personal sean necesarias y proporcionales a los riesgos presentados.38
 Lo que llama la atenciÃ³n de este capÃ­tulo, es el numeral 6 que indica: â6. Reconociendo que las Partes podrÃ¡n tomar diferentes enfoques legales para proteger la informaciÃ³n personal, cada Parte deberÃ­a fomentar el desarrollo de mecanismos para promover la compatibilidad entre estos diferentes regÃ­menes. Las Partes procurarÃ¡n intercambiar informaciÃ³n sobre los mecanismos aplicados en sus jurisdicciones y explorarÃ¡n maneras de extender estos u otros acuerdos adecuados para promover la compatibilidad entre estos. Las Partes reconocen que el sistema de Reglas de Privacidad Transfronterizas de APEC es un mecanismo vÃ¡lido para facilitar las transferencias transfronterizas de informaciÃ³n mientras se protege la informaciÃ³n personalâ.39
 En este sentido, la ComisiÃ³n Europea ya se ha pronunciado sobre elementos que se deben advertir al momento de negociar tratados internacionales en materia comercial, dejando sentado que los aspectos econÃ³micos no pueden estar por encima de los derechos humanos. TambiÃ©n se debe resaltar que si bien la adhesiÃ³n de MÃ©xico al Convenio 108 del Consejo de Europa, establece un antecedente inÃ©dito para indicar el rumbo hacia donde debe evolucionar normativamente este derecho en el marco legal domÃ©stico, (atendiendo primero, al principio de progresividad de los derechos humanos y en segunda lugar, al principio pro persona y la interpretaciÃ³n conforme, reconocidos en la ConstituciÃ³n, a partir de la reforma de derechos humanos de 2011), estÃ¡n pendientes los trabajos de adhesiÃ³n para el citado Convenio 108 Plus, que ya prevÃ© el impacto transversal de la tecnologÃ­a en la vida privada de las personas.  Esto no es nada menor, ya que paÃ­ses como RepÃºblica Dominicana, hoy dÃ­a se encuentran analizando y estableciendo las bases para solicitar la adhesiÃ³n al Convenio 108 plus y MÃ©xico ha tenido retrocesos al aceptar disposiciones de menor protecciÃ³n para el tratamiento de datos personales, previstas en el apartado de comercio electrÃ³nico del propio TMEC. Este fenÃ³meno tiene su explicaciÃ³n en la forma en la que el valor econÃ³mico de los datos prevalece sobre el reconocimiento del derecho de protecciÃ³n de datos personales del modelo europeo, que considera la dignidad humana como el eje rector para el desarrollo tecnolÃ³gico, de ciencia y de innovaciÃ³n, y hace un enÃ©rgico llamado a las corporaciones a insertar aspectos Ã©ticos que sirvan como lÃ­mites frente a tratamientos que atenten en contra de la dignidad de las personas. Es decir, en su momento, MÃ©xico decidiÃ³ sobre el modelo de regulaciÃ³n por el que optarÃ­a, siendo el modelo europeo de protecciÃ³n de datos personales el que considerÃ³ el mÃ¡s idÃ³neo y dicho modelo, tambiÃ©n incluye algunas directrices para la IA y el tratamiento de la informaciÃ³n de carÃ¡cter general, por lo que en el marco del estado constitucional y democrÃ¡tico de derecho, se tendrÃ­a que guardar congruencia a este reconocimiento y protecciÃ³n de la dignidad de las personas logrando un balance entre los intereses comerciales o econÃ³micos que podrÃ­an estar contenidos en otros instrumentos internacionales posteriores a la adhesiÃ³n de MÃ©xico al referido Convenio 108. Para una mejor explicaciÃ³n del tema, en el caso de la UniÃ³n Europea, fue la ComisiÃ³n Europea la que aprobÃ³ las disposiciones para los flujos de datos transfronterizos, derivadas del cierre de la consulta sobre la orientaciÃ³n del artÃ­culo 49 del Reglamento Europeo de ProtecciÃ³n de Datos Personales. Estas disposiciones se aprueban como horizontales para los flujos de datos transfronterizos y la protecciÃ³n de datos personales en los acuerdos comerciales, ya que los datos personales son un derecho fundamental, que no pueden ser objeto de negociaciÃ³n en los acuerdos comerciales de la UE. Es decir, la ComisiÃ³n Europea estÃ¡ tratando de romper las barreras al flujo de datos entre empresas, en futuros acuerdos comerciales como parte de su impulso hacia una economÃ­a mÃ¡s digital, al tiempo que salvaguarda los principios fundamentales del derecho de protecciÃ³n de datos personales. Las disposiciones estÃ¡n diseÃ±adas para insertarse en futuros acuerdos comerciales y garantizar que los principios subyacentes al Reglamento Europeo de ProtecciÃ³n de Datos Personales no se vean socavados. Lo interesante de esta propuesta para suscribir acuerdos internacionales por la que optÃ³ la UniÃ³n Europea, es que las clÃ¡usulas relativas a datos personales incluidas en un tratado comercial, serÃ¡n excluidas de cualquier tribunal de inversiÃ³n establecido por el acuerdo para arbitrar y resolver disputas, lo que significa que las disposiciones estarÃ¡n sujetas a la jurisdicciÃ³n del tribunal mÃ¡s alto de la UniÃ³n Europea.40
 Derivado de lo anterior, el TMEC si bien reconoce el margen de apreciaciÃ³n para que un Estado regule a travÃ©s de sus normas domÃ©sticas el derecho de protecciÃ³n de datos personales, establece las normas del Foro de CooperaciÃ³n EconÃ³mica Asia-PacÃ­fico (APEC), como un punto de encuentro para realizar transferencias internacionales de datos, lo cual no estÃ¡ redactado en tÃ©rminos de lo resuelto por la ComisiÃ³n Europea, especÃ­ficamente en el tema de la resoluciÃ³n de controversias, ya que no serÃ­a el alto tribunal europeo quien resuelva una posible controversia, sino probablemente los Ã¡rbitros seÃ±alados dentro de los mecanismos alternativos que reconoce el Foro, lo cual propiciarÃ­a que si no se cumplen las disposiciones de datos que ya se tienen en MÃ©xico, su revisiÃ³n no recaerÃ­a sobre una instancia europea (cuando las transferencias involucren datos de personas nacidas o que vivan en alguno de los paÃ­ses miembros de la UniÃ³n Europea), sino en la instancia seÃ±alada por el propio APEC. Esto serÃ­a algo menor si MÃ©xico no fuera parte del Convenio 108 del Consejo de Europa. Por otro lado, resaltar que MÃ©xico aÃºn no ha sido declarado paÃ­s seguro (paÃ­s tercero fuera de Europa que brinda garantÃ­as para un debido tratamiento de datos que reciba por transferencia), por lo que los acuerdos comerciales hacia Europa, podrÃ­an verse mermados por esta situaciÃ³n y por la falta de voluntad de alinear las normas locales con los compromisos internacionales, especÃ­ficamente del Ã¡mbito europeo a los que MÃ©xico se comprometiÃ³. En este sentido, los Acuerdos de Puerto Seguro desempeÃ±an un rol importante porque pueden ser los puentes por los que se intercambien datos personales entre uno de los paÃ­ses miembro de la UniÃ³n Europea con paÃ­ses que no tienen el mismo nivel normativo de protecciÃ³n del dato, como el caso de Estados Unidos de NorteamÃ©rica.41
 En 2015 el Tribunal de Justicia de la UniÃ³n Europea declarÃ³ la invalidez del acuerdo sobre la transferencia internacional de datos personales pues entendÃ­a que la legislaciÃ³n estadounidense no brindaba las garantÃ­as suficientes para proteger aquella informaciÃ³n que provenÃ­a del espacio europeo. Tras un nuevo acuerdo, en julio del 2020, el mismo tribunal declarÃ³ la invalidez del escudo privacy shield como herramienta jurÃ­dica vÃ¡lida para garantizar el derecho de protecciÃ³n de los datos de los ciudadanos europeos en supuestos de transferencia internacional.42
 La figura de los Acuerdos de Puertos Seguro pueden ser una vÃ­a idÃ³nea para que MÃ©xico transfiera datos personales al paÃ­s del norte, a fin de tener certeza sobre el tipo de tratamiento proporcional y razonable que haga el paÃ­s receptor y que el tratamiento de la informaciÃ³n no derive en vulneraciones a la dignidad humana, como pasÃ³ con los datos personales de migrantes, que instancias mexicanas compartieron con autoridades migratorias de Estados Unidos. En la regiÃ³n iberoamericana (que privilegia el derecho continental), se han trabajado documentos de soft law, que sirven como orientadores para comprender las necesidades regulatorias en el tratamiento de datos en la inteligencia artificial. El primer documento que analizaremos se denomina âRecomendaciones generales para el tratamiento de datos en la Inteligencia Artificialâ de la Red Iberoamericana de ProtecciÃ³n de Datos, el cual estÃ¡ dirigido a desarrolladores de productos de IA y da recomendaciones generales, entre las que destacan la elaboraciÃ³n de estudios de impacto de privacidad, la Ã©tica y seguridad desde el diseÃ±o, accountability, esquemas de gobernanza, respeto a los derechos de los titulares del dato, etcÃ©tera.43
 De este documento es importante destacar que no tiene como pretensiÃ³n oponerse a que las corporaciones traten datos personales a travÃ©s de la inteligencia artificial, sino que lo hagan con las garantÃ­as necesarias, atendiendo las reglas, principios y derechos que dan vida a la protecciÃ³n de datos personales, para asÃ­ evitar cualquier daÃ±o, abuso o vulneraciÃ³n de los derechos de los titulares de esos datos. La guÃ­a se acompaÃ±a por un documento mÃ¡s especÃ­fico, emitido tambiÃ©n por la Red Iberoamericana de ProtecciÃ³n de Datos Personales, denominado âOrientaciones especÃ­ficas para el cumplimiento de los principios y derechos que rigen la protecciÃ³n de datos personales en los proyectos de inteligencia artificialâ,44 en el marco del instrumento normativo que constituye la referencia comÃºn para las entidades integrantes de la seÃ±alada Red, como son los EstÃ¡ndares de ProtecciÃ³n de Datos Personales para los Estados Iberoamericanos que se aprobaron en Santiago de Chile, en 2017. Otro documento normativo paradigmÃ¡tico en favor del derecho de protecciÃ³n de datos personales vinculado con disposiciones especÃ­ficas sobre IA es el Reglamento General de ProtecciÃ³n de Datos (RGPD) aplicable en el Ã¡mbito europeo, el cual refuerza los requisitos relacionados con las decisiones automatizadas, basadas en el uso de inteligencia artificial; es decir, las entidades que utilicen algoritmos (insumos de la inteligencia artificial) tendrÃ¡n que proporcionar una explicaciÃ³n sobre la lÃ³gica de las decisiones automatizadas y sobre sus consecuencias principales para los individuos, pudiendo Ã©stos pedir la intervenciÃ³n humana y recurrir la decisiÃ³n (principio de transparencia).45
 Derivado de lo anterior, se advierte que si bien se cuenta con un marco normativo que establece los lÃ­mites para el tratamiento de datos personales a travÃ©s de sistemas de inteligencia artificial, resulta necesario pensar en la configuraciÃ³n de mecanismos especÃ­ficos para que los Estados supervisen el cumplimiento de los alcances de este derecho humano en la IA (principio de escrutinio) y habilitar nuevas manifestaciones del derecho de protecciÃ³n de datos personales para que los titulares tengan mecanismos concretos de defensa frente a las consecuencias de los tratamientos de datos a travÃ©s de IA (mecanismos de reclamaciÃ³n, de no identificaciÃ³n y de no tratamiento de datos en sistemas de inteligencia artificial). 6. Conclusiones De las lÃ­neas anteriores se ha podido identificar que la IA tiene diversos usos que impactan en todas las esferas de la sociedad. Los beneficios de su incorporaciÃ³n son evidentes por lo que empresas y gobiernos se encuentran explorando nuevas posibilidades de uso y explotaciÃ³n de esta tÃ©cnica. La IA funciona principalmente a travÃ©s del procesamiento masivo de informaciÃ³n (que puede contener datos personales) lo cual despierta enormes preocupaciones para su instrumentaciÃ³n. En este sentido, si bien existe un marco legal robusto en materia de datos personales en MÃ©xico, se han identificado algunos de los desafÃ­os para la salvaguarda de este derecho cuando se trata de entornos tecnolÃ³gicos, especÃ­ficamente en la inteligencia artificial. Estos desafÃ­os, relacionados con la extraterritorialidad de la norma, la no existencia de fronteras fÃ­sicas, las mÃºltiples jurisdicciones interactuando, la reducciÃ³n del Estado NaciÃ³n, la responsabilidad otorgada para que sean las corporaciones las que salvaguarden derechos humanos como el de privacidad y datos, diluyen en un mundo digital global el alcance que tiene el derecho de protecciÃ³n de datos en el mundo fÃ­sico. Esto particularmente desde los paÃ­ses perifÃ©ricos, que no actÃºan en bloque regional y que no tienen mecanismos efectivos de obligatoriedad y cumplimiento de sus normas nacionales. Aunado a lo anterior, se ha identificado la necesidad de reconocer la configuraciÃ³n de nuevas manifestaciones del derecho de protecciÃ³n de datos personales, atendiendo la forma en la que funciona y se incorporan los sistemas de inteligencia artificial, tales como el derecho de reclamaciÃ³n frente a decisiones automatizadas, el derecho a no ser sometido a tratamientos de datos a travÃ©s de IA y el derecho a que la persona no sea identificada en los tratamientos a travÃ©s de esta tÃ©cnica. Derivado de lo anterior, podemos afirmar que el derecho de protecciÃ³n de datos personales desde su Ã¡mbito de derecho humano permite establecer en general las reglas para el tratamiento de los datos personales en la inteligencia artificial, como los principios, los deberes y las obligaciones que Responsables y Encargados deben tener en cuenta. No obstante, la forma en la que se ha diversificado su uso hace necesario hablar de nuevas manifestaciones del derecho de protecciÃ³n de datos personales como las referidas en el pÃ¡rrafo previo, que en su conjunto permitirÃ­an incluso proteger otros derechos humanos, como el derecho a la no discriminaciÃ³n. Por otro lado, frente al crecimiento exponencial de la inteligencia artificial, nos encontramos que los sistemas son programados para cumplir requisitos formales normativos para el tratamiento de datos personales, sin que esto signifique que sean tratamientos Ã©ticos; es decir, estamos frente a tratamientos lÃ­citos, pero en muchos casos no Ã©ticos. Desde la Ã³ptica de los tratados internacionales, MÃ©xico debe suscribir solo aquÃ©llos que estÃ©n armonizados con los compromisos internacionales que el paÃ­s ha asumido, relativos a la salvaguarda de los derechos humanos de las personas y su dignidad, particularmente respecto del derecho de protecciÃ³n de datos personales. Finalmente, MÃ©xico tiene una oportunidad para fungir como paÃ­s lÃ­der hacia una integraciÃ³n regional que estandarice las normas en materia de protecciÃ³n de datos personales aplicadas a la inteligencia artificial, optando por el modelo europeo, que al menos para los paÃ­ses de IberoamÃ©rica, resulta el mÃ¡s compatible, en tÃ©rminos de la herencia del derecho continental y la forma en la que se han configurado los sistemas jurÃ­dicos domÃ©sticos. BibliografÃ­a BibliografÃ­a AdecuaciÃ³n al RGPD de tratamientos que incorporan Inteligencia Artificial. Una introducciÃ³n. Agencia EspaÃ±ola de ProtecciÃ³n de Datos Personales, 2020 [Consulta 13-03-20]. Disponible en: https://www.aepd.es/sites/default/files/2020-02/adecuacion-rgpd-ia.pdf
					
				
			
			[Â LinksÂ ]  Artificial Intelligence for Europe. ComisiÃ³n Europea, 2018 [consulta 13-03-20]. Disponible en: https://ec.europa.eu/digital-single-market/en/artificial-intelligence
					
				
			
			[Â LinksÂ ]  Black, Edwin. IBM y el Holocausto. La alianza estratÃ©gica entre la Alemania Nazi y la mÃ¡s poderosa corporaciÃ³n norteamericana, Buenos Aires: AtlÃ¡ntida, 2001, p. 18. 
			
			[Â LinksÂ ]  Contreras, Carlos. El papel del gobierno en la era digital: un enfoque de economÃ­a pÃºblica. 2017, Editorial Universitaria RamÃ³n Arces, pp. 153 y 154.
			
			[Â LinksÂ ]  Disruptive technologies: Advances that will transform life, business, and the global economy, McKinsey Global Institute, 2013. [Consulta 13-03-20]. Disponible en: https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/disruptive-technologies
					
				
			
			[Â LinksÂ ]  GIBBS, M., y Adams , (1962). âA report on the second national law and electronics conferenceâ. En: MULL: Modern Uses of Logic in Law, [en lÃ­nea]. V. 3, no. 4, pp. 215-223 [consulta 20-03-20]. Disponible en: www.jstor.org/stable/29760908
					
				
			
			[Â LinksÂ ]  Giddens, A., Consecuencias de la Modernidad, Madrid: Alianza, 1993, p. 162. 
			
			[Â LinksÂ ]  Guidelines on Article 49 of Regulation 2016/679. Consejo de Europa, 2018, [Consulta 30-03-20]. Disponible en: https://ec.europa.eu/newsroom/article29/item-detail.cfm?item_id=614232
					
				
			
			[Â LinksÂ ]  Informe Anual del Alto Comisionado de las Naciones Unidas para los Derechos Humanos denominado el Derecho a la Privacidad en la Era Digital. Disponible en: https://icdppc.org/wp-content/uploads/2015/02/Resolution-on-Privacy-In-digital-Age-Spanish-version.pdf
				
			
			[Â LinksÂ ]  Informe sobre la economÃ­a digital 2019. CreaciÃ³n y captura de valor: repercusiones para los paÃ­ses en desarrollo. Conferencia de las Naciones Unidas sobre Comercio y Desarrollo, UNCTAD. [Consulta 30-03-20]. Disponible en: https://unctad.org/es/PublicationsLibrary/der2019_overview_es.pdf
					
				
			
			[Â LinksÂ ]  Inteligencia Artificial. Foro Consultivo de Ciencia y TecnologÃ­a, 2018[Consulta 13-03-20]. Disponible en:  https://www.foroconsultivo.org.mx/INCyTU/documentos/Completa/INCYTU_18-012.pdf
					.
			
			[Â LinksÂ ]  Lefranc, Federico, âLa necesidad de reafirmar el principio de la dignidad humana en el Derecho del siglo XXIâ. MÃ©xico Revista Penal MÃ©xico. 2011, no. 2, p. 155, [Consulta 13-03-20]. Disponible en: https://dialnet.unirioja.es/servlet/articulo?codigo=6158028
					
				
			
			[Â LinksÂ ]  Lefranc, F. Terra IncÃ³gnita. Bases para una polÃ­tica criminal pro persona en la sociedad digital, MÃ©xico: INFOTEC, 2015, p. 9. 
			
			[Â LinksÂ ]  Libro Blanco sobre la inteligencia artificial - un enfoque europeo orientado a la excelencia y la confianza. ComisiÃ³n Europea, 2020 [consulta 13-03-20]. Disponible en: https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_es.pdf
					
				
			
			[Â LinksÂ ]  LÃ³pez, Baroni, (2019). âLas narrativas de la inteligencia artificial. Revistaâ. En: BioÃ©tica y Derecho, No. 46, p. 13 [consulta 10-10-20]. Disponible en: https://revistes.ub.edu/index.php/RBD/article/view/27280
					
				
			
			[Â LinksÂ ]  Mc Carthy, J., et al. âA Proposal for the Dartmouth Summer Research Project on Artificial Intelligenceâ. AI Magazine. 1955, vol. 27, nÃºm. 4, p. 2. https://doi.org/10.1609/aimag.v27i4.1904.
			
			[Â LinksÂ ]  Mendoza, O. DefiniciÃ³n de privacidad. En: Diccionario ProtecciÃ³n de Datos Personales, INAI, 2020, p. 672. [Consulta 13-03-20]. Disponible en: http://inicio.inai.org.mx/PublicacionesComiteEditorial/DICCIONARIO_PDP_digital.pdf
					
				
			
			[Â LinksÂ ]  Orientaciones especÃ­ficas para el cumplimiento de los principios y derechos que rigen la protecciÃ³n de datos personales en los proyectos de inteligencia artificial. Red Iberoamericana de ProtecciÃ³n de Datos, 2019, [Consulta 18-03-20]. Disponible en: https://www.redipd.org/sites/default/files/2020-02/guia-orientaciones-espec%C3%ADficas-proteccion-datos-ia.pdf
					
				
			
			[Â LinksÂ ]  PiÃ±ar, J. âÂ¿Existe privacidad?, LecciÃ³n magistral impartida en la Apertura Solemne del Curso AcadÃ©mico en la Universidad San Pablo-CEU de Madridâ. En: ProtecciÃ³n de Datos Personales. Compendio de lecturas y legislaciÃ³n. MÃ©xico, 2010, Editorial Tiro Corto, p. 16.
			
			[Â LinksÂ ]  Recomendaciones generales para el tratamiento de datos en la Inteligencia Artificial. Red Iberoamericana de ProtecciÃ³n de Datos, 2019, [consulta 18-03-20]. Disponible en: https://www.redipd.org/sites/default/files/2020-02/guia-recomendaciones-generales-tratamiento-datos-ia.pdf
					
				
			
			[Â LinksÂ ]  Ricci, D. ArtÃ­culo 16 Constitucional. Derecho a la privacidad. En: Derechos Humanos en la ConstituciÃ³n: comentarios de jurisprudencia constitucional Interamericana II. [En lÃ­nea]. MÃ©xico: Instituto de Investigaciones JurÃ­dicas, p. 1045. [Consulta 2-03-20]. Disponible en: https://archivos.juridicas.unam.mx/www/bjv/libros/8/3567/39.pdf
					.
			
			[Â LinksÂ ]  Westin, A. Privacy and Freedom. Nueva York: Ateneum, 1967, p. 7.
			
			[Â LinksÂ ]  Winston, J. (1967). âThe Law and Legal Education in the Computer Age.â En: Journal of Legal Education, [en lÃ­nea]. V. 20, no. 2, pp. 159-168. [Consulta 12-02-20] Disponible en: www.jstor.org/stable/42891839
				
			
			[Â LinksÂ ]  Sentencia del Tribunal de Justicia de la UniÃ³n Europea (TJUE) de 16 de julio de 2020 Disponible en: https://curia.europa.eu/jcms/upload/docs/application/pdf/2015-10/cp150117es.pdf
				
			
			[Â LinksÂ ]  Sentencia C311/18 de la STJUE (Gran Sala) de 16 de julio del 2020 del Tribunal Superior, Irlanda.
			
			[Â LinksÂ ]  Sentencia de 15 de diciembre de 1983 emitida por el Tribunal Constitucional Federal AlemÃ¡n. [Consulta 13-03-20]. Disponible en: http://www.informatica-juridica.com/jurisprudencia/alemania.asp
					.
			
			[Â LinksÂ ]  165823. 1a. CCXIV/2009. Primera Sala. Novena Ã©poca. Semanario Judicial de la FederaciÃ³n y su Gaceta. Tomo XXX, diciembre de 2009, p. 277. Derecho a la Vida Privada. [Consulta 10-03-20]. Disponible en: http://sjf.scjn.gob.mx/sjfsist/Documentos/Tesis/165/165823.pdf
					. Fecha de consulta: 20 de agosto de 2018.
			
			[Â LinksÂ ]  ConstituciÃ³n PolÃ­tica de los Estados Unidos Mexicanos. Diario Oficial de la FederaciÃ³n el 5 de febrero de 1917. P. 17.
			
			[Â LinksÂ ]  Ley Federal de ProtecciÃ³n de Datos Personales en PosesiÃ³n de los Particulares Tratado entre Estados Unidos de NorteamÃ©rica, CanadÃ¡ y MÃ©xico en materia comercial. [Consulta 17-03-20]. Disponible en: https://www.gob.mx/t-mec
					
				
			
			[Â LinksÂ ]  CapÃ­tulo 19 de Comercio Digital del TMEC. [Consulta 17-03-20]. Disponible en: https://www.gob.mx/cms/uploads/attachment/file/465801/19ESPComercioDigital.pdf
					
				
			
			[Â LinksÂ ]  1No debemos perder de vista que algunos paÃ­ses funcionan como perifÃ©ricos y que simplemente son consumidores tecnolÃ³gicos de lo que para algunos paÃ­ses desarrollados resulta obsoleto. La obsolescencia tecnolÃ³gica que no es casualidad, es un fenÃ³meno propiciado por las corporaciones a partir de la situaciÃ³n de desventaja de paÃ­ses que no tiene desarrolladas sus propias capacidades tecnolÃ³gicas. Un ejemplo claro, es la compra de pruebas rÃ¡pidas que detectan el Covid-19 por parte de paÃ­ses como EspaÃ±a, que ya han sido descartadas para diagnÃ³sticos oportunos y certeros en paÃ­ses como Alemania. La obsolescencia tecnolÃ³gica tambiÃ©n tiene un impacto en la forma en la que los paÃ­ses utilizan y explotan la informaciÃ³n y los beneficios que de ello obtienen en la economÃ­a digital. 2
Mc Carthy, J., et al. âA Proposal for the Dartmouth Summer Research Project on Artificial Intelligenceâ. AI Magazine. 1955, vol. 27, nÃºm. 4, p. 2. Disponible en: https://doi.org/10.1609/aimag.v27i4.1904. 3
Gibbs, M., y Adams, (1962). âA report on the second national law and electronics conferenceâ. En: MULL: Modern Uses of Logic in Law, [en lÃ­nea]. V. 3, no. 4, pp. 215-223 [consulta 20-03-20]. Disponible en: www.jstor.org/sta-ble/29760908
 4
Winston, J. (1967). âThe Law and Legal Education in the Computer Age.â En: Journal of Legal Education, [en lÃ­nea]. V. 20, no. 2, pp. 159-168. [consulta 12-02-20] Disponible en: www.jstor.org/stable/42891839
 5Artificial Intelligence for Europe. ComisiÃ³n Europea, 2018 [consulta 13-03-20]. Disponible en: https://ec.europa.eu/digital-single-market/en/artificial-intelligence
 6Inteligencia Artificial. Foro Consultivo de Ciencia y TecnologÃ­a, 2018 [consulta 13-03-20]. Disponible en: https://www.foroconsultivo.org.mx/INCyTU/documentos/Completa/INCYTU_18-012.pdf. 7Libro Blanco sobre la inteligencia artificial - un enfoque europeo orientado a la excelencia y la confianza. ComisiÃ³n Europea, 2020 [consulta 13-03-20]. Disponible en: https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_es.pdf
 8Op. Cit., nota 5. 9Informe sobre la economÃ­a digital 2019. CreaciÃ³n y captura de valor: repercusiones para los paÃ­ses en desarrollo. Conferencia de las Naciones Unidas sobre Comercio y Desarrollo, UNCTAD. [consulta 30-03-20]. Disponible en: https://unctad.org/es/PublicationsLibrary/der2019_overview_es.pdf
 10En funciÃ³n del alcance y el Ã¡mbito de aplicaciÃ³n de la inteligencia artificial se diferencian tres categorÃ­as distintas de IA: las inteligencias artificiales fuertes, generales y dÃ©biles. La IA general podrÃ­a resolver cualquier tarea intelectual resoluble por un ser humano; la IA fuerte o superinteligencia irÃ­a mÃ¡s allÃ¡ de las capacidades humanas. 11AdecuaciÃ³n al RGPD de tratamientos que incorporan Inteligencia Artificial. Una introducciÃ³n. Agencia EspaÃ±ola de ProtecciÃ³n de Datos Personales, 2020 [consulta 13-03-20]. Disponible en: https://www.aepd.es/sites/default/files/2020-02/adecuacion-rgpd-ia.pdf
 12Disruptive technologies: Advances that will transform life, business, and the global economy, McKinsey Global Institute, 2013. [consulta 13-03-20]. Disponible en: https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/disruptive-technologies
 13
BLACK, Edwin. IBM y el Holocausto. La alianza estratÃ©gica entre la Alemania Nazi y la mÃ¡s poderosa corporaciÃ³n norteamericana, Buenos Aires: AtlÃ¡ntida, 2001, p. 18. 14âArtÃ­culo 11. ProtecciÃ³n de la Honra y de la Dignidad 1. Toda persona tiene derecho al respeto de su honra y al reconocimiento de su dignidad. 2. Nadie puede ser objeto de injerencias arbitrarias o abusivas en su vida privada, en la de su familia, en su domicilio o en su correspondencia, ni de ataques ilegales a su honra o reputaciÃ³n. 3. Toda persona tiene derecho a la protecciÃ³n de la ley contra esas injerencias o esos ataquesâ. 15âArtÃ­culo 17. 1. Nadie serÃ¡ objeto de injerencias arbitrarias o ilegales en su vida privada, su familia, su domicilio o su correspondencia, ni de ataques ilegales a su honra y reputaciÃ³n. 2. Toda persona tiene derecho a la protecciÃ³n de la Ley contra esas injerencias o esos ataquesâ. 16âArtÃ­culo 8. Derecho al respeto a la vida privada y familiar. 1. Toda persona tiene derecho al respeto de su vida privada y familiar, de su domicilio y de su correspondencia. 2. No podrÃ¡ haber injerencia de la autoridad pÃºblica en el ejercicio de este derecho, sino en tanto en cuanto esta injerencia estÃ© prevista por la ley y constituya una medida que, en una sociedad democrÃ¡tica, sea necesaria para la seguridad nacional, la seguridad pÃºblica, el bienestar econÃ³mico del paÃ­s, la defensa del orden y la prevenciÃ³n del delito, la protecciÃ³n de la salud o de la moral, o la protecciÃ³n de los derechos y las libertades de los demÃ¡sâ. 17Sentencia de 15 de diciembre de 1983 emitida por el Tribunal Constitucional Federal AlemÃ¡n. [consulta 13-03-20]. Disponible en: http://www.informatica-juridica.com/jurisprudencia/alemania.asp. El principio de consentimiento se analiza en esta Sentencia, anulando la Ley del Censo de PoblaciÃ³n de 1.982 y dio lugar a una revisiÃ³n sustancial de la ley federal de 1977, asÃ­ como las leyes del EjÃ©rcito y del Servicio Secreto. 18
Lefranc, Federico, âLa necesidad de reafirmar el principio de la dignidad humana en el Derecho del siglo XXIâ. MÃ©xico Revista Penal MÃ©xico. 2011, no. 2, p. 155, [consulta 13-03-20]. Disponible en: https://dialnet.unirioja.es/servlet/articulo?codigo=6158028. 19
LÃ³pez, Baroni, (2019). âLas narrativas de la inteligencia artificial. Revistaâ. En: BioÃ©tica y Derecho, No. 46, p. 13 [consulta 10-10-20]. Disponible en: https://revistes.ub.edu/index.php/RBD/article/view/27280
 20Adelantando un poco la respuesta respecto a los principios ahÃ­ establecidos y el resultado de la sociedad digital construida, podemos mencionar el informe anual del Alto Comisionado de las Naciones Unidas para los Derechos Humanos de 2014, denominado el Derecho a la Privacidad en la Era Digital, que deja en relieve la responsabilidad que hasta ahora han tenido las empresas para vulnerar la privacidad de las personas en el ciberespacio. [consulta 13-03-20]. Disponible en: https://icdppc.org/wp-content/uploads/2015/02/Resolution-on-Privacy-In-digital-Age-Spanish-version.pdf
 21
Giddens, A., Consecuencias de la Modernidad, Madrid: Alianza, 1993, p. 162. 22
Lefranc, F. Terra IncÃ³gnita. Bases para una polÃ­tica criminal pro persona en la sociedad digital, MÃ©xico: INFOTEC, 2015, p. 9. 23A pesar de que el concepto surge en un sistema de derecho perteneciente al common law, esta doctrina ha tenido un impacto provechoso en sistemas jurÃ­dicos del derecho continental, como en el caso de MÃ©xico, particularmente para la construcciÃ³n del derecho a la protecciÃ³n de datos personales. 24
Westin, A. Privacy and Freedom. Nueva York: Ateneum, 1967, p. 7. 25
Mendoza, O. DefiniciÃ³n de privacidad. En: Diccionario ProtecciÃ³n de Datos Personales, INAI, 2020, p. 672. [consulta 13-03-20]. Disponible en: http://inicio.inai.org.mx/PublicacionesComiteEditorial/DICCIONARIO_PDP_digital.pdf
 26
PiÃ±ar, J. âÂ¿Existe privacidad?, LecciÃ³n magistral impartida en la Apertura Solemne del Curso AcadÃ©mico en la Universidad San Pablo-CEU de Madridâ. En: ProtecciÃ³n de Datos Personales. Compendio de lecturas y legislaciÃ³n. MÃ©xico, 2010, Editorial Tiro Corto, p. 16. 27165823. 1a. CCXIV/2009. Primera Sala. Novena Ã©poca. Semanario Judicial de la FederaciÃ³n y su Gaceta. Tomo XXX, diciembre de 2009, p. 277. Derecho a la Vida Privada. Su contenido general y la importancia de no descontextualizar las referencias a la misma. [consulta 10-03-20]. Disponible en: http://sjf.scjn.gob.mx/sjfsist/Documentos/Tesis/165/165823.pdf. Fecha de consulta: 20 de agosto de 2018. 28El derecho a la privacidad no es un derecho absoluto y estarÃ¡ limitado a apreciaciones establecidas en precedentes judiciales como el grado de exposiciÃ³n pÃºblica de una persona, la trascendencia en las actividades que realiza, los alcances de protecciÃ³n de la libertad de expresiÃ³n, el interÃ©s pÃºblico, etc. 29
Ricci, D. ArtÃ­culo 16 Constitucional. Derecho a la privacidad. En: Derechos Humanos en la ConstituciÃ³n: comentarios de jurisprudencia constitucional Interamericana II. [en lÃ­nea]. MÃ©xico: Instituto de Investigaciones JurÃ­dicas, p. 1045. [consulta 2-03-20]. Disponible en: https://archivos.juridicas.unam.mx/www/bjv/libros/8/3567/39.pdf. 30
Contreras, Carlos. El papel del gobierno en la era digital: un enfoque de economÃ­a pÃºblica. 2017, Editorial Universitaria RamÃ³n Arces, p.p. 153 y 154. 31Este caso consistiÃ³ en que la empresa Cambridge Analytical tuvo acceso a los datos de unos 87 millones de usuarios de Facebook, segÃºn revelÃ³ la red social. La informaciÃ³n fue obtenida a travÃ©s de una aplicaciÃ³n que ofrecÃ­a realizar un test de personalidad pero que, en realidad usÃ³ ese acceso para recopilar datos de los usuarios y de sus redes de amigos hasta sumar hasta un 15% de la poblaciÃ³n de Estados Unidos. La empresa utilizÃ³ este material para elaborar perfiles psicolÃ³gicos de cada usuario y diseÃ±ar mensajes hechos a medida para tratar de influir en las elecciones presidenciales de Estados Unidos de 2016. [consulta 12-03-20]. Disponible en: https://www.bbc.com/mundo/noticias-43971491
 32En este punto, es fÃ¡cil escuchar discursos que criminalizan a los usuarios de sistemas de inteligencia artificial, por otorgar el consentimiento sin comprender las dimensiones del tratamiento de la informaciÃ³n, pero se debe tener en cuenta, primero la falta de educaciÃ³n digital de los usuarios (porque existe muy poca polÃ­tica pÃºblica efectiva de educaciÃ³n e inclusiÃ³n digital en MÃ©xico), en segundo lugar, los condicionamientos para la prestaciÃ³n de servicios necesarios, incluso aunque sean contrarios a las normas nacionales, tercero, la instrumentaciÃ³n de clÃ¡usulas de adhesiÃ³n en los contratos y cuarto, la responsabilidad final y Ãºnica de las corporaciones para insertar aspectos Ã©ticos en el tratamiento de datos, que pudieran generar confianza. 33MÃ©xico. ConstituciÃ³n PolÃ­tica de los Estados Unidos Mexicanos. Diario Oficial de la FederaciÃ³n el 5 de febrero de 1917. P. 17. 34A partir de la publicaciÃ³n de la Ley General de ProtecciÃ³n de Datos Personales en PosesiÃ³n de Sujetos Obligados (ley de datos cuyo Ã¡mbito de aplicaciÃ³n es el sector pÃºblico), se ha discutido si el reconocimiento en la norma de la portabilidad del dato debe considerarse o no una extensiÃ³n de los llamados derechos ARCO. En opiniÃ³n de la autora, la portabilidad no es mÃ¡s que una forma de manifestaciÃ³n del derecho de acceso a los datos personales. 35Op. Cit., nota 22, p. 44. 36AdecuaciÃ³n al RGPD de tratamientos que incorporan Inteligencia Artificial. Una introducciÃ³n. Agencia EspaÃ±ola de ProtecciÃ³n de Datos Personales, 2020 [consulta 11-03-20]. Disponible en: https://www.aepd.es/sites/default/files/2020-02/adecuacion-rgpd-ia.pdf
 37Tratado entre Estados Unidos de NorteamÃ©rica, CanadÃ¡ y MÃ©xico en materia comercial. [consulta 17-03-20]. Disponible en: https://www.gob.mx/t-mec
 38Se recomienda revisar las restricciones seÃ±aladas por la UniÃ³n Europea a Estados Unidos de NorteamÃ©rica y antecedentes como el Safeharbor. 39CapÃ­tulo 19 de Comercio Digital del TMEC. [consulta 17-03-20]. Disponible en: https://www.gob.mx/cms/uploads/attachment/file/465801/19ESPComercioDigital.pdf
 40Guidelines on Article 49 of Regulation 2016/679. Consejo de Europa, 2018, [consulta 30-03-20]. Disponible en: https://ec.europa.eu/newsroom/article29/item-detail.cfm?item_id=614232
 41El 16 de julio de 2020 el Tribunal de Justicia de la UniÃ³n Europea (TJUE) ha hecho pÃºblica una sentencia en la que anula la DecisiÃ³n 2016/1250 de la ComisiÃ³n que declaraba el nivel adecuado de protecciÃ³n del esquema del Escudo de Privacidad (Privacy Shield) para las transferencias internacionales de datos a EEUU. Esta DecisiÃ³n sustituÃ­a a su vez a Puerto Seguro que tambiÃ©n fue declarado invÃ¡lido por el TJUE en octubre de 2015. La sentencia, cuyas implicaciones marcan un nuevo punto de inflexiÃ³n sobre la forma en la que se realizan las transferencias internacionales de datos a EEUU, establece, a su vez, la validez de las clÃ¡usulas contractuales estÃ¡ndar adoptadas por la ComisiÃ³n Europea para realizar transferencias internacionales de datos entre un Responsable establecido en la UniÃ³n Europea y un Encargado del tratamiento fuera de la UE. [consulta 17-03-20]. Disponible en: https://curia.europa.eu/jcms/upload/docs/application/pdf/2015-10/cp150117es.pdf
 42La Ãºltima Sentencia es la STJUE (Gran Sala) del 16 de julio del 2020. Asunto Câ311/18 que tuvo por objeto resolver una peticiÃ³n de decisiÃ³n prejudicial planteada, con arreglo al artÃ­culo 267 TFUE, por la High Court (Tribunal Superior, Irlanda). 43Recomendaciones generales para el tratamiento de datos en la Inteligencia Artificial. Red Iberoamericana de ProtecciÃ³n de Datos, 2019, [consulta 18-03-20]. Disponible en: https://www.redipd.org/sites/default/files/2020-02/guia-recomendaciones-generales-tratamiento-datos-ia.pdf
 44Orientaciones especÃ­ficas para el cumplimiento de los principios y derechos que rigen la protecciÃ³n de datos personales en los proyectos de inteligencia artificial. Red Iberoamericana de ProtecciÃ³n de Datos, 2019, [consulta 18-03-20]. Disponible en: https://www.redipd.org/sites/default/files/2020-02/guia-orientaciones-espec%C3%ADficas-proteccion-datos-ia.pdf
 45AdecuaciÃ³n al Reglamento General de ProtecciÃ³n de Datos de tratamientos que incorporen Inteligencia Artificial. Agencia EspaÃ±ola de ProtecciÃ³n de Datos Personales. [consulta 18-03-20]. Disponible en: https://www.aepd.es/sites/default/files/2020-02/adecuacion-rgpd-ia.pdf
 Recibido:
				30 de Abril de 2020; Aprobado:
				10 de Noviembre de 2020 Â Este es un artÃ­culo publicado en acceso abierto bajo una licencia Creative Commons