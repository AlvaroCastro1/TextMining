Título: ¿Qué es un modelo de lenguaje grande? | Una guía de LLM integral | Elastic
URL: https://www.elastic.co/es/what-is/large-language-models
Número de palabras: 2170

Soluciones de observabilidad, seguridad y búsqueda; impulsadas por Elasticsearch Platform. Búsqueda y analíticas, ingesta de datos y visualización; todo al alcance de tu mano. Encuentra respuestas que importan con Elastic en tu Proveedor Cloud preferido. Unifica la visibilidad de las aplicaciones e infraestructura para resolver problemas de forma proactiva. Protege, investiga y responde a amenazas cibernéticas rápido y a escala. Acelera los resultados de búsqueda en cualquier cloud y aumenta la personalización. Brinda a los clientes la flexibilidad, velocidad y escala para encontrar qué sigue. Cisco ahorra 5000 horas de ingenieros de soporte al mes Sitecore automatiza el 96 por ciento de los flujos de trabajo de seguridad con Elastic Comcast transforma las experiencias de los clientes con Elastic Observability Adéntrate en todo lo relacionado con el código, foros y grupos. Mantente actualizado respecto a los temas técnicos más recientes, innovaciones y noticias. Aumenta tus habilidades y abre puertas para el éxito futuro. Encuentra el soporte que necesitas, independientemente del tema. Ve nuestra galería de demostración Primeros pasos con Elasticsearch Novedades en Elastic 8.13 Un modelo de lenguaje grande es un algoritmo de aprendizaje profundo que puede realizar una variedad de tareas de procesamiento de lenguaje natural (NLP). Los modelos de lenguaje grandes usan modelos de transformadores y están entrenados con sets de datos enormes; por consiguiente, grandes. Esto les permite reconocer, traducir, predecir o generar texto u otro contenido. Los modelos de lenguaje grandes también se denominan redes neuronales (NN), que son sistemas informáticos inspirados en el cerebro humano. Estas redes neuronales funcionan con una red de nodos en capas, similar a las neuronas. Además de enseñar lenguajes humanos a aplicaciones de inteligencia artificial (AI), los modelos de lenguaje grandes también pueden entrenarse para realizar una variedad de tareas, como comprender las estructuras de proteínas, escribir código de software y más. Tal como el cerebro humano, los modelos de lenguaje grandes deben preentrenarse y luego ajustarse para poder resolver problemas de clasificación de textos, respuesta a preguntas, resumen de documentos y generación de texto. Sus capacidades de solución de problemas pueden aplicarse a campos como la atención médica, las finanzas y el entretenimiento, en donde los modelos de lenguaje grandes se usan para una variedad de aplicaciones de NLP, como traducción, chatbots, asistentes de AI, etc. Los modelos de lenguaje grandes también tiene grandes cantidades de parámetros que son semejantes a recuerdos que recopila el modelo a medida que aprende del entrenamiento. Piensa en estos parámetros como el banco de conocimientos del modelo. Un modelo de transformadores es la arquitectura más común de un modelo de lenguaje grande. Consiste en un codificador y un decodificador. Un modelo de transformadores procesa datos tokenizando la entrada y luego, simultáneamente, realizando ecuaciones matemáticas para descubrir relaciones entre los tokens. Esto permite a la computadora ver los patrones que un humano vería si recibiera la misma búsqueda.  Los modelos de transformadores trabajan con mecanismos de autoatención, lo que permite al modelo aprender con más rapidez que los modelos tradicionales, como los modelos de memoria de corto/largo plazo. La autoatención es lo que permite al modelo de transformadores considerar distintas partes de la secuencia o el contexto completo de una oración para generar predicciones. Los modelos de lenguaje grandes están compuestos de varias capas de redes neuronales. Las capas recurrentes, capas feedforward (unidireccionales), capas de incrustación y capas de atención trabajan en conjunto para procesar el texto de entrada y generar contenido de salida. La capa de incrustación crea incrustaciones desde el texto de entrada. Esta parte del modelo de lenguaje grande captura el significado semántico y sintáctico de la entrada, de modo que el modelo puede comprender el contexto. La capa feedforward (FFN) de un modelo de lenguaje grande está compuesta por varias capas completamente conectadas que transforman las incrustaciones de entrada. Al hacerlo, estas capas permiten al modelo obtener abstracciones de nivel más alto; es decir, comprender la intención del usuario con la entrada de texto. La capa recurrente interpreta las palabras en el texto de entrada en secuencia. Captura la relación entre las palabras en una oración. El mecanismo de atención permite al modelo de lenguaje enfocarse en partes individuales del texto de entrada que son relevantes para la tarea en cuestión. Esta capa permite al modelo generar las salidas más precisas. Aplica transformadores a tus aplicaciones de búsqueda Existen tres tipos principales de modelos de lenguaje grandes: La AI generativa es un término general que se refiere a los modelos de inteligencia artificial que tienen la capacidad de generar contenido. La AI generativa puede generar texto, código, imágenes, video y música. Algunos ejemplos de AI generativa incluyen Midjourney, DALL-E y ChatGPT. Los modelos de lenguaje grandes son un tipo de AI generativa que se entrenan con texto y producen contenido de texto. ChatGPT es un ejemplo popular de AI de texto generativa. Todos los modelos de lenguaje grandes son AI generativa1. Un modelo de lenguaje grande se basa en un modelo de transformadores y funciona recibiendo una entrada, codificándola y luego decodificándola para producir una predicción de salida. Pero para que un modelo de lenguaje grande pueda recibir la entrada de texto y generar una predicción de salida, se debe entrenar para poder realizar funciones generales y se debe ajustar, lo que le permite realizar tareas específicas. Capacitación: los modelos de lenguaje grandes se preentrenan con sets de datos textuales grandes de sitios como Wikipedia, GitHub u otros. Estos sets de datos consisten en billones de palabras, y su calidad afectará el rendimiento del modelo de lenguaje. En este punto, el modelo de lenguaje grande realiza un aprendizaje no supervisado, lo que significa que procesa los sets de datos que se le proporcionan sin instrucciones específicas. Durante este proceso, el algoritmo de AI del LLM puede aprender el significado de palabras y de las relaciones entre las palabras. También aprende a distinguir palabras según el contexto. Por ejemplo, aprenderá a comprender si "derecha" significa "recta" o lo opuesto de "izquierda". Ajuste: para que un modelo de lenguaje grande realice una tarea específica, como la traducción, debe ajustarse para dicha actividad en particular. El ajuste optimiza el rendimiento de tareas específicas. El ajuste de solicitudes cumple una función similar de ajuste, por la cual entrena un modelo para realizar una tarea específica a través de few-shot prompting o zero-shot prompting. Una solicitud es una instrucción dada a un LLM. Few-shot prompting enseña al modelo a predecir salidas a través del uso de ejemplos. Por ejemplo en este ejercicio de análisis de sentimiento, un few-shot prompt se vería así: El modelo de lenguaje entendería, a través de la semántica, el significado de "hideous", y como se proporcionó un ejemplo opuesto, que el sentimiento del cliente en el segundo ejemplo es negativo ("negative"). Como alternativa, el zero-shot prompting no usa ejemplos para enseñar al modelo de lenguaje cómo responder a las entradas. En su lugar, formula la pregunta como "El sentimiento en ‘This plant is so hideous' es…". Indica claramente qué tarea debe realizar el modelo de lenguaje, pero no proporciona ejemplos de resolución de problemas. Los modelos de lenguaje grandes pueden usarse con varios fines: Además de estos casos de uso, los modelos de lenguaje grandes pueden completar oraciones, responder preguntas y resumir texto. Con una variedad tan amplia de aplicaciones, las aplicaciones de lenguaje grandes pueden encontrarse en una gran variedad de campos: Con un amplio rango de aplicaciones, los modelos de lenguaje grandes son excepcionalmente beneficiosos para la solución de problemas, dado que brindan información en un estilo claro y conversacional que es fácil de comprender para los usuarios. Conjunto grande de aplicaciones: se pueden usar para traducir idiomas, completar oraciones, realizar el análisis de sentimiento, responder preguntas, resolver ecuaciones matemáticas y más. Mejora continua: el rendimiento de los modelos de lenguaje grandes mejora continuamente dado que crece cuando se agregan más datos y parámetros. En otras palabras, cuanto más aprende, mejor se vuelve. Además, los modelos de lenguaje grandes pueden mostrar lo que se denomina "aprendizaje en contexto". Una vez que un LLM se preentrenó, few-shot prompting permite al modelo aprender de la solicitud sin parámetros adicionales. De este modo, aprende de manera continua. Aprendizaje rápido: al demostrar aprendizaje en contexto, los modelos de lenguaje grandes aprenden rápido porque no requieren ponderación adicional, recursos ni parámetros para el entrenamiento. Es rápido en el sentido de que no requiere demasiados ejemplos. Los modelos de lenguaje grandes pueden darnos la impresión de que comprenden el significado y pueden responder a este con precisión. Sin embargo, siguen siendo una herramienta tecnológica y, como tal, los modelos de lenguaje grandes se enfrentan a una variedad de desafíos. Alucinaciones: una alucinación es cuando un LLM produce una salida falsa o que no coincide con la intención del usuario. Por ejemplo, alega ser humano, que tiene emociones o que está enamorado del usuario. Como los modelos de lenguaje grandes predicen la siguiente palabra o frase sintácticamente correcta, no pueden interpretar por completo el significado humano. El resultado, en ocasiones, puede ser lo que se conoce como una "alucinación". Seguridad: los modelos de lenguaje grandes presentan riesgos de seguridad importantes si se gestionan o supervisan correctamente. Pueden filtrar información privada de las personas, participar en fraudes de phishing y producir spam. Los usuarios con intenciones malintencionadas pueden programar la AI conforme a sus ideologías o sesgos, y contribuir a la distribución de información errónea. Las repercusiones pueden ser devastadoras a escala global. Sesgo: los datos usados para entrenar modelos de lenguaje afectarán las salidas que produce un modelo dado. De este modo, si los datos representan una sola demografía o no tiene suficiente diversidad, a las salidas que produzca el modelo de lenguaje grande también les faltará diversidad. Consentimiento: los modelos de lenguaje grandes se entrenan con billones de sets de datos; algunos de ellos pueden no haberse obtenido de forma consensuada. Al raspar datos de internet, se sabe que los modelos de lenguaje grandes ignoran las licencias de derechos de autor, plagian el contenido escrito y reutilizan contenido confidencial sin obtener permiso de los artistas o propietarios originales. Cuando produce resultados, no hay forma de rastrear la procedencia de los datos y, en general, no se da crédito a los creados, lo cual puede exponer a los usuarios a problemas por infringir los derechos de autor. También es posible que raspen datos personales, como nombres de sujetos o fotógrafos de las descripciones de las fotos, lo cual puede comprometer la privacidad.2 Los LLM ya han sido demandados; incluida una importante demanda de Getty Images3, por infringir la propiedad intelectual. Escalado: puede ser difícil y demandar mucho tiempo y recursos escalar y mantener los modelos de lenguaje grandes. Despliegue: desplegar modelos de lenguaje grandes requiere aprendizaje profundo, un modelo de transformadores, hardware y software distribuidos, y experiencia técnica general. Los modelos de lenguaje grandes han conquistado el mundo. Muchos han sido adoptados por personas en todas las industrias. Sin dudas has oído hablar de ChatGPT, una forma de chatbot de AI generativa. Otros modelos de LLM populares incluyen: La llegada de ChatGPT ha llevado a los modelos de lenguaje grandes al primer plano y activado la especulación y el debate acalorado sobre cómo podría verse el futuro.  A medida que los modelos de lenguaje grandes continúan creciendo y mejorando su manejo del lenguaje natural, hay mucha inquietud respecto al impacto de sus avances en el mercado laboral. Está claro que los modelos de lenguaje grandes desarrollarán la capacidad para reemplazar trabajadores en ciertos campos.  En las manos adecuadas, los modelos de lenguaje grandes tienen la capacidad para aumentar la productividad y la eficiencia de los procesos, pero esto ha planteado interrogantes sobre su uso en la sociedad humana. Para abordar las limitaciones actuales de los LLM, Elasticsearch Relevance Engine (ESRE) es un motor de relevancia creado para aplicaciones de búsqueda impulsadas por inteligencia artificial. Con ESRE, los desarrolladores están facultados para crear su propia aplicación de búsqueda semántica, utilizar sus propios modelos de transformadores y combinar NLP con AI generativa para mejorar la experiencia de búsqueda de sus clientes. Supercarga tu relevancia con Elasticsearch Relevance Engine  1 Myer, Mike. “Are Generative AI and Large Language Models the Same Thing?” (¿Son lo mismo la AI generativa y los modelos de lenguaje grandes?) Quiq, 12 de mayo de 2023, quiq.com/blog/generative-ai-vs-large-language-models/. 2 Sheng, Ellen. “In generative AI legal Wild West, the courtroom battles are just getting started” (En el Lejano Oeste legal de la AI generativa, las batallas en la Corte recién comienzan) CNBC, 3 de abril de 2023, https://www.cnbc.com/2023/04/03/in-generative-ai-legal-wild-west-lawsuits-are-just-getting-started.html (Último acceso el 29 de junio de 2023) 3 Declaración de Getty Images, Getty Images, 17 de enero de 2023 https://newsroom.gettyimages.com/en/getty-images/getty-images-statement (Último acceso el 29 de junio de 2023) © . Elasticsearch B.V. Todos los derechos reservados Elastic, Elasticsearch y otras marcas asociadas son marcas comerciales, logotipos o marcas comerciales registradas de Elasticsearch B.V. en los Estados Unidos y otros países. Apache, Apache Lucene, Apache Hadoop, Hadoop, HDFS y el logotipo del elefante amarillo son marcas comerciales de Apache Software Foundation en los Estados Unidos o en otros países.