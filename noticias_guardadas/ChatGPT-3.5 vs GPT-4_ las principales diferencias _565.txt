Título: ChatGPT-3.5 vs GPT-4: las principales diferencias entre los modelos de OpenAI, explicadas
URL: https://www.genbeta.com/comparativa/chatgpt-3-5-vs-gpt-4-principales-diferencias-explicadas
Número de palabras: 976

Eva Rodriguez de Luis Si con ChatGPT-3.5 la sensación era la misma que cuando usamos internet por primera vez (la frase y el artículo es de Javier Lacort, pero la hago propia porque siento lo mismo), GPT-4 va un paso más allá. Aunque no integra todas las especificaciones rumoreadas, la realidad es que mejora considerablemente la experiencia respecto a ChatGPT-3.5 pero, ¿en qué se diferencian ChatGPT- 3.5 y GPT-4? Mientras que GPT-3.5 solo acepta peticiones en texto, GPT-4 es multimodal, es decir, admite entradas en texto y visuales. O lo que es lo mismo: no tiene por qué ser una imagen con texto escrito (aunque valdría), si no que vale cualquier cosa, desde una fotografía de un paisaje a un problema matemático manuscrito pasando por un meme. GPT-4 es capaz de comprender y describir prácticamente cualquier imagen. Es decir, que GPT-4 ya no es "solo" un modelo de lenguaje por Inteligencia Artificial, si no también un modelo visual. Entre sus posibilidades está la de identificar objetos concretos dentro de una foto con muchos elementos visuales. Durante la presentación de GPT-4, alguien del equipo de OpenAI suministró una captura de pantalla de un servidor de Discord y la nueva versión describió cada detalle, hasta los nombres de los usuarios en línea. Hasta unos sencillos garabatos con el esquema de una web basta para convertirlo en un código para llevarlo a cabo. 1️⃣ Multimodal: GPT-4 API can accept images as inputs, can analyze captions and the image. Can understand memes and insider jokes. pic.twitter.com/INLCqJ0l9T Uno de los grandes defectos y peligros de ChatGPT-3.5 es su habilidad para generar información sin sentido y que parece cierta pero que no lo es, lo que técnicamente se conoce como una "alucinación de IA". Desgraciadamente, con la nueva versión también somos susceptibles de sufrirla, pero según el informe técnico de GPT-4, el nuevo modelo tiene entre un 19 y un 29% menos de probabilidad de alucinar con respecto a GPT-3.5. Pero más allá de este paper, las pruebas nos remiten a una respuestas más objetivas. Si bien ChatGPT-3.5 nos dejó con la boca abierta con su "inteligencia" y habilidad para resolver problemas de acuerdo con sus necesidades, la nueva versión combina la arquitectura Transformer (presentada por Google en 2017) con la estructura de nube de Azure con los ordenadores de Microsoft y chips A100 de NVIDIA. ¿El objetivo? Lograr un rendimiento a nivel humano. Así, comparado con  GPT-3.5, GPT-4 superó las pruebas para conseguir unos resultados mucho mejores, aunque no exento de fallos o respuestas que reproducen problemas sociales. Una de las grandes ventajas de la nueva versión es su capacidad para proporcionar respuestas más creativas a nuestros prompts. Vaya por delante que ChatGPT-3.5 ya era creativo y para muestra, este artículo con algunas de sus mejores aplicaciones y ya se postula como el mejor dentro de su segmento. Pero GPT-4 da un paso más. Aunque este plus creativo no se aprecia en la resolución de problemas básicos, la mejora en la creatividad queda patente conforme la tarea se vuelve más difícil y requiere de más ingenio. Entre sus habilidades está componer canciones hasta escribir guiones o aprender el estilo de escritura del usuario con mucha más precisión y calidad que las versiones anteriores. Aunque GPT-4 no es perfecto, cuenta con las medidas suficientes para garantizar respuestas más seguras y solo por eso ya merece dar el paso a la nueva versión. Porque con ChatGPT-3.5, OpenAI adoptó un enfoque de seguridad basado en la moderación a posteriori. Es decir, que después de monitorizar la respuesta de la máquina después de ciertas interacciones de los usuarios, identificó los fallos y los solventó sobre la marca. Con GPT-4 las medidas de seguridad ya están integradas en el sistema. Estableciendo una analogía en el sector de la construcción: la nueva versión está construída con los materiales más resistentes frente a la anterior, que fue construída de cierta manera y reparada al momento. Visto con la frialdad y la objetividad de las cifras, según el informe técnico de OpenAI, GPT-4 genera un 0,73% de respuestas "tóxicas" frente al 6,48% de ChatGPT-3.5. Asimismo, GPT-4 es un 82% menos probable que responda a solicitudes de contenido no permitido y 40% más probable que ofrezca respuestas objetivas frente a su precedesor. Se ha hablado menos de la diferencia entre GPT-4 y GPT-3.5 de la ventana de contexto y su tamaño, dos conceptos que marcan la diferencia en la experiencia. Así, la ventana de contexto es la cantidad de datos que un modelo puede retener en su memoria durante una sesión de chat y durante cuánto tiempo. En este escenario,  GPT-4 ofrece una ventana y tamaño de contexto significativamente superior a su predecesor. De forma práctica, GPT-4 puede recordar mejor el contexto de una conversación durante más tiempo, así como las instrucciones proporcionadas en esa sesión. Y es que uno de los problemas de ChatGPT-3.5 era su tendencia a salirse del tema o a no seguir las instrucciones conforme avanzaba la conversación. Un ejemplo sencillo: pedirle que se dirija a ti por tu nombre. Otro aspecto que GPT-4 mejora es la cantidad de texto a introducir. En la versión anterior era común tener dividir el texto de entrada en varios fragmentos para proceder, pero GPT-4 ha mejorado la longitud del contexto, lo que se traduce en que hasta puedes pegar PDFs completos de una sola vez para que te lo resuma. En Genbeta | GPT-4, el nuevo 'cerebro' de ChatGPT, nos permitirá comunicarnos con imágenes con el chatbot de moda. Pero no es la única novedad Portada | Montaje con logo de OpenAI + foto de Mark Chan en Unsplash Los mejores comentarios: Ver 1 comentarios En Genbeta hablamos de... Ver más temas 
Webedia
  Tecnología   Videojuegos   Entretenimiento   Gastronomía   Estilo de vida  
             Latinoamérica
            
Ver más temas
 
Suscribir Más sitios que te gustarán Reciente Ver más artículos  Xataka
     TV
 Ver más vídeos