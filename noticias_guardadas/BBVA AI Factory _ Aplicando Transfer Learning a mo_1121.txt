Título: BBVA AI Factory | Aplicando Transfer Learning a modelos de lenguaje natural
URL: https://www.bbvaaifactory.com/es/applying-transfer-learning-to-natural-language-models/
Número de palabras: 1215

Dentro de la Inteligencia Artificial, el Procesamiento de Lenguaje Natural (NLP por sus siglas en inglÃ©s) ha sido uno de los campos clave desde los orÃ­genes. Al fin y al cabo, el lenguaje es una de las cosas mÃ¡s ligadas a  la inteligencia humana. En los Ãºltimos aÃ±os este campo ha sufrido una nueva revoluciÃ³n semejante a la que hace 20 aÃ±os supuso la introducciÃ³n de las tÃ©cnicas estadÃ­sticas y de aprendizaje automÃ¡tico (Machine Learning). Esta revoluciÃ³n la abanderan nuevos modelos basados en redes neuronales profundas que facilitan la codificaciÃ³n de la informaciÃ³n lingÃ¼Ã­stica y la posibilidad de reutilizaciÃ³n en diversas aplicaciones. Con la apariciÃ³n en 2018 de modelos de lenguaje auto-supervisados como BERT (Google), entrenados sobre una ingente cantidad de texto, se inicia una Ã©poca en la que la Transferencia de Aprendizaje (Transfer Learning) empieza a ser una realidad prÃ¡ctica para NLP, tal y como lo ha sido para el campo de la VisiÃ³n Artificial desde 2013. El concepto de Transferencia de Aprendizaje se basa en la idea de reutilizar el conocimiento adquirido realizando una tarea para abordar nuevas tareas que son similares. En realidad, es una prÃ¡ctica que los humanos llevamos a cabo constantemente en nuestro dÃ­a a dÃ­a. Aunque afrontamos nuevos retos, nuestra experiencia nos permite abordar los problemas desde un estadÃ­o mÃ¡s avanzado. La mayorÃ­a de algoritmos de aprendizaje automÃ¡tico (Machine Learning), en particular si son supervisados, solo pueden resolver la tarea para la que han sido entrenados mediante ejemplos. Si lo llevamos al mundo culinario, el algoritmo serÃ­a como un cocinero sÃºper especializado, entrenado para realizar una Ãºnica receta. Pedirle una receta diferente a este algoritmo puede tener consecuencias no deseadas, como realizar predicciones incorrectas o incorporar sesgos. El objetivo de utilizar Transferencia de Aprendizaje es que nuestro cocinero -que es el mejor cocinando ravioli carbonara- sea capaz de aplicar lo aprendido para alcanzar un Ã©xito razonable cocinando unos spaguetti a la boloÃ±esa. Aunque la salsa sea diferente, puede reutilizar el conocimiento adquirido a la hora de cocer la pasta (figura 1). Este mismo concepto de reutilizaciÃ³n de conocimiento, aplicado al desarrollo de modelos de Procesamiento de Lenguaje Natural (NLP), es el que hemos explorado en una colaboraciÃ³n con Vicomtech, un Centro de InvestigaciÃ³n del PaÃ­s Vasco especializado en tÃ©cnicas de interacciÃ³n humano-mÃ¡quina basadas en inteligencia artificial. En concreto, el objetivo de este trabajo conjunto ha sido conocer las aplicaciones que tiene la Transferencia de Aprendizaje y valorar los resultados que ofrecen estas tÃ©cnicas, pues vemos que pueden ser aplicables en las interacciones en lenguaje natural entre clientes y gestores de BBVA. DespuÃ©s de todo, el propÃ³sito que perseguimos con este trabajo no es otro que mejorar la forma en la que nos relacionamos con nuestros clientes. Una de las tareas que hemos abordado ha consistido en el procesamiento de informaciÃ³n textual en diferentes idiomas. Para ello, hemos utilizado conjuntos de datos de dominio pÃºblico. Es el caso de un dataset de opiniones de restaurantes, generado para la competiciÃ³n acadÃ©mica Semeval 2016, que incluye reseÃ±as en inglÃ©s, espaÃ±ol, francÃ©s, ruso, turco, Ã¡rabe y chino. El objetivo ha sido identificar los diferentes aspectos o caracterÃ­sticas que se mencionan (comida, ambiente o servicio al cliente, entre otros), en inglÃ©s, espaÃ±ol y francÃ©s. En la siguiente tabla se muestra el volumen de datos de los distintos idiomas. Con este ejercicio querÃ­amos validar si las tÃ©cnicas de Transferencia de Aprendizaje basadas en el uso de modelos BERT eran apropiadas para adaptar un clasificador multiclase que detectase los aspectos en diferentes idiomas. Frente a este enfoque, existen alternativas basadas en la traducciÃ³n del texto para adaptarla a un Ãºnico idioma. Esto lo podemos hacer traduciendo la informaciÃ³n que utilizaremos para entrenar el modelo, por un lado, o bien traduciendo directamente las conversaciones de los clientes que queremos clasificar. Sin embargo, estas alternativas tambiÃ©n encierran problemas e ineficiencias. Recuperando el ejemplo culinario que comentÃ¡bamos al inicio de este artÃ­culo, en nuestro caso podrÃ­amos considerar que el texto del que disponemos son los ingredientes de la receta. Estos âdatasetsâ de informaciÃ³n son diferentes de un idioma a otro (de igual modo que los ingredientes varÃ­an segÃºn la receta). Por otro lado, la capacidad adquirida por el modelo para clasificar los textos es un conocimiento que podemos reutilizar en varios idiomas; del mismo modo que reutilizamos el conocimiento sobre cÃ³mo cocer la pasta en recetas diferentes. En este experimento hemos partido de un modelo pre-entrenado BERT multilingÃ¼e de dominio pÃºblico, y hemos realizado un ajuste fino (fine tuning) sobre el dataset de restaurantes. En la siguiente figura se muestra el procedimiento (figura 2). Los resultados obtenidos adaptando este modelo, entrenado con dato genÃ©rico, al dataset de reseÃ±as en cada idioma, fueron similares a los reportados en 2016 para la tarea en inglÃ©s, francÃ©s y espaÃ±ol por modelos mÃ¡s especializados. Esto es consistente con los resultados de diferentes trabajos de investigaciÃ³n sobre la capacidad de este tipo de modelos de alcanzar muy buenos resultados. Una vez ajustado un clasificador para texto en inglÃ©s, el proceso de Transferencia de Aprendizaje entre idiomas lo llevamos a cabo realizando una segunda etapa de fine tuning con el dataset del segundo idioma (figura 3). Para medir la efectividad del proceso comparamos el comportamiento de este clasificador con el comportamiento resultante de realizar una Ãºnica etapa de ajuste fino partiendo del modelo base multilingÃ¼e. Los resultados nos indican (ver tabla 2) que, partiendo del modelo en inglÃ©s y utilizando menos datos del idioma de destino (espaÃ±ol o francÃ©s, en este caso) podemos alcanzar resultados similares a los que obtenemos al adaptar un modelo para cada idioma. Por ejemplo, en el caso del espaÃ±ol, alcanzamos un desempeÃ±o muy similar si partimos del modelo en inglÃ©s y aÃ±adimos sÃ³lo el 40% de dato en espaÃ±ol. Por otro lado, en el caso del francÃ©s, los resultados se empiezan a igualar al utilizar el modelo en inglÃ©s y el 80% del dato en francÃ©s. Por Ãºltimo, si utilizamos todos los datos disponibles, los resultados mejoran de forma moderada si los comparamos con los resultados que alcanzamos al entrenar solo con los datos de cada idioma. En cambio, la mejora es notable respecto a usar el modelo en inglÃ©s para el resto de idiomas. Es importante tener en cuenta que estos resultados van a depender de la tarea concreta en la que se aplican. Los diferentes resultados obtenidos con este experimento son muy esperanzadores desde el punto de vista de aplicaciÃ³n en problemas reales, ya que nos estarÃ­an indicando que los modelos son capaces de utilizar el conocimiento adquirido en un idioma para extrapolarlo a otro, obteniendo la misma calidad con menos dato etiquetado. De hecho, uno de los principales obstÃ¡culos al desarrollar cualquier funcionalidad de NLP en un entorno industrial es disponer de una gran cantidad de datos de calidad, y tener que desarrollarlo para cada uno de los idiomas. Por lo tanto, requerir de menos dato etiquetado siempre es una gran ventaja a la hora de desarrollar las funcionalidades. El conocimiento obtenido a raÃ­z de esta colaboraciÃ³n con Vicomtech nos va a permitir, de esta forma, construir de forma mÃ¡s Ã¡gil funcionalidades de ayuda al gestor en su relaciÃ³n con el cliente, permitiendo reducir el ciclo de desarrollo de un caso de uso en un idioma o canal distinto a aquel en el que originalmente se implementÃ³.