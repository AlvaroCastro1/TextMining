Título: Versus: OpenAI GPT-4 vs. Google Gemini Pro vs. Mistral AI Large
 - Paradigma
URL: https://www.paradigmadigital.com/dev/versus-openai-gpt4-google-gemini-pro-mistral-ai-large/
Número de palabras: 2325

Â¿Buscas nuestro logo? AquÃ­ te dejamos una copia, pero si necesitas mÃ¡s opciones o quieres conocer mÃ¡s, visita nuestra Ã¡rea de marca. 

Revamping Simyo.

                                    Revamping simyo.
                                

 

IMAT - Play Graph. Naturgy.

                                    La inteligencia de datos acelera la transformaciÃ³n de Naturgy
                                

 

Telefonica.com

                                    La nueva TelefÃ³nica.com
                                

 

                  ConÃ³celos todos.
              
 dev Inteligencia Artificial 
3 autores


                            17/04/2024
                        

Cargando comentariosâ¦
 El mundo de la IA generativa ha experimentado un gran crecimiento en el Ãºltimo aÃ±o y medio debido a la viralizaciÃ³n de la disciplina tras la salida al mercado de ChatGPT en noviembre de 2022. Ahora mismo hay dos maneras de interactuar con esta tecnologÃ­a: a travÃ©s de las plataformas habilitadas por las compaÃ±Ã­as para un acceso sencillo y para cualquier usuario, y mediante sus APIs, pensadas para el desarrollo de soluciones industrializables. Ambas tienen detrÃ¡s los mismos modelos, pero difieren en la manera en la que se utilizan. En este post nos centraremos en los modelos, no prestando atenciÃ³n a las plataformas donde el gran pÃºblico tiene acceso a estas herramientas. Enfrentaremos a GPT-4, el modelo mÃ¡s avanzado de OpenAI, con Gemini Pro de Google, y con el recientemente publicado Mistral Large, de Mistral AI. En el mundo de la IA generativa existen mÃºltiples modelos que han sido lanzados al mercado desde que OpenAI abriera la veda con ChatGPT. En esta primera secciÃ³n describiremos cuÃ¡les son las generalidades de cada uno de los modelos de relevancia para este artÃ­culo. OpenAI pegÃ³ primero y pegÃ³ dos veces. Cuando sacÃ³ al mercado ChatGPT, lo hizo con el modelo GPT-3 detrÃ¡s. En los meses venideros evolucionÃ³, y a dÃ­a de hoy su versiÃ³n gratuita cuenta con GPT-3.5 detrÃ¡s, y la de pago, llamada âPlusâ, con GPT-4. La relevancia de ser la primera queda patente en quÃ© modelo prefiere tanto el usuario medio como las empresas. Hemos visto en documentaciones de herramientas de IA generativa, como LangChain, LangSmith o Langfuse, que el modelo de pruebas suele ser casi siempre el de OpenAI. Esto le ha permitido a la empresa obtener una ventaja competitiva respecto a sus competidores. AdemÃ¡s, los de San Francisco han rodeado a su modelo estrella con lo que llaman tools basadas en modelos independientes que lo hacen un modelo capaz de producir y analizar imÃ¡genes, transcripciones, pequeÃ±as bases de datos, y desde hace muy poco, audio y vÃ­deo. Google respondiÃ³ a OpenAI con el lanzamiento de Gemini 1.0 en diciembre del 2023. Se ponÃ­a asÃ­ a la altura de OpenAI en cuanto a modelos de lenguaje. Una de sus principales caracterÃ­sticas y diferencias con GPT-4 consiste en que es multimodal desde el entrenamiento, pudiendo entender y generar texto, imÃ¡genes, audio, vÃ­deo y cÃ³digo. Gemini viene en tres tallas: ULTRA, el mÃ¡s capaz. PRO, para tareas cotidianas y NANO, pensado para ser ejecutado en los telÃ©fonos mÃ³viles. En esta comparativa nos basaremos en su versiÃ³n intermedia. A los grandes gigantes americanos que solo parecÃ­an tener competencia dentro de sus fronteras se les suma el parisino Mistral Large. Large es el modelo mÃ¡s reciente lanzado por Mistral AI, con capacidades de generaciÃ³n de texto. SegÃºn indican, puede alcanzar capacidades de razonamiento de primer nivel en tareas complejas de razonamiento multilingÃ¼e, como comprender textos, transformarlos e incluso, como ya hemos visto en otros modelos de este tipo, generar cÃ³digo fuente. Como hemos indicado, se pueden usar estos modelos a travÃ©s de las plataformas de sus empresas, o a travÃ©s de APIs. La manera mÃ¡s sencilla, pero no gratuita, de acceder a GPT-4 es a travÃ©s de ChatGPT Plus. La mejora de plan respecto al gratuito permite usar este modelo para el anÃ¡lisis de datos, generaciÃ³n de imÃ¡genes, tener una conversaciÃ³n por voz con el modelo (que funciona muchÃ­simo mejor en inglÃ©s que en otras lenguas), e integrarlo con los GPTs, que son las modificaciones personalizadas e integrables que los usuarios hacen del modelo. Cabe destacar que se puede acceder a GPT-4 de manera gratuita a travÃ©s de Microsoft Copilot en el buscador Microsoft Edge (cuenta tambiÃ©n con versiÃ³n de pago) o el motor de bÃºsqueda Bing AI. GPT-4 tambiÃ©n es accesible a travÃ©s del Playground de OpenAI dentro de su pÃ¡gina web. Si queremos crear herramientas basadas en GPT-4 a nivel empresarial, deberemos acceder a Ã©l a travÃ©s de la API, para la que necesitaremos registrarnos en OpenAI, y crear una llave API, con la que podremos acceder a diferentes versiones de GPT-4, asÃ­ como a numerosos parÃ¡metros de configuraciÃ³n. Para el caso de acceder a travÃ©s de la API, tambiÃ©n estÃ¡ disponible a travÃ©s de Azure OpenAI Service. AdemÃ¡s, GPT-4 estÃ¡ detrÃ¡s de otros productos de IA generativa, como el asistente de cÃ³digo Github Copilot, y del producto de la startup americana Perplexity AI. La manera mÃ¡s fÃ¡cil de empezar a usar Gemini es mediante la aplicaciÃ³n de Google con el mismo nombre (antes conocida como Bard) pues da la casualidad de que el producto Gemini usa por detrÃ¡s el modelo de Gemini Pro. Gemini estÃ¡ disponible en EspaÃ±a en cuentas personales, pero aÃºn no de empresa a travÃ©s de Google Workspace. Si lo que queremos es usar el modelo de una manera mÃ¡s directa, la siguiente opciÃ³n es usar la consola de Google Cloud Platform en su apartado de Vertex AI Studio, donde podemos realizar llamadas, editar y guardar prompts y cambiar los parÃ¡metros de configuraciÃ³n de modelo. Mistral Large se puede probar de distintas formas. La forma mÃ¡s directa aunque haya lista de espera para acceder, es utilizando este nuevo modelo desde la interfaz de usuario que proporcionan en su web, llamado Le Chat. Similar al Playground de OpenAI, Mistral AI ofrece la posibilidad de acceder a sus modelos a travÃ©s de La Plateforme, alojada en la infraestructura propia de Mistral AI en Europa, proporcionan un endpoint que permite hacer llamadas para asÃ­ poder crear aplicaciones o servicios de forma directa. Igual que ocurrÃ­a con OpenAI, se puede acceder a los modelos a travÃ©s de Azure. Actualmente, estÃ¡ disponible a travÃ©s de Azure AI Studio y Azure Machine Learning a travÃ©s del API que proveen. Eso sÃ­, solo lo podremos encontrar en las regiones de âEast US 2â o âFrance Centralâ. La Ãºltima forma de poder consumir este modelo es a travÃ©s de un despliegue en nuestro propio entorno (On-Premise), ya que dan acceso a los pesos del modelo. Eso sÃ­, para conseguirlo tendremos que contactar con ellos de forma directa. Una vez hemos presentado los tres modelos, vamos a evaluar las capacidades de los tres modelos. Prestaremos atenciÃ³n a tres parÃ¡metros clave en los LLM: Para ello los pondremos a prueba en tres escenarios diferentes (con sus respectivos prompts). Les preguntaremos por un tema general, por un tema de actualidad, y que haga las funciones de asistente de cÃ³digo. En esta primera prueba queremos principalmente evaluar que el modelo es capaz de adherirse a todas las instrucciones, ademÃ¡s de cumplir con los requisitos comunes de los otros dos casos de uso. Usaremos este prompt: A fin de visualizar los puntos fuertes de los modelos, hemos elaborado esta tabla comparativa: Como vemos en este primer escenario, Gemini y Mistral AI resultan ser la mejor opciÃ³n, pues ambas tienen en cuenta el nÃºmero de comensales y sus edades, mientras que GPT-4 obvia esa instrucciÃ³n a la hora de ofrecer la receta. En el caso de Mistral AI, a pesar de que el prompt estÃ¡ en espaÃ±ol, respondiÃ³ en inglÃ©s antes de que se le volviera a preguntar especificÃ¡ndolo. Los LLM se entrenan en una fecha especÃ­fica y desconocen hechos, noticias y cualquier otra cosa que ocurra tras esa fecha. Por defecto, es decir, sin que puedan acceder a travÃ©s de internet o mediante un sistema tipo RAG a informaciÃ³n personalizada, tendrÃ¡n un conocimiento limitado a su fecha de entrenamiento. Para comprobar un hecho reciente, usaremos el siguiente prompt: Buscamos comprobar que los modelos tengan informaciÃ³n actualizada sin usar tools para el acceso a internet, o que en el caso de no tenerla, que es lo mÃ¡s probable, admitan que no conocen la respuesta y no se la inventen (esto se conoce como hallucination o alucinaciÃ³n). Veamos las respuestas obtenidas desde los tres modelos. NÃ³tese que dentro del prompt hay informaciÃ³n que debe recabar despuÃ©s del fin de semana, pero otra, como el lugar donde se celebrÃ³ un gran premio en esas fechas, es pÃºblico desde meses antes, y si su fecha de entrenamiento (conocido como knowledge cutoff) es posterior a la publicaciÃ³n del calendario, deberÃ­a proporcionar la respuesta correcta (de no ser asÃ­ incurrirÃ­a en un knowledge error o refusal). A fin de visualizar los puntos fuertes de los modelos, hemos elaborado esta tabla comparativa: En este caso los tres modelos presentan una informaciÃ³n bastante pobre, aunque la gravedad de los errores no es la misma. Mistral AI reconoce que su fecha actual sigue siendo 2022, y aunque reconoce que es una informaciÃ³n a la que no puede acceder, determinamos que el modelo ni siquiera conoce la fecha actual. Caso distinto presenta GPT-4. GPT-4 sÃ­ que conoce la fecha actual, aunque no la haga pÃºblica. Al no tener acceso a informaciÃ³n actualizada a travÃ©s de internet, acierta en reconocer que carece de esa informaciÃ³n. Por otra parte, el caso de Gemini es mÃ¡s preocupante: no solo no reconoce que no tiene la informaciÃ³n, sino que se la inventa. La intuiciÃ³n podrÃ­a hacer pensar que se equivocÃ³ de aÃ±o y estÃ¡ mostrando informaciÃ³n del aÃ±o anterior, pero de ser asÃ­, tambiÃ©n serÃ­a errÃ³nea. Esto constituye un hallucination, uno de los errores mÃ¡s graves de un LLM. Por lo tanto, vemos como GPT-4 es ligeramente mejor que Mistral Large, y ambos superan con creces a Gemini en cuanto a informaciÃ³n de actualidad (sin acceder a otras tools) se refiere. Los grandes modelos de lenguaje son capaces de generar mÃ¡s que texto. Entre sus funcionalidades se encuentra la de generar cÃ³digo fuente en diversos lenguajes de programaciÃ³n, convirtiÃ©ndose asÃ­ en aceleradores a la hora de crear scripts o aplicaciones, o traducir de un lenguaje de programaciÃ³n a otro, como IBM estÃ¡ intentando con COBOL. Para evaluar quÃ© modelo genera mejor cÃ³digo, usaremos el siguiente prompt y luego ejecutaremos el resultado en un Jupyter Notebook para analizar el resultado. Tras evaluar los resultados obtenidos al ejecutar los cÃ³digos en Jupyter Notebook, presentamos lo siguiente: Todos los modelos se inventan el nombre de las columnas del archivo CSV a utilizar. En este caso, tanto Gemini como Mistral AI proporcionan un cÃ³digo que genera un archivo JSON vÃ¡lido, mientras que el JSON generado por GPT-4 contiene pequeÃ±os errores. GPT-4 ciertamente es el que mÃ¡s economiza en sus respuestas: es muy escueto y eso hace que tampoco "alucine" especialmente. La falta de una actualizaciÃ³n con datos mÃ¡s recientes le perjudica en un potencial uso como buscador o incluso al resolver cuestiones tÃ©cnicas, pero su comportamiento es menos errÃ¡tico que el de Gemini o Mistral AI. En general, los tres modelos tienen puntos fuertes y dÃ©biles similares: fallan a la hora de proporcionar informaciÃ³n actualizada. En cuanto a su uso para tareas cotidianas, como la preparaciÃ³n de una receta, una dieta, o un plan de viaje, los tres cumplen bastante bien con tantas instrucciones como se les den, aunque GPT-4 se quedÃ³ en nuestra prueba ligeramente atrÃ¡s. Para tareas de cÃ³digo, suelen funcionar a la par, y a pesar de que el cÃ³digo obtenido no fuera Ã³ptimo en ninguno de los casos, las modificaciones para hacerlo funcionar fueron mÃ­nimas. Aunque GPT-4 fue el que peor resultado dio, hemos de recordar que es el modelo detrÃ¡s de GitHub Copilot, donde con contexto resulta una herramienta extremadamente Ãºtil y fiable a la hora de construir cÃ³digo. En todo caso, estos modelos se actualizan constantemente y es posible que el despliegue masivo de Gemini Pro no estÃ© del todo completo en estos momentos. SerÃ¡ interesante ver la versiÃ³n 1.5 del modelo, ya anunciada pero aÃºn no disponible. Asimismo, podemos esperar nuevas actualizaciones de modelo por parte de Mistral AI, y por parte de OpenAI, ya han registrado la marca âGPT-5â. Una vez hemos analizado las bondades de cada uno de los modelos, hemos decidido terminar este artÃ­culo pidiÃ©ndole a cada uno de ellos que indiquen sus bondades y puntos dÃ©biles: TambiÃ©n Mistral Large parece desconocer alguna regla del espaÃ±ol con âo ofensivasâ. NÃ³tese la falta de ortografÃ­a âsobresaloâ, indicativo de que el modelo no conoce la conjugaciÃ³n de verbo âsobresalirâ. Y tÃº, Â¿quÃ© modelo crees que es mejor? DÃ©janos en un comentario diciÃ©ndonos cuÃ¡l prefieres ð. Jose MarÃ­a HernÃ¡ndez de la Cruz Formado como filÃ³logo y posteriormente como lingÃ¼ista computacional, emigrÃ© a Irlanda donde participÃ© en grandes proyectos de NLP en empresas Big Tech. AdemÃ¡s, colaborÃ© en el entrenamiento de algunos de los Large Language Models mÃ¡s reconocidos. Actualmente, mis esfuerzos se basan en estar al dÃ­a sobre las herramientas que rodean a la IA Generativa, evaluar su viabilidad y aplicarlas a casos de la vida real para generar valor en nuestros clientes. RaÃºl PÃ©rula Con varios aÃ±os de experiencia en posiciones tÃ©cnicas y de gestiÃ³n, soy Doctor en Inteligencia Artificial Aplicada, especializado en Reinforcement Learning, Computer Vision y NLP. Apasionado por la innovaciÃ³n, lidero como Arquitecto Principal en el equipo de Estrategia TecnolÃ³gica, la estrategia empresarial en IA con foco actualmente en IA Generativa. Siempre intento que mi curiosidad y perfeccionismo impulsen cada proyecto y mi objetivo es que cada dÃ­a podamos hacer realidad la ciencia ficciÃ³n. TomÃ¡s Calleja De pequeÃ±o me encantaba solucionar problemas de manera sencilla y cacharrear con la tecnologÃ­a. Han pasado los aÃ±os pero mis gustos no han cambiado: me paso el dÃ­a aprendiendo nuevas tecnologÃ­as para luego diseÃ±ar e implementar soluciones sencillas a problemas complejos, siempre desde un punto de vista LEAN. Durante los Ãºltimos aÃ±os me he centrado en Google Cloud Platform, soluciones Cloud Native y Serverless aunque me gusta saber un poco de todo.  Leer mÃ¡s. Los comentarios serÃ¡n moderados. SerÃ¡n visibles si aportan un argumento constructivo. Si no estÃ¡s de acuerdo con algÃºn punto, por favor, muestra tus opiniones de manera educada. 

                        ContÃ¡ctanos
                    
 
                    Newsletter.
