Título: ¿Qué son los grandes modelos de lenguaje (LLM)? | IBM 
URL: https://www.ibm.com/mx-es/topics/large-language-models
Número de palabras: 1971

Los modelos de lenguaje de gran tamaño (LLM) son una categoría de modelos fundacionales entrenados sobre enormes cantidades de datos que los hacen capaces de comprender y generar lenguaje natural, entre otros tipos de contenidos, para realizar una amplia gama de tareas. Los LLM se han convertido en un nombre familiar gracias al papel que han desempeñado para llevar la IA generativa a la vanguardia del interés público. Además, las organizaciones se están enfocando en adoptar la inteligencia artificial en numerosas funciones comerciales y casos de uso. Fuera del contexto empresarial, podría parecer que los LLM aparecieron de la nada junto con nuevos desarrollos en IA generativa. Sin embargo, muchas empresas, entre ellas IBM, han dedicado años a la implementación de estos modelos en diferentes niveles para mejorar sus capacidades de comprensión del lenguaje natural (NLU) y de procesamiento del lenguaje natural (NLP). Esto ha ocurrido junto con los avances en el aprendizaje automático, los modelos de aprendizaje automático, los algoritmos, las redes neuronales y los modelos de transformador que proporcionan la arquitectura para estos sistemas de IA. Los LLM son una clase de modelo fundacional, que se entrena con enormes cantidades de datos para proporcionar las capacidades fundamentales necesarias para impulsar múltiples casos de uso y aplicaciones, así como resolver una multitud de tareas. Esto crea un marcado contraste con la idea de construir y entrenar modelos específicos de dominio para cada uno de estos casos de uso individualmente, lo cual es prohibitivo en función de muchos criterios (los más importantes son el costo y la infraestructura), sofoca las sinergias e incluso puede conducir a un menor rendimiento. Los LLM representan un avance significativo en NLP e inteligencia artificial y son fácilmente accesibles para el público a través de interfaces como Chat GPT-3 y GPT-4 de OpenAI, que han obtenido el soporte de Microsoft. Otros ejemplos son los modelos Llama de Meta, las representaciones de codificadores bidireccionales de transformadores de Google (BERT/RoBERTa) y los modelos PaLM. Recientemente, IBM también lanzó su serie de modelos Granite en Watsonx.ai, que se ha convertido en la columna vertebral de la IA generativa para otros productos de IBM como watsonx Assistant y watsonx Orchestrate.  En pocas palabras, los LLM están diseñados para comprender y generar texto como un humano, además de otras formas de contenido, basándose en la enorme cantidad de datos utilizados para entrenarlos. Tienen la capacidad de inferir del contexto, generar respuestas coherentes y pertinentes para el contexto, traducir a idiomas distintos del inglés, resumir texto, responder preguntas (conversación general y preguntas frecuentes) e incluso ayudar en tareas de escritura creativa o de generación de código.  Pueden hacerlo gracias a miles de millones de parámetros que les permiten capturar patrones complejos en el lenguaje y realizar una amplia variedad de tareas relacionadas con el lenguaje. Los LLM están revolucionando las aplicaciones en varios campos, desde los chatbots y asistentes virtuales hasta la generación de contenido, asistencia para la investigación y traducción de idiomas. Mientras continúan evolucionando y mejorando, los LLM están preparados para remodelar la forma en que interactuamos con la tecnología y accedemos a la información, lo que los convierte en una parte fundamental del panorama digital moderno. Explore el libro electrónico sin costo de O'Reilly para aprender los primeros pasos con Presto, el motor SQL de código abierto para analytics de datos. Regístrese para obtener el libro electrónico sobre almacenes de datos de IA Para funcionar, los LLM aprovechan las técnicas de aprendizaje profundo y enormes cantidades de datos textuales. Estos modelos suelen basarse en una arquitectura de transformador, como el transformador generativo entrenado previamente, que se destaca en el manejo de datos secuenciales, por ejemplo, la entrada de texto. Los LLM constan de varias capas de redes neuronales, cada una con parámetros que pueden ajustarse durante el entrenamiento, y que se mejoran aún más mediante una multiplicidad de capas conocidas en su conjunto como mecanismo de atención, que se centra en partes específicas de los conjuntos de datos. Durante el proceso de entrenamiento, estos modelos aprenden a predecir la siguiente palabra en una oración en función del contexto proporcionado por las palabras anteriores. El modelo lo hace atribuyendo una puntuación de probabilidad a la recurrencia de palabras que se han convertido en tokens, desglosadas en secuencias de caracteres más pequeñas. Luego, estos tokens se transforman en incrustaciones, que son representaciones numéricas de este contexto. Para garantizar la precisión, el proceso implica entrenar el LLM en un corpus masivo de texto (en miles de millones de páginas), lo que le permite aprender gramática, semántica y relaciones conceptuales mediante un aprendizaje zero-shot y autosupervisado. Una vez entrenados en estos datos, los LLM pueden generar texto al predecir de forma autónoma la siguiente palabra en función de la información que reciben y dibujar sobre los patrones y conocimientos que adquirieron. El resultado es una generación de lenguaje coherente y pertinente para el contexto que se puede aprovechar para una amplia gama de tareas de NLU y generación de contenido. El rendimiento del modelo también se puede mejorar a través de la ingeniería rápida, el ajuste rápido, el ajuste de precisión y otras tácticas como el aprendizaje por refuerzo con retroalimentación humana (RLHF) para eliminar los sesgos, el discurso de odio y las respuestas objetivamente incorrectas conocidas como “alucinaciones” que a menudo son subproductos no deseados del entrenamiento con tantos datos no estructurados. Este es uno de los aspectos más importantes de garantizar que los LLM de nivel empresarial estén listos para su uso y no expongan a las organizaciones a responsabilidad no deseada, ni causen daños a su reputación.  Los LLM están redefiniendo un número cada vez mayor de procesos de negocios y han demostrado su versatilidad en una gran variedad de casos de uso y tareas en diversas industrias. Aumentan la IA conversacional en chatbots y asistentes virtuales (como IBM Watsonx Assistant y Google BARD) para mejorar las interacciones que sustentan la excelencia en la atención al cliente, proporcionando respuestas contextualizadas que imitan las interacciones con agentes humanos.  Los LLM también se destacan en la generación de contenidos, automatizando la creación de contenidos para artículos de blog, materiales de marketing o ventas y otras tareas de redacción. En la investigación y el mundo académico, ayudan a resumir y extraer información de grandes conjuntos de datos, acelerando el descubrimiento de conocimientos. Los LLM también desempeñan un papel fundamental en la traducción de idiomas, eliminando las barreras idiomáticas al proporcionar traducciones precisas y pertinentes para el contexto. Incluso pueden usarse para escribir código o "traducir" entre lenguajes de programación. Además, contribuyen a la accesibilidad ayudando a las personas con discapacidades, por ejemplo, con las aplicaciones Text to Speech y generando contenido en formatos accesibles. Desde la atención médica hasta las finanzas, los LLM están transformando las industrias optimizando los procesos, mejorando las experiencias del cliente y permitiendo la toma de decisiones más eficiente y basada en datos.  Lo más interesante es que todas estas capacidades son de fácil acceso; en algunos casos, literalmente, a una API de distancia.  En la siguiente lista se enumeran algunas de las áreas más importantes donde los LLM benefician a las organizaciones: Generación de texto: habilidades de generación de lenguaje, como escribir correos electrónicos, entradas de blog u otro contenido de formato medio o largo en respuesta a instrucciones que se pueden ajustar y pulir. Un excelente ejemplo es la generación aumentada por recuperación (RAG).  Resúmenes de contenido: resumir artículos largos, noticias, informes de investigación, documentación empresarial e incluso el historial de los clientes en textos completos, adaptados a la longitud del formato de salida. Asistentes de IA: chatbots que responden a las consultas de los clientes, realizan tareas de backend y proporcionan información detallada en lenguaje natural como parte de una solución de atención al cliente integrada y de autoservicio.  Generación de código: ayuda a los desarrolladores a crear aplicaciones, encontrar errores en el código y detectar problemas de seguridad en varios lenguajes de programación, incluso a generar "traducciones" entre ellos. Análisis de sentimientos: analiza el texto para determinar el tono del cliente con el objetivo de comprender los comentarios de los clientes a escala y ayudar a gestionar la reputación de la marca.  Traducción de idiomas: proporciona a las organizaciones una cobertura más amplia en todos los idiomas y zonas geográficas con traducciones fluidas y capacidades multilingües.  Los LLM van a afectar a todos los sectores, desde las finanzas a los seguros, pasando por los recursos humanos o la atención sanitaria, automatizando el autoservicio del cliente, acelerando los tiempos de respuesta en un número cada vez mayor de tareas y proporcionando mayor precisión, mejorando el enrutamiento y recopilando contextos de forma inteligente. Las organizaciones necesitan una base sólida en las prácticas de gobernanza para aprovechar el potencial de los modelos de IA para revolucionar la forma en que hacen negocios. Esto significa proporcionar acceso a herramientas y tecnologías de IA que sean confiables, transparentes, responsables y seguras. La gobernanza y trazabilidad de la IA también son aspectos fundamentales de las soluciones que IBM ofrece a sus clientes, de modo que las actividades que involucran la IA se gestionan y monitorean para permitir el seguimiento de orígenes, datos y modelos, de manera que siempre se puedan auditar y permitan determinar responsabilidades.  Entrenados con conjuntos de datos centrados en la empresa, seleccionados directamente por IBM para ayudar a mitigar los riesgos que conlleva la IA generativa, de modo que los modelos se implementen de forma responsable y requieran una entrada mínima para garantizar que estén preparados para el cliente. Watsonx.ai proporciona acceso a modelos de código abierto de Hugging Face, modelos de terceros, así como a la familia de modelos entrenados previamente de IBM. Por ejemplo, la serie de modelos Granite utiliza una arquitectura de decodificador para admitir una variedad de tareas de IA generativa dirigidas a casos de uso empresarial.  Ofrezca experiencias excepcionales a los clientes en cada interacción, a los agentes de centros de atención telefónica que necesitan asistencia e incluso a los empleados que necesitan información. Escale las respuestas en lenguaje natural con base en el contenido empresarial para impulsar interacciones orientadas a los resultados y respuestas rápidas y precisas. Automatice las tareas y simplifique procesos complejos para que los empleados puedan centrarse en un trabajo estratégico de mayor valor, todo desde una interfaz conversacional que aumenta los niveles de productividad de los empleados con un conjunto de automatizaciones y herramientas de IA. A veces, el problema de la IA y la automatización es que requieren demasiada mano de obra. Pero todo eso está cambiando gracias a los modelos fundacionales de código abierto y previamente entrenados. Desarrollados por IBM Research, los modelos Granite utilizan una arquitectura de &quot;decodificador&quot;, lo que respalda la capacidad de los modelos de lenguaje de gran tamaño actuales para predecir la siguiente palabra en una secuencia.

 Nuestra investigación basada en datos identifica cómo las empresas pueden localizar y aprovechar las oportunidades en el campo de la IA generativa, en constante evolución y expansión. Con la tecnología de nuestro modelo de lenguaje de gran tamaño, IBM Granite, y nuestro motor de búsqueda empresarial, Watson Discovery, Conversational Search está diseñado para escalar las respuestas conversacionales tomando como base contenidos empresariales. Si bien la adopción de la IA generativa en toda la empresa sigue siendo un desafío, las organizaciones que implementan con éxito estas tecnologías pueden obtener una ventaja competitiva significativa.  ¿Y si la gran renuncia fuera en realidad la gran actualización, es decir, una oportunidad para atraer y mantener a los empleados haciendo un mejor uso de sus habilidades? La mano de obra digital lo hace posible al asumir el trabajo pesado de sus empleados. Entrene, valide, ajuste y despliegue IA generativa, modelos fundacionales y capacidades de aprendizaje automático con IBM® watsonx.ai, un estudio empresarial de próxima generación para creadores de IA. Diseñe aplicaciones de IA en menos tiempo y con menos datos.