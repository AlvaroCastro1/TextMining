Título: Cinco tendencias vanguardistas de la IA generativa que darán que hablar en 2024 - Forbes España
URL: https://forbes.es/tecnologia/391129/cinco-tendencias-vanguardistas-de-la-ia-generativa-que-daran-que-hablar-en-2024/
Número de palabras: 987





 Último número El año 2023 marcó un momento decisivo en la evolución de la tecnología, con la generalización de la Inteligencia Artificial (IA) generativa. A medida que avanzamos en este 2024, se espera que el panorama de la IA generativa evolucione rápidamente, introduciendo una serie de tendencias que prometen transformar la tecnología y sus aplicaciones. Estas tendencias, que van desde los avances en los modelos de IA multimodal hasta el auge de los pequeños modelos lingüísticos, no sólo configurarán el panorama tecnológico, sino que también redefinirán las interacciones, la creatividad y la comprensión del potencial de la IA. De cara a 2024, exploremos las principales tendencias de la IA generativa: GPT4 de OpenAI, LLama 2 de Meta y Mistral son ejemplos de los avances en los grandes modelos lingüísticos. La tecnología va más allá del texto con los modelos de IA multimodal, que permiten a los usuarios mezclar y combinar contenidos basados en texto, audio, imagen y vídeo para provocar y generar nuevos contenidos. Este enfoque implica combinar datos, como imágenes, texto y voz, con algoritmos avanzados para hacer predicciones y generar resultados. En 2024, se espera que la IA multimodal evolucione significativamente, dando paso a un cambio en las capacidades de la IA generativa. Estos modelos están progresando más allá de las funciones monomodales tradicionales, incorporando diversos tipos de datos como imágenes, lenguaje y audio. Como resultado de esta transición a los modelos multimodales, la IA será más intuitiva y dinámica. El GPT4-V ya es popular entre los suscriptores de ChatGPT Plus por sus capacidades multimodales. En 2024, podemos esperar el auge de modelos abiertos como el Gran Asistente de Lenguaje y Visión o LLava. Si 2023 fue el año de los modelos lingüísticos grandes, 2024 será testigo del poder de los modelos lingüísticos pequeños. Los LLM (modelo grande de lenguaje) se entrenan en conjuntos de datos masivos como Common Crawl y The Pile. Los terabytes de datos que componen estos conjuntos de datos se extrajeron de miles de millones de sitios web de acceso público. Aunque los datos son realmente beneficiosos para enseñar a los LLM a generar contenidos significativos y predecir la siguiente palabra, su naturaleza ruidosa se debe a que se basan en contenidos generales de Internet. Los modelos lingüísticos pequeños (SLM), por otro lado, se entrenan en conjuntos de datos más limitados que, sin embargo, están compuestos por fuentes de alta calidad como libros de texto, revistas y contenidos autorizados. Estos modelos son más pequeños en términos de recuento de parámetros, así como de requisitos de almacenamiento y memoria, lo que les permite funcionar en hardware menos potente y menos costoso. Los SLM producen contenidos de calidad comparable a la de algunos de sus homólogos más grandes a pesar de ser una fracción del tamaño de los LLM. El PHI-2 y el Mistral 7B de Microsoft son dos SLM prometedores que impulsarán la próxima generación de aplicaciones de IA generativa. Los agentes autónomos representan una estrategia innovadora para construir modelos de IA generativa. Estos agentes son programas de software autónomos diseñados para lograr un objetivo específico. Al considerar la IA generativa, la capacidad de los agentes autónomos para producir contenidos sin intervención humana supera las limitaciones asociadas a la ingeniería rápida convencional. En el desarrollo de agentes autónomos se utilizan algoritmos avanzados y técnicas de aprendizaje automático. Estos agentes utilizan los datos para aprender, adaptarse a nuevas situaciones y tomar decisiones sin apenas intervención humana. Por ejemplo, OpenAI ha creado herramientas que hacen un uso eficaz de los agentes autónomos, lo que indica un avance significativo en el campo de la inteligencia artificial. La IA multimodal, que combina varias técnicas de IA como el procesamiento del lenguaje natural, la visión por ordenador y el aprendizaje automático, es fundamental en el desarrollo de agentes autónomos. Puede hacer predicciones, emprender acciones e interactuar de forma más adecuada analizando diferentes tipos de datos al mismo tiempo y aplicando el contexto actual. Frameworks como LangChain y LlamaIndex son algunas de las herramientas populares utilizadas para construir agentes basados en los LLM. En 2024, veremos nuevos marcos que aprovecharán la IA multimodal. En 2024, se espera que los modelos abiertos y generativos de IA evolucionen significativamente, y algunas predicciones sugieren que serán comparables a los modelos propietarios. La comparación entre los modelos abiertos y los propietarios, por otra parte, es compleja y depende de diversos factores, como los casos de uso específicos, los recursos de desarrollo y los datos utilizados para entrenar los modelos. Llama 2 70B de Meta, Halcón 180B y Mixtral-8x7B de Mistral AI se hicieron extremadamente populares en 2023, con un rendimiento comparable al de modelos propietarios como GPT 3.5, Claude 2 y Jurrasic. En el futuro, la brecha entre los modelos abiertos y los propietarios se estrechará, proporcionando a las empresas una gran opción para alojar modelos generativos de IA en entornos híbridos o locales. En 2024, la próxima iteración de modelos de Meta, Mistral y posiblemente nuevos participantes se lanzarán como alternativas viables a los modelos propietarios disponibles como API. Kubernetes es ya el entorno preferido para alojar modelos de IA generativa. Se espera que actores clave como Hugging Face, OpenAI y Google aprovechen la infraestructura nativa de la nube impulsada por Kubernetes para ofrecer plataformas de IA generativa. Herramientas como Text Generation Inference de Hugging Face, Ray Serve de AnyScale y vLLM ya admiten la ejecución de inferencia de modelos en contenedores. En 2024, veremos la madurez de las herramientas y las plataformas que se ejecutan en Kubernetes para gestionar todo el ciclo de vida de los modelos fundacionales. Los usuarios podrán preentrenar, afinar, desplegar y escalar modelos generativos de forma eficiente. Los principales actores del ecosistema nativo de la nube proporcionarán arquitecturas de referencia, mejores prácticas y optimizaciones para ejecutar IA generativa en infraestructuras nativas de la nube. LLMOps se ampliará para soportar flujos de trabajo integrados nativos de la nube. © 2024 Forbes España. Todos los derechos reservados. - 