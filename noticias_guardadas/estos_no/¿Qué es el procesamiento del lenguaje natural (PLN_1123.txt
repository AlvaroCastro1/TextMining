Título: ¿Qué es el procesamiento del lenguaje natural (PLN)? | IBM
URL: https://www.ibm.com/mx-es/topics/natural-language-processing
Número de palabras: 3324

Conferencia IBM TechXchange 2024 | Del 21 al 24 de octubre en Las Vegas Únase al evento imprescindible para los tecnólogos que emplean productos y soluciones de IBM. Explore el creciente catálogo de sesiones de más de 1200 sesiones y laboratorios. Fecha de actualización: 11 de agosto de 2024
Colaboradores: Cole Stryker, Jim Holdsworth
 El procesamiento de lenguaje natural (PLN) es un subcampo de la informática y la inteligencia artificial (IA) que emplea el aprendizaje automático para permitir que las computadoras comprendan y se comuniquen con el lenguaje humano.  El PLN permite que las computadoras y los dispositivos digitales reconozcan, comprendan y generen texto y voz mediante la combinación de la lingüística computacional (el modelado basado en reglas del lenguaje humano) y el modelado estadístico, el aprendizaje automático y el aprendizaje profundo.  La investigación de PLN ha ayudado a habilitar la era de la IA generativa, desde las habilidades de comunicación de los modelos de lenguaje de gran tamaño (LLM) hasta la capacidad de los modelos de generación de imágenes para comprender las solicitudes. El PLN ya forma parte de la vida cotidiana de muchos, accionando los motores de búsqueda, impulsando los chatbots de atención al cliente con instrucciones habladas, los sistemas GPS operados por voz y los asistentes digitales de preguntas frecuentes en teléfonos inteligentes como Alexa de Amazon, Siri de Apple y Cortana de Microsoft.  El PLN también desempeña un papel cada vez más importante en las soluciones empresariales que ayudan a optimizar y automatizar las operaciones comerciales, aumentar la productividad de los empleados y simplificar los procesos comerciales. Utilice este marco de selección de modelos para elegir el modelo más apropiado mientras equilibra sus requisitos de rendimiento con los costos, los riesgos y las necesidades de despliegue. Regístrese para obtener el informe técnico sobre la gobernanza de la IA El PLN facilita que los humanos se comuniquen y colaboren con las máquinas, al permitirles hacerlo en el lenguaje humano natural que usan todos los días. Esto ofrece beneficios en muchas industrias y aplicaciones. 
El PLN es especialmente útil para automatizar tareas, total o parcialmente, como la atención al cliente, la entrada de datos y la gestión de documentos. Por ejemplo, los chatbots impulsados por PLN pueden gestionar consultas rutinarias de los clientes, liberando a los agentes humanos para problemas más complejos. En el procesamiento de documentos, las herramientas de PLN pueden clasificar, extraer información clave y resumir el contenido de manera automática, lo que reduce el tiempo y los errores asociados con la gestión manual de datos. El PLN facilita la traducción de idiomas, convirtiendo texto de un idioma a otro mientras se conserva el significado, el contexto y los matices.
 
El PLN mejora el análisis de datos al permitir la extracción de insights de datos de texto no estructurados, como opiniones de clientes, publicaciones en redes sociales y artículos de noticias. Mediante el uso de técnicas de minería de texto, el PLN puede identificar patrones, tendencias y sentimientos que no son inmediatamente obvios en grandes conjuntos de datos. El análisis de sentimientos permite extraer cualidades subjetivas (actitudes, emociones, sarcasmo, confusión o sospecha) del texto. Esto se usa a menudo para enrutar las comunicaciones al sistema o a la persona con mayor probabilidad de dar la siguiente respuesta.  Esto permite a las empresas comprender mejor las preferencias de los clientes, las condiciones del mercado y la opinión pública. Las herramientas de PLN también pueden categorizar y resumir grandes cantidades de texto, lo que facilita a los analistas identificar información clave y tomar decisiones basadas en datos de manera más eficiente. 
El PLN beneficia la búsqueda al permitir que los sistemas comprendan la intención detrás de las consultas de los usuarios, proporcionando resultados más precisos y contextualmente relevantes. En lugar de depender únicamente de la coincidencia de palabras clave, los motores de búsqueda impulsados por PLN analizan el significado de palabras y frases, lo que facilita la búsqueda de información incluso cuando las consultas son vagas o complejas. Esto mejora la experiencia del usuario, ya sea en búsquedas de sitio web, recuperación de documentos o sistemas de datos empresariales. 
El PLN potencia modelos de lenguaje avanzados para crear textos similares a los humanos para diversos propósitos. Los modelos previamente entrenados, como GPT-4, pueden generar artículos, informes, textos de marketing, descripciones de productos e incluso textos creativos basados en indicaciones proporcionadas por los usuarios. Las herramientas impulsadas por PLN también pueden ayudar a automatizar tareas como redactar correos electrónicos, escribir publicaciones en redes sociales o documentación legal. Al comprender el contexto, el tono y el estilo, el PLN se cerciora de que el contenido generado sea coherente, relevante y esté alineado con el mensaje deseado, lo que ahorra tiempo y esfuerzo en la creación de contenido y mantiene la calidad. El PLN combina el poder de la lingüística computacional con algoritmos de aprendizaje automático y aprendizaje profundo. La lingüística computacional emplea la ciencia de datos para analizar el lenguaje y el habla. Incluye dos tipos principales de análisis: análisis sintáctico y análisis semántico. El análisis sintáctico determina el significado de una palabra, frase u oración al analizar la sintaxis de las palabras y aplicar reglas gramaticales preprogramadas. El análisis semántico emplea la salida sintáctica para extraer significado de las palabras e interpretar su significado dentro de la estructura de la oración.   El análisis de palabras puede tomar una de dos formas. El análisis de dependencias analiza las relaciones entre palabras, como la identificación de sustantivos y verbos, mientras que el análisis de constituyentes construye un árbol de análisis (o árbol de sintaxis): una representación enraizada y ordenada de la estructura sintáctica de la oración o cadena de palabras. Los árboles de análisis resultantes subyacen a las funciones de los language translators y el reconocimiento de voz. Idealmente, este análisis hace que el resultado, ya sea texto o voz, sea comprensible tanto para los modelos de PLN como para las personas. El aprendizaje autosupervisado (SSL) es particularmente útil para respaldar el PLN porque este requiere grandes cantidades de datos etiquetados para entrenar modelos de IA. Dado que estos conjuntos de datos etiquetados requieren mucho tiempo de anotación (un proceso que implica el etiquetado manual por parte de humanos), la recopilación de datos suficientes puede resultar prohibitivamente difícil. Los enfoques autosupervisados pueden ser más eficaces y rentables, ya que sustituyen algunos o todos los datos de entrenamiento etiquetados manualmente. 
 
Tres enfoques diferentes para el PLN incluyen: 
Las primeras aplicaciones del PLN eran simples decision trees, que requerían reglas preprogramadas. Solo pueden proporcionar respuestas a instrucciones específicas, como la versión original de Moviefone, que contaba con capacidades básicas de generación de lenguaje natural. Debido a que no hay capacidad de aprendizaje automático o IA en el PLN basado en reglas, esta función es muy limitada y no es escalable. 
Posteriormente, se desarrolló el PLN estadístico, el cual extrae, clasifica y etiqueta automáticamente elementos de datos de texto y de voz y asigna una probabilidad estadística a cada significado posible de esos elementos. 
 Esto se basa en el aprendizaje automático, lo que permite un desglose sofisticado de la lingüística, como el etiquetado de partes del discurso. 
 
El PLN estadístico introdujo la técnica esencial de mapear elementos del lenguaje (como palabras y reglas gramaticales) a una representación vectorial para que el lenguaje se pueda modelar mediante métodos matemáticos (estadísticos), incluidos los modelos de regresión o de Markov. Esto fundamentó los primeros desarrollos de PLN, como los correctores ortográficos y los mensajes de texto T9 (Texto en 9 teclas, para usar en teléfonos de marcación por tonos).
 
Recientemente, los modelos de aprendizaje profundo se han convertido en el modo dominante de PLN, mediante el uso de enormes volúmenes de datos sin procesar y no estructurados, tanto de texto como de voz, para ser cada vez más precisos. El aprendizaje profundo puede considerarse una evolución del PLN estadístico, con la diferencia de que emplea modelos de redes neuronales. Existen varias subcategorías de modelos: Modelos de secuencia a secuencia (seq2seq): basados en redes neuronales recurrentes (RNN), se han empleado principalmente para la traducción automática al convertir una frase de un dominio (como el alemán) en la frase de otro dominio (como el inglés). Modelos transformadores: Utilizan la tokenización del lenguaje (la posición de cada token, palabras o subpalabras) y la autoatención (captura de dependencias y relaciones) para calcular la relación de diferentes partes del lenguaje entre sí. Los modelos transformadores se pueden entrenar de manera eficiente mediante el uso del aprendizaje autosupervisado con bases de datos de texto masivas. Un hito en los modelos transformadores fueron las representaciones de codificadores bidireccionales de transformadores (BERT) de Google, que se convirtieron y siguen siendo la base de cómo funciona el motor de búsqueda de Google. Modelos autorregresivos: Este tipo de modelo transformador está entrenado específicamente para predecir la siguiente palabra de una secuencia, lo que representa un enorme salto en la capacidad de generar texto. Algunos ejemplos de LLM autorregresivos son GPT, Llama, Claude y el código abierto Mistral. Modelos fundacionales: Los modelos fundacionales prediseñados y curados pueden acelerar el lanzamiento de una iniciativa de PLN y aumentar la confianza en su funcionamiento. Por ejemplo, los modelos fundacionales de IBM® Granite son ampliamente aplicables en todas las industrias. Admiten tareas de PLN, incluida la generación de contenido y la extracción de insights. Además, facilitan la generación aumentada por recuperación, un marco para mejorar la calidad de la respuesta al vincular el modelo a fuentes externas de conocimiento. Los modelos también realizan reconocimiento de entidades nombradas, lo que implica identificar y extraer información clave en un texto. 
 Varias tareas de PLN suelen ayudar a procesar datos de texto y voz humanos de maneras que ayudan a la computadora a comprender lo que está ingiriendo. Algunas de estas tareas incluyen: Resolución de correferencias Reconocimiento de entidades nombradas Etiquetado de partes de la oración Desambiguación del sentido de las palabras 
Esta es la tarea de identificar si dos palabras se refieren a la misma entidad. El ejemplo más común es determinar la persona u objeto al que se refiere un determinado pronombre (como “ella” = “María”). Pero también puede identificar una metáfora o una expresión idiomática en el texto (como una instancia en la que “oso” no es un animal, sino una persona grande y peluda).  
El NER identifica palabras o frases como entidades útiles. El NER identifica “Londres” como una ubicación o “María” como el nombre de una persona. 
 
También llamado etiquetado gramatical, este es el proceso de determinar qué parte del discurso es una palabra o fragmento de texto, en función de su uso y contexto. Por ejemplo, la parte del discurso identifica “hacer” como un verbo en “Puedo hacer un avión de papel” y como un sustantivo en “¿Qué marca de auto tienes?”. 
 
Se trata de la selección de un significado para una palabra con múltiples significados posibles. Esto emplea un proceso de análisis semántico para examinar la palabra en contexto. Por ejemplo, la desambiguación del sentido de las palabras ayuda a distinguir el significado del verbo “make” en “make the grade” (alcanzar) frente a “make a bet” (hacer una apuesta). Clasificar “I will be merry when I marryMary” (Seré feliz cuando me case con María) requiere un sofisticado sistema de PLN. El PLN funciona combinando varias técnicas computacionales para analizar, comprender y generar lenguaje humano de una manera que las máquinas puedan procesarlo. Aquí hay una descripción general de un pipeline típico de PLN y sus pasos: 
El preprocesamiento de texto del PLN prepara el texto sin procesar para su análisis transformándolo en un formato que las máquinas puedan entender más fácilmente. Comienza con la tokenización, que implica dividir el texto en unidades más pequeñas, como palabras, oraciones o frases. Esto ayuda a desglosar el texto complejo en partes manejables. A continuación, se estandariza el texto al convertir todos los caracteres a minúsculas, lo que garantiza que palabras como “Apple” y “apple” se traten de la misma manera. La eliminación de palabras de detención es otro paso común, en el cual las palabras de uso frecuente como “es” o “el” se filtran porque no agregan un significado importante al texto. La derivación o lematización reduce las palabras a su forma raíz (por ejemplo, “corriendo” se convierte en “correr”), lo que facilita el análisis del lenguaje agrupando diferentes formas de la misma palabra. Además, la limpieza de texto elimina elementos no deseados, como puntuación, caracteres especiales y números que pueden saturar el análisis.  Luego del preprocesamiento, el texto está limpio, estandarizado y listo para que los modelos de aprendizaje automático lo interpreten de manera efectiva. 
La extracción de características es el proceso de convertir texto sin procesar en representaciones numéricas que las máquinas pueden analizar e interpretar. Esto implica transformar texto en datos estructurados mediante el uso de técnicas de PLN como Bag of Words y TF-IDF, que cuantifican la presencia e importancia de las palabras en un documento. Los métodos más avanzados incluyen las incrustaciones de palabras como Word2Vec o GLOve, que representan palabras como vectores densos en un espacio continuo, capturando las relaciones semánticas entre palabras. Las incrustaciones contextuales mejoran aún más esto al considerar el contexto en el que aparecen las palabras, lo que permite tener mejores representaciones y más matizadas.  
El análisis de textos consiste en interpretar y extraer información significativa de los datos textuales mediante diversas técnicas computacionales. Este proceso incluye tareas como el etiquetado de partes del discurso (POS), que identifica las funciones gramaticales de las palabras, y el reconocimiento de entidades nombradas (NER), que detecta entidades específicas como nombres, lugares y fechas. El análisis sintáctico de dependencias analiza las relaciones gramaticales entre las palabras para comprender la estructura de las frases, mientras que el análisis de sentimientos determina el tono emocional del texto, evaluando si es positivo, negativo o neutro. El modelado de temas identifica los temas subyacentes en un texto o en un corpus de documentos. La comprensión del lenguaje natural (NLU) es un subconjunto de NLP que se centra en analizar el significado detrás de las oraciones. La NLU permite al software encontrar significados similares en distintas frases o procesar palabras que tienen significados diferentes. Mediante estas técnicas, el análisis de textos de PLN transforma el texto no estructurado en insights.    
A continuación, los datos procesados se emplean para entrenar modelos de aprendizaje automático, que aprenden patrones y relaciones dentro de los datos. Durante el entrenamiento, el modelo ajusta sus parámetros para reducir los errores y mejorar su rendimiento. Una vez entrenado, el modelo puede emplearse para hacer predicciones o generar resultados con datos nuevos y desconocidos. La eficacia de los modelos de PLN se perfecciona continuamente mediante la evaluación, la validación y el ajuste para mejorar la precisión y la pertinencia en las aplicaciones del mundo real. Diferentes entornos de software son útiles a lo largo de dichos procesos. Por ejemplo, Natural Language Toolkit (NLTK) es un conjunto de bibliotecas y programas para inglés escrito en el lenguaje de programación Python. Admite funciones de clasificación de texto, tokenización, derivación, etiquetado, análisis y razonamiento semántico. TensorFlow es una biblioteca de software gratuita y de código abierto para aprendizaje automático e IA que se puede emplear para entrenar modelos para aplicaciones de PLN. Existen numerosos tutoriales y certificaciones para aquellos interesados en familiarizarse con dichas herramientas. 
 Incluso los modelos de PLN de última generación no son perfectos, de la misma forma que el habla humana es propensa a errores. Al igual que con cualquier tecnología de IA, el PLN conlleva posibles dificultades. El lenguaje humano está lleno de ambigüedades que dificultan que los programadores escriban software que determine con precisión el significado previsto del texto o los datos de voz. Los humanos tardan años en aprender el lenguaje humano, y muchos nunca dejan de aprender. Pero luego los programadores deben enseñar a las aplicaciones impulsadas por lenguaje natural a reconocer y comprender las irregularidades para que sus aplicaciones puedan ser precisas y útiles. Los riesgos asociados pueden incluir: 
Al igual que con cualquier función de IA, los datos sesgados empleados en el entrenamiento sesgarán las respuestas. Cuanto más diversos sean los usuarios de una función de PLN, más significativo se vuelve este riesgo, como en los servicios gubernamentales, la atención médica y las interacciones de Recursos Humanos. Los conjuntos de datos de entrenamiento extraídos de la web, por ejemplo, son propensos a sesgos. 
Al igual que en la programación, existe el riesgo de que entre basura y salga basura (GIGO). Reconocimiento de voz, también conocido como conversión de voz a texto, es la tarea de convertir de forma confiable datos de voz en datos de texto. Pero las soluciones de PLN pueden confundirse si la entrada hablada está en un dialecto extraño, en murmuros, con demasiada jerga, homónimos, gramática incorrecta, modismos, fragmentos, malas pronunciaciones, contracciones o se graba con demasiado ruido de fondo.
 
Continuamente se inventan o importan nuevas palabras. Las convenciones gramaticales pueden evolucionar o romperse intencionadamente. En estos casos, el PLN puede hacer una suposición o admitir que no está segura, lo que crea una complicación. 
Cuando las personas hablan, su expresión verbal o incluso su lenguaje corporal pueden dar un significado completamente diferente al de las palabras por sí solas. La exageración por efecto, el énfasis en las palabras por su importancia o el sarcasmo pueden confundir al PLN, lo que hace que el análisis semántico sea más difícil y menos confiable. Las aplicaciones de PLN ahora se pueden encontrar en prácticamente todas las industrias.  
En las transacciones financieras, los nanosegundos pueden hacer la diferencia entre el éxito y el fracaso a la hora de acceder a los datos o realizar operaciones o tratos. El PLN puede acelerar la extracción de información de estados financieros, reportes anuales y regulatorios, comunicados de prensa o incluso redes sociales.
 
Los nuevos conocimientos y avances médicos pueden llegar más rápido de lo que muchos profesionales de la salud pueden seguir. Las herramientas basadas en PLN e IA pueden ayudar a acelerar el análisis de historiales médicos y documentos de investigación médica, lo que hace posible la toma de decisiones médicas más informadas o ayuda a detectar o incluso prevenir afecciones médicas. 
El PLN puede analizar las reclamaciones para buscar patrones que puedan identificar áreas de preocupación y encontrar ineficiencias en el procesamiento de reclamaciones, lo que lleva a una mayor optimización del procesamiento y los esfuerzos de los empleados.
 
Casi cualquier caso legal puede requerir la revisión de montones de documentos, información de antecedentes y precedentes legales. El PLN puede ayudar a automatizar el descubrimiento legal, lo cual ayuda en la organización de la información, acelera la revisión y garantiza que todos los detalles relevantes se capturen para su consideración. Acelere el valor de negocio de la inteligencia artificial con una cartera potente y flexible de bibliotecas, servicios y aplicaciones. Incorpore una poderosa IA de lenguaje natural a las aplicaciones comerciales con una biblioteca en contenedores diseñada para dotar a los asociados de IBM de una mayor flexibilidad. Granite es la serie insignia de modelos fundacionales LLM de IBM basada en arquitectura transformadora de solo decodificador. Los modelos de lenguaje Granite se entrenan con datos empresariales confiables que abarcan áreas de Internet, académicas, de código, legales y financieras. Aprenda los conceptos fundamentales de la IA y la IA generativa, incluida la ingeniería rápida, los modelos de lenguaje de gran tamaño y los mejores proyectos de código abierto. Descubra cómo el procesamiento de lenguaje natural puede ayudarle a conversar de forma más natural con las computadoras. Conozca Scout Advisor, una innovadora herramienta de PLN creada en la plataforma IBM® watsonx™ especialmente para el Club de Futbol Sevilla de España.  Este artículo explica cómo IBM watson puede ayudarle a emplear los servicios de PLN para desarrollar aplicaciones cada vez más inteligentes, con un enfoque en la comprensión del lenguaje natural. Entrene, valide, ajuste y despliegue IA generativa, modelos fundacionales y capacidades de aprendizaje automático con IBM® watsonx.ai, un estudio empresarial de próxima generación para creadores de IA. Diseñe aplicaciones de IA en menos tiempo y con menos datos.