Título: La Inteligencia Artificial Generativa, a debate - KPMG Tendencias
URL: https://www.tendencias.kpmg.es/2024/01/inteligencia-artificial-generativa-apocalipticos-vs-integrados/
Número de palabras: 3707

Hablar directamente con una máquina parecía algo reservado a las películas de ciencia ficción y más aún mantener una conversación fluida con una herramienta que maneja millones de datos más que un ser humano y los procesa en cuestión de segundos. Esta idea dejó de pertenecer al mundo de la ficción en el momento en el que se ha democratizado el uso de la Inteligencia Artificial Generativa, sin previo aviso aparente, abriendo una infinidad de posibilidades para los usuarios y también para las compañías. Ambas acompañadas de no menos riesgos y dudas, pues, aunque ya existe un acuerdo provisional sobre la propuesta relativa a normas armonizadas en materia de inteligencia artificial (IA), el conocido ‘Reglamento de Inteligencia Artificial’, aún se siguen perfilando los parámetros de uso de esta tecnología, así como en qué ámbitos podrá ser o no aplicable, su impacto legal y ético, cuáles serán sus consecuencias a nivel social y en la configuración del trabajo, o si es posible blindarse en materia de ciberseguridad ante ella. Se trata de un camino que tanto compañías como usuarios están empezando a explorar. Sin embargo, lo cierto es que esta nueva arquitectura se basa en enfoques que llevan décadas evolucionando hasta llegar a lo que hoy se conoce como inteligencia artificial generativa: una Inteligencia Artificial que utiliza modelos de aprendizaje automático para crear resultados completamente nuevos basados ​​en un conjunto de entrenamiento. Y cuya novedad, “a diferencia de la naturaleza analítica estándar del resto de los sistemas de Inteligencia Artificial, reside en que permite que un algoritmo cree cosas nuevas desde el entrenamiento de los documentos que ha procesado”, tal y como señala Eva García San Luis, socia responsable de KPMG Lighthouse de KPMG en España. Además, su llegada ha sido posible gracias al desarrollo a lo largo de los últimos años de otras tecnologías ‘facilitadoras’ como el Deep learning, el aprendizaje por transferencia o las incrustaciones de palabras (especialmente relevantes ya que son las que permiten representar los datos como vectores numéricos) en la década de los años 2000, o los transformadores de redes neuronales, surgidas en 2017. Con todo ello, el resultado es que la Inteligencia Artificial Generativa ya está a disposición del usuario y el debate se divide entre abrazarla y aprovechar las oportunidades que ofrece, de manera controlada atendiendo a criterios legales y éticos y en base a unos parámetros compartidos, o ponerles freno al desarrollo tecnológico y a la innovación. Sobre su uso corporativo, la socia responsable de Lighthouse tiene claro cómo están posicionándose ya algunas compañías: utilizarán estos modelos para reinventar la forma en que se realiza el trabajo. “Imaginemos que cada empleado de una empresa tuviera un ayudante que tuviera información sobre la empresa: toda la historia, el contexto, los matices y la intención del negocio y sus operaciones, y pudiera procesar, analizar y usar esa información en cuestión de segundos”, vaticina. Para que esto suceda y para aumentar el valor de la Inteligencia Artificial Generativa y los modelos básicos en casos de uso empresariales específicos, “las empresas personalizarán cada vez más los modelos previamente entrenados ajustándolos con sus propios datos”, señala Eva García San Luis. Aquí, además, es importante que las compañías tengan en cuenta la importancia de aliarse con organizaciones tecnológicas para extraer el máximo potencial de las últimas herramientas. Aunque, cada vez más, se impone la segunda de estas alternativas. En paralelo, que las compañías cuenten con estrategias de tecnología responsable y confiable ayudará a mitigar riesgos, ayudando a la par a cumplir con criterios ESG por relación a la ética digital. Y es que, aunque hace un año escaso que los modelos de inteligencia artificial generativa han aterrizado en el panorama corporativo, muchas organizaciones, especialmente las tecnológicas, no han querido quedarse atrás en lo que a su adopción se refiere. “Vemos que la Inteligencia Artificial Generativa tiene el potencial de transformar significativamente el mundo empresarial, mejorando la eficiencia y la productividad de los empleados, el desarrollo de software, la personalización de la experiencia del cliente y la seguridad”, asegura Alberto Pinedo, National Technology Officer de Microsoft en España. Y ya se están emprendiendo proyectos y viendo casos de uso específicos para determinadas organizaciones: Sin embargo, a la misma velocidad a la que se suceden los titulares sobre el alcance de esta inteligencia artificial generativa, se abren debates sobre cómo controlar y regular la adopción de esta tecnología desde el punto de vista legal. Como suele ocurrir con los desarrollos tecnológicos, la regulación no avanza al mismo ritmo y han surgido preguntas en torno a la normativa que sustenta el uso de la inteligencia artificial generativa. Sin embargo, “Europa está siendo pionera en revertir esta situación: “el pasado 8 de diciembre la Presidencia del Consejo de la Unión Europea y los negociadores del Parlamento Europeo alcanzaron un acuerdo provisional sobre la propuesta relativa a normas armonizadas en materia de inteligencia artificial (IA), el conocido “Reglamento de Inteligencia Artificial, que supone la primera propuesta legislativa de tipo transversal en el mundo, y que sirve de referente mundial para regular la IA en otras jurisdicciones, igual que lo hizo el Reglamento General de Protección de Datos (RGPD)”, señala Noemí Brito, directora en el área Mercantil, responsable del área de Propiedad Intelectual y Nuevas Tecnologías de KPMG Abogados. La importancia de este Reglamento, a punto de ser aprobado, reside en que “supone el comienzo de unas bases de seguridad y confianza a la hora de implementar esta tecnología, ya que los sistemas de IA pueden poner en peligro derechos fundamentales como el derecho a la igualdad, a la no discriminación, la libertad de expresión, la dignidad humana, o la protección de los datos personales, entre otros. Y la protección de estos derechos imprime una doble dimensión desde la perspectiva de la IA legal, pero también desde el enfoque de la ética digital y el uso de tecnologías confiables y responsables (IA Ética), lo que está muy relacionado con el cumplimiento de los estándares ESG, además, añade Noemí Brito. Además, la nueva normativa de IA deberá coordinarse con otras normas importantes como es la normativa protectora de datos personales, habiéndose emitido por la Agencia Española de Protección de Datos diversas Guías respecto a los procesos de privacidad del diseño y por defecto que deben aplicarse en este ámbito, y también de auditoría de los tratamientos de datos que incluyan IA. “Sin duda, la relación entre la privacidad y la normativa reguladora de IA es muy estrecha, de forma que, incluso, algunas autoridades de protección de datos como la francesa (CNIL) han sumido competencias en estas materias y creado una división específica para supervisar que la IA sea confiable, señala Brito , el objetivo de este reglamento europeo es regular todo lo relativo a los sistemas de inteligencia artificial, partiendo de una definición de esta tecnología alineada con la establecida por la OCDE y aplicando un enfoque de riesgo. En este sentido, se consideraría IA y estaría sujeto a esta normativa todo “ sistema basado en una máquina diseñado para funcionar con distintos niveles de autonomía y que pueden mostrar adaptabilidad después del despliegue y que, por razones explícitas u objetivos implícitos, infiere, a partir de los insumos que recibe, cómo generar resultados tales como predicciones, contenidos, recomendaciones o decisiones que puedan influir física o entornos virtuales (…)”. En cualquier caso, la propia normativa establece que, con el tiempo, se van a ir incorporando nuevos sistemas en función de la innovación tecnológica en esta materia para que, en ningún caso, la norma quede desfasada y pueda así integrar los distintos avances que se hagan en torno a la Inteligencia Artificial. Este aspecto es especialmente relevante ya que, en palabras de Alberto Pinedo, National Techolonogy Officer de Microsoft en España, “en los próximos años, es probable que veamos una mayor adopción de la Inteligencia Artificial Generativa, y veremos implementaciones de productos basados en esta tecnología que van más allá de los usos en entornos productivos, de ventas y de seguridad. Estos usos van a traer nuevos retos regulatorios y de supervisión. Por ello, va a ser necesario que las políticas de sandboxing regulatorio, transparencia algorítmica y la oficina del dato se desarrollen para facilitar la adopción de esos nuevos casos de uso con las garantías necesarias”. España, en este sentido, está liderando el Sandbox regulatorio, un entorno de pruebas que incluye estudios algorítmicos con el que se pretende probar la eficacia del futuro del reglamento europeo sobre Inteligencia Artificial. De hecho, hasta el próximo 29 de junio, está en fase de audiencia pública el nuevo Proyecto de Real Decreto español que establece un entorno controlado de pruebas para el ensayo del cumplimiento de la propuesta de Reglamento del Parlamento Europeo y del Consejo, por el que se establecen normas armonizadas en materia de inteligencia artificial: Lo que resulta evidente es que cada vez está más cerca la adopción de esta nueva normativa y que, por consiguiente, las compañías y organizaciones deben comenzar a analizar a la mayor brevedad posible en qué medida les afecta las misma, según el tipo de sistemas Inteligencia Artificial que desarrollen, adopten o usen en su actividad, preparándose para poder cumplir con todas las obligaciones y previsiones de esta nueva normativa en ciernes. También implantando, en paralelo, un enfoque y visión ética y responsable/confiable  de tecnología emergente, que incluye a la Inteligencia Artificial, tal y como apunta esta legislación, y otros tantos pronunciamientos importantes en lo relativo a la Ética en la Inteligencia Artificial se refiere. Ante este panorama regulatorio, de lo que no cabe duda es de que una vez aterrice el Reglamento Europeo de Inteligencia Artificial, ese será el tablero de juego y la norma que aplique para las compañías que quieran integrarlo en sus modelos de negocio y servicios. Hasta entonces, la cuestión es cómo pueden blindarse las organizaciones que adopten esta tecnología ante los riesgos de seguridad que presenta la propia Inteligencia Artificial Generativa. Porque hasta ahora había determinadas herramientas que contaban con Inteligencia Artificial dentro de sus capas y, con ellas, lo que se hacía era ayudar al operador que trabajaba sobre la misma, pero, al haberse puesto esta tecnología al servicio del común de los usuarios, esta es capaz de relacionar distintos tipos de conocimiento y aportar un entendimiento sobre el mismo. “Gracias a su extensa base de conocimiento, también permite generar plantillas de ataque, por lo que puede ser una herramienta de soporte para quien plantea un vector (es decir, el medio por el que un ciberatacante llega a su ‘víctima’). Por este motivo, “la Inteligencia Artificial generativa no sería un riesgo de ciberseguridad en sí mismo, pero facilita los procesos que utiliza un potencial atacante para cerrar un vector de ataque”, destaca Javier Aznar, socio del área de Technology Risk, Consulting de KPMG en España. Más allá del posible uso de esta herramienta como facilitador para ‘diseñar’ ciberataques, Javier Aznar advierte del peligro y la vulnerabilidad que puede suponer para una compañía el uso de esta tecnología para cualquier tarea en la que se vean involucrados datos sensibles o privados de la misma, sin haber establecido unos límites y controles previos. “Hay que diferenciar entre introducir datos más o menos inocuos para realizar tareas de escaso valor y a título personal, y la adopción de una herramienta de estas características en un entorno empresarial con las licencias pertinentes. En este entorno, uno ya puede trabajar en automatizar sus procesos”, añade. En este sentido, Aznar es firme defensor de probar y adoptar esta tecnología, aunque siempre anticipándose para minimizar riesgos: Es importante mostrar especial cautela en las organizaciones que se planteen la introducción de la Inteligencia Artificial Generativa en sus procesos en lo que respecta a la protección de los datos personales , siendo diversas las autoridades de control que han iniciado de oficio actuaciones previas de investigación por posibles incumplimientos de la normativa. En general, se aboga por una mayor transparencia, mejor determinación de las bases legales del tratamiento, así como el reforzamiento de los derechos personales, entre otras medidas, lo que supone revisar si nuestros sistemas, procesos y políticas corporativas están preparadas para incorporar de manera segura esta tecnología para maximizar las posibilidades y oportunidades que trae consigo, sin perjuicio de los análisis y evaluaciones de impacto que deban realizarse de estos sistemas en los derechos fundamentales, sobre todo, cuanto estos sistemas de IA son calificados como de alto riesgo, apunta Noemí Brito. El debate ha trascendido del sector empresarial, escalando hasta los propios gobiernos. El ejemplo más notorio es que Italia prohibió en un primer momento su uso en su jurisdicción debido a la falta de claridad en cuanto a quién protegía los datos, si las bases legales eran correctas, si se estaba informando a los usuarios de manera adecuada o, incluso, si se estaba verificando la edad de los usuarios. Finalmente, se alcanzó un acuerdo en el que se establecía que, una vez adoptadas una serie de medidas (transparencia de los datos, ejercicio de derechos, protección de menores y la puesta en marcha de una campaña de información, entre otras), se permitiría su uso en el país, sin prejuicio de nuevas investigaciones. En la misma línea, también el propio Comité Europeo de protección de datos (quien aglutina todas las autoridades de protección de datos en Europa) ha planteado empezar a investigar esas prácticas, sumándose a esta investigación, entre otras autoridades europeas, la Agencia Española de Protección de Datos.  “Se trata de un escenario sobre la que aún no ha habido un pronunciamiento definitivo, pero en torno al cual los países están movilizándose de manera contundente antes el rápido crecimiento exponencial de esta tecnología”, comenta Noemí Brito. Volviendo al debate sobre cómo puede una empresa utilizar y sacar el mejor provecho de la Inteligencia Artificial Generativa, es crucial partir del concepto de dato personal, que es aquel que hace identificable a una persona. Teniendo en cuenta la gran base de datos con la que cuentan los sistemas de Inteligencia Artificial Generativa y a las preguntas que se le plantean, y gracias a la correlación de conocimiento que realiza, la herramienta puede llegar a identificar a una persona y suponer un riesgo. Sin embargo, los expertos recuerdan que el propio RGPD ya contempla la protección en entornos en los que se produce un tratamiento masivo de datos o una toma automatizada de decisiones. En estos casos, “se considera que dichos procesos tienen un riesgo más elevado y, en consecuencia, es necesario hacer una evaluación de impacto en privacidad, un PIA, por sus siglas en inglés (privacy impact assessment). Es por ello que la compañía debe hacer un análisis de riesgos de los datos que está tratando y argumentar cómo está generando una decisión en base a ellos, garantizando que son seguros”, señala Javier Aznar. Si bien es cierto que el Reglamento Europeo de Inteligencia Artificial es todavía un borrador, las organizaciones que vayan a utilizar esta tecnología deben ir trabajando en documentarse y anticiparse. “Porque la compañía tiene obligación de tener registros de todas las actividades en las que se tratan datos de terceros de carácter personal. Y, si en estas actividades se van a utilizar alguna de estas tecnologías, es imprescindible que las organizaciones revisiten esos PIAS e identifiquen qué controles y medidas específicas están tomando para proteger esos datos o garantizar que hay medidas de seguridad sobre los mismos o sobre el entorno y demostrar a la Agencia Española de Protección de Datos (AEPD) la anticipación en este sentido”, añade Javier Aznar. Por último, concienciar y formar a los empleados y profesionales dentro de las organizaciones que vayan a trabajar o apoyarse en esta tecnología acerca de su correcto uso, formulando guías o recomendaciones claras en este ámbito ayudará, sin duda, a optimizar tal uso, reduciendo los riesgos mencionados. Pero las medidas que deben tomar desde ya las compañías no son únicamente de naturaleza legal y de ciberseguridad. La llegada de la Inteligencia Artificial Generativa ha causado un gran revuelo a todos los niveles en cuanto a cómo va a cambiar la manera de trabajar. Las compañías llevan años acuciando un gap de talento: no están encontrando profesionales con la formación y habilidades necesarias como para manejar y potenciar el uso de una tecnología que no deja de avanzar y de superarse. Tanto es así que en el último Informe sobre el Futuro del Empleo 2023 del Foro Económico Mundial, se habla de “ruptura” como lo que mejor resume lo que está ocurriendo en el mercado laboral mundial, que se ve constantemente remodelado por la revolución digital, los esfuerzos por descarbonizar frente a la crisis climática y otros cambios geopolíticos y sociales. La separación entre el mundo empresarial y el mercado laboral es uno de los mayores desafíos a nivel económico y social de la actualidad, que tecnologías como la Inteligencia Artificial Generativa vuelven a poner encima de la mesa. El informe apunta a que los empresarios prevén la creación de 69 millones de nuevos puestos de trabajo y la supresión de 83 millones, lo que supondría una disminución neta de 14 millones de empleos, es decir, el 2% del empleo actual. Y, en paralelo, un 59% de los directivos que participaron en la encuesta ‘Perspectivas España 2023’ comparte que su organización está teniendo dificultades para incorporar el talento que necesita, mientras que un 65% reconoce que la escasez de talento pone en riesgo sus objetivos de negocio. El desafío es claro. Y la respuesta, insuficiente. Así lo considera Cristina Hebrero, socia responsable de People & Change de KPMG en España: “no estamos haciendo lo suficiente ante la problemática del talento porque no estamos alineados con las necesidades de hoy. Por un lado, debemos transmitir mejor a los jóvenes cuáles son las profesiones más demandadas, aquellas que tienen más futuro y en las que merece la pena invertir su formación. Y, por otro, debemos integrar esa rama tecnológica en todas las carreras porque no se está produciendo la alfabetización digital que el mundo necesita. Y eso es fruto de que no hemos actuado lo suficiente sobre los sistemas educativos”. 
69
 
59%
 
65%
 Prueba de ello es que, según se desprende del informe ‘Caminos que convergen: jóvenes y empresas ante el reto del talento’, realizado por KPMG junto a la Fundación Princesa de Girona, el 52% de los jóvenes y el 42% de las compañías encuestadas consideran que la preparación académica de las generaciones que se están incorporando al mercado laboral no se ajusta lo suficiente a las necesidades del mercado. Así, a la pregunta ¿está la oferta formativa preparada para responder a esta necesidad?, Ricardo J. Palomo Zurdo, catedrático y decano de la universidad San Pablo CEU responde: “en España, de momento no lo está. Los perfiles de grados tecnológicos están más avanzados en este sentido, pero los de ciencias sociales, aunque se están incorporando materias, todavía están lejos de contar con los conocimientos tecnológicos que desearíamos. El problema es que los planes de estudio, en muchos casos, han quedado obsoletos debido a la rapidez con la que se ha producido la transformación digital. Lo que se planteaba hace cinco o seis años, hoy ya no vale”. Parte de la solución a esta problemática y a la brecha de talento es el acercamiento entre el mundo corporativo y la educación, que “no pueden ni deben actuar como silos sino remar en la misma dirección”, defiende Cristina Hebrero. Sobre esta cuestión, Ricardo J. Palomo Zurdo sostiene que “durante muchos años la relación universidad empresa no ha sido del todo fluida. El alumno estudiaba, a veces se le proporcionaban prácticas en empresas, pero no había una retroalimentación o una información procedente de las empresas que trasladara lo que era necesario incorporar en los planes de estudio o la dirección a seguir. Sin embargo, ya hay universidades que están acercándose a las necesidades de la empresa y emprendiendo iniciativas conjuntas para estrechar lazos. Porque sabemos que nuestro fin último, nuestro éxito, reside en la empleabilidad de nuestros estudiantes”. Y es que, según el citado informe del Foro Económico Mundial, más de tres cuartos de las 803 empresas encuestadas prevén seguir adoptando tecnologías de Big data, computación en la nube e Inteligencia Artificial en los próximos cinco años, por lo que las compañías también necesitan implementar una estrategia de cara a su gestión del talento a raíz de la llegada de estas tecnologías. “Se va a producir un cambio en las prioridades en las compañías, que deben estar dispuestas a invertir más de lo que lo hacían antes en revisar sus estrategias de talento para identificar las habilidades que necesitan. No solo en los puestos comerciales y de producción sino en todas las funciones, porque esta revolución va a impactar a todas las áreas de la organización. No sabemos aún en qué porcentaje, pero lo que sí es seguro es que, aunque va a requerir cambios en la configuración del talento, y cambios rápidos, nos dirigimos hacia una sociedad en la que la capacidad humana tendrá un mayor valor estratégico”, sostiene Cristina Hebrero y coincide Ricardo J. Palomo Zurdo: “en el futuro habrá muchos empleados que se verán muy potenciados por las herramientas de Inteligencia Artificial si las saben utilizar”. No es la primera vez que el mundo se enfrenta a lo que parece una revolución, un desarrollo tecnológico que, sin duda, cambiará la manera de producir, de trabajar, y de relacionarse interpersonal y profesionalmente. Y, por ende, no es la primera vez que la empresa se enfrenta a un cambio de estas características. Es por ello que las compañías deben liderar este cambio. Y así lo están haciendo, demandando ya incorporar esta tecnología en sus procesos, aunque limitándose a pequeñas tareas. Para Eva García San Luis, este es el camino acertado. Aunque “es importante que las empresas no se limiten a un caso de uso, sino que sean capaces de automatizar sus procesos de forma completa para hacerlos más eficientes. Es aquí donde encontraremos el verdadero potencial”, asegura, además de defender una visión a largo plazo en lo que a la Inteligencia Artificial Generativa se refiere en el entorno corporativo. “las organizaciones deben adoptar un doble enfoque para la experimentación. Uno centrado en oportunidades de quick wins para obtener retornos rápidos. Y el otro, centrado en la reinvención del negocio utilizando modelos que se personalizan con los datos de la organización”, concluye.