Título: El entrenamiento de la IA supone un robo de los derechos de autor, según un estudio europeo
URL: https://www.elconfidencial.com/tecnologia/2024-09-06/inteligencia-artificial-robo-derechos-autor-propiedad-intelectual_3956950/
Número de palabras: 1233

 Los creadores de contenido y las empresas tecnológicas llevan meses en pie de guerra desde la aparición de las inteligencias artificiales generativas, como ChatGPT o Midjourney. Si bien es evidente su potencial creativo, su extendida popularidad ha sacado a la palestra cuestiones sobre la propiedad intelectual y la protección de los derechos de autor. Hasta hace poco, las empresas de IA estaban entrenando su tecnología con todos los datos que pescaban en la red, en lo que algunos especialistas han llamado el "mayor robo de la historia de internet".   El problema es que, tras el boom inicial de la IA, se ha hecho más que evidente que uno no puede ir por internet y usar lo que le dé la gana sin permiso. Ahí está la demanda en los tribunales de The New York Times contra OpenAI para recordárnoslo. En este caso, la primera demandó a la segunda por, supuestamente, usar sus extensos archivos sin permiso para entrenar chatbots. O la de Getty Images contra Stable Diffusion, por infringir también su copyright. Según denunció, esta IA había utilizado para su entrenamiento millones de imágenes protegidas.   Ya se han producido decenas de demandas en este sentido y no serán las únicas. El tema ahora ha llegado al Parlamento Europeo, donde se acaba de presentar un dictamen pericial conjunto sobre los aspectos tecnológicos y jurídicos del entrenamiento de modelos generativos de IA. En una investigación interdisciplinar titulada Copyright y formación de modelos generativos de IA: fundamentos tecnológicos y legales, el profesor Dr. Tim W. Dornis, de la Universidad de Hannover, junto al profesor Dr. Sebastian Stober, de la Universidad de Magdeburgo, han creado a gran escala pruebas relativas a los pasos de procesamiento en el entrenamiento de la IA.   En su estudio, concluyen que esto supone una infracción de los derechos de autor: "Como revela un examen más detallado de la tecnología de los modelos generativos de IA, el entrenamiento de tales modelos no es un caso de minería de textos y datos. Se trata de una infracción de los derechos de autor, sin excepción alguna en la legislación alemana y europea sobre derechos de autor", afirma el profesor Stober Dornis. El profesor Stober explica que "parte de los datos de entrenamiento pueden ser memorizados total o parcialmente por los modelos generativos actuales (LLM y modelos de difusión latente) y, por tanto, pueden ser generados de nuevo con indicaciones adecuadas por los usuarios finales y, de este modo, reproducidos".   La investigación ha sido muy bien recibida en el Parlamento Europeo. Axel Voss, eurodiputado y anfitrión del acto, señalaba que este estudio "no sólo demuestra que el entrenamiento de los modelos de IA no está cubierto por la minería de textos y datos, sino que también aporta otras indicaciones importantes para lograr un mejor equilibrio entre la protección de la creatividad humana y el fomento de la innovación”. En la misma línea se pronunciaba Hanna Möllers, asesora jurídica del DJV y representante de la Federación Europea de Periodistas (FEP), quien indicaba que se trata de una investigación explosiva porque demuestra que estamos ante un robo de propiedad intelectual a gran escala: “La pelota está ahora en el tejado de los políticos para que saquen las conclusiones necesarias y pongan fin de una vez a este robo a costa de los periodistas y otros autores".   El compositor y portavoz de la Iniciativa de Derechos de Autor, Matthias Hornschuh, se mostraba algo más duro con los resultados. "Habría un nuevo y rentable mercado de licencias en el horizonte, pero no fluye ninguna remuneración, mientras que la IA generativa se prepara para sustituir a aquellos de cuyos contenidos vive en su propio mercado. Esto pone en peligro el trabajo profesional del conocimiento y no puede ir en interés de la sociedad, la cultura o la economía”.   Hace unos meses, la actriz y comediante estadounidense Sarah Silverman y los escritores Paul Tremblay y Mona Awad, demandaron a OpenAI, el creador de ChatGPT, y al gigante tecnológico Meta, por infringir sus derechos de autor en el entrenamiento de sus IA generativas. Alegaron que, sin el consentimiento de los autores, “sus materiales protegidos con derechos de autor fueron ingeridos y utilizados para entrenar a ChatGPT”. También recientemente se lanzó una demanda colectiva en EEUU contra Google en el que se le acusaba de “haber robado en secreto todo lo creado y compartido en internet por cientos de millones de estadounidenses” para entrenar sus productos.   El argumento jurídico que suelen alegar las empresas es que la IA entrenada con obras protegidas por derechos de autor no constituye una infracción, ya que estos modelos no "copian" los datos de entrenamiento, sino que están diseñados para aprender las asociaciones entre los elementos de los escritos y las imágenes, como las palabras y los píxeles, y transformarlos. Y que los resultados no coinciden con los datos de entrenamiento.   Sin embargo, otras investigaciones de auditoría han demostrado que los usuarios pueden acabar produciendo obras que se parecen mucho a contenido protegido. El problema es que es muy complicado demostrar que una obra ha sido usada para entrenar una máquina, de ahí que las entidades de gestión de derechos de autor quisieran imponer la obligación de citar las fuentes utilizadas, algo ahora contemplado en el Reglamento de Inteligencia Artificial. Otra solución que se ha barajado entre instituciones, expertos y empresas editoriales ha sido la de crear una especie de Lista Robinson, donde te apuntes para prohibir que las IA utilicen tus obras o fondo editorial. O imponer un canon a las empresas de estas herramientas, parecido al famoso canon por copia privada.   En Reino Unido, en un informe presentado a la Comisión de Comunicaciones y Asuntos Digitales de la Cámara de los Lores, OpenAI ha afirmado que no puede entrenar grandes modelos lingüísticos sin tener acceso a obras protegidas por derechos de autor. La dueña de ChatGPT admite que la información publicada en internet es una de las fuentes principales de sus modelos y defiende que el entrenamiento es fair use (uso legítimo), pero que dan la opción de no participar (opt-out) “porque es lo correcto”.   En repetidas veces, OpenAI y otras compañías similares han esquivado los derechos de autor excusándose en que sus modelos “aprenden” y que no hay copia ni plagio, como no lo hay cuando nosotros explicamos con nuestras palabras algo que hemos leído previamente. Pero esa visión contradice en cierto modo la demanda del New York Times, que ilustraba con ejemplos reales varios casos de “memorización” diferentes en los que ChatGPT y Bing Chat (ahora Copilot) reproducen textos completos de varios párrafos exactamente igual a los artículos originales del periódico, incluso de aquellos que están detrás del muro de pago. OpenAI le pone un nuevo nombre a esto: “regurgitación”, y lo define como un fallo poco común en el que están trabajando. La batalla entre medios y tecnológicas de IA está muy lejos de terminar.   Los creadores de contenido y las empresas tecnológicas llevan meses en pie de guerra desde la aparición de las inteligencias artificiales generativas, como ChatGPT o Midjourney. Si bien es evidente su potencial creativo, su extendida popularidad ha sacado a la palestra cuestiones sobre la propiedad intelectual y la protección de los derechos de autor. Hasta hace poco, las empresas de IA estaban entrenando su tecnología con todos los datos que pescaban en la red, en lo que algunos especialistas han llamado el "mayor robo de la historia de internet". 